UID,title,authors,keywords,sessions,abstract
A1-1,市況コメント生成のための少数事例選択,川原田将之|石垣達也|高村大也,,A1:言語生成技術の応用,"株価の数値時系列データからその値動きを説明する市況コメントを生成するタスクにおいて，プロンプトに含める少数ショット事例の選択方法が性能向上のために重要であることを述べる．従来，少数ショット事例は無作為に選択されており，その選択方法に関しては十分に研究されてこなかった．本研究では，類似する数値時系列データからのコメントや同一時点でのコメントの傾向が類似しているという特性を活用し，これらを少数ショット事例としてプロンプトに含める手法を提案する．評価実験において，ランダムに選択された事例を使用するベースラインと比較し,提案手法が代表的な評価指標である BLEU，METEOR，BERTScore をいずれも向上させた．"
A1-2,プロンプトチューニングとkNN-LMを組み合わせたリスティング広告のタイトル自動生成,児玉壮平|星野智紀|石塚湖太,,A1:言語生成技術の応用,リス ティ ング 広告 のタ イト ル自 動生 成に は，Fine-Tuning された事前学習済み言語モデルをの活用が盛んである．また，Fine-Tuning はモデルやデータが大規模になると計算コストがより増加する．本研究では，Instruction-Tuning 済みモデルに kNN-LMを導入し，プロンプトチューニングと用例検索によって広告タイトルを生成する．さらに，kNN-LMにおいて用例検索を行うモデルと生成を行うモデルを分けることで，プロンプトチューニングの度にkNN-LM のデータストアを再構築する必要をなくす．実験によって，提案手法によって広告タイトルの生成品質が向上することを確認し，計算コストを削減できることを確認した．
A1-3,複数の属性に対する評価を含む宿泊施設レビューに対する多様な返信の自動生成,村越裕太|白井清昭,,A1:言語生成技術の応用,本研究は，宿泊施設に関する低評価レビューに対し，定型的で当り障りのない表現を用いずに，レビューワーが苦情を述べている全ての属性について言及した返信を生成することを目的とする．レビュー中の全ての属性に言及するために，レビューを文に分割し，それぞれの文に対して系列変換モデルで返信を生成した後，それらを統合する．系列変換モデルを学習する際には，属性に言及していない返信，定型的な表現が含まれる返信を訓練データからあらかじめ削除する．実験の結果，特に複数の属性を含むレビューに対し，提案手法によって自動生成された返信の品質が向上することを確認した．
A1-4,答案診断グラフを用いた国語記述式答案へのフィードバックの生成,古橋萌々香|舟山弘晃|岩瀬裕哉|松林優一郎|磯部順子|菅原朔|乾健太郎,,A1:言語生成技術の応用,学校教育現場では記述式問題が盛んに使われている．しかし，人手による記述式の答案の採点では，学習者の答案に対して個別最適なアドバイスが難しいという問題がある．本研究では，国語の記述式問題を対象に，学習者の答案の誤りに応じた個別のフィードバックを生成するシステムの構築を目指す．その手法として，実際の教育現場で扱われている本文の論理構造関係に着目し，本文の論理構造，談話関係，フィードバックのテンプレートを統合した答案診断グラフと呼ぶ構造を構築し，答案に記述されている内容と模範解答の内容の対応から，適切なフィードバック文を生成する枠組みを提案する．
A1-5,多様なクイズを自動生成する手法およびその検証,小林俊介|河原大輔,,A1:言語生成技術の応用,クイズは、高齢者の認知機能維持や、エンターテインメントに利用されており、多様なクイズ問題の作成が必要である。しかし、人手による大量の作問にはコストがかかるため、自動生成が望ましい。本研究では、質問生成モデルの学習手法や入出力形式を変更し、多様なクイズ問題の自動生成について検証する。提案手法を用いて生成された問題は、多様な問題を生成することが確認できた。また新規のWikipedia 記事から問題を生成できることも確認でき、システムの有効性が示された。
B1-1,用語制約が多い翻訳に対する手法の提案,加藤優吾|小川泰弘|外山勝彦,,B1:機械翻訳(1),翻訳における訳語の揺れは混乱や誤解を招く可能性があるため，決められた訳語に従った翻訳が必要となる．すなわち，用語制約のある翻訳が求められる．そのための手法として入力拡張[1]などが提案されている．しかし，学習に使用する対訳文が用語制約に従っているとは限らず，それらの対訳文が学習においてノイズとなる可能性がある．そこで，本研究では学習データを選別する手法を導入し，入力拡張と組み合わせる手法を提案する．さらに，日本法令の対訳データセットを用いて実験し，提案手法が有効であることを示す．
B1-2,Post-Editing with Error Annotation for Machine Translation: Dataset Construction using GPT-4,◊YouyuanLin|MasaakiNagata|ChenhuiChu,,B1:機械翻訳(1),"Despite advancements in Large Language Models(LLMs) and their state-of-the-art Machine Translation(MT) performance,ﬁne-grained Automatic Post Editing(APE) remains useful for MT by aiding in error detection,especially when applied to speciﬁc domains. To train suchAPE systems that incor porate error detection capabilities,APE datasets with error annotation are essential. However,most APE datasets are lack of error annotations. We aimto construct error-annotated APE datasets that improve theerror-based editing proﬁciency of APE systems. We lever-age GPT-4, expand post-editing into error-annotated MTdatasets. By employing a Chain-of-Thought (CoT) settingthat applies an error annotation-based analysis step beforepost-editing, we ensure the post-editing corrects the errorswhile maintaining the phraseology. Our experiments on aJapanese-English medical MT dataset reveal that GPT-4,coupled with CoT and error annotations, excels in generat-ing high-quality, annotation-informed post-edits."
B1-3,日本語→琉球諸語翻訳モデルの構築に向けて,當間愛晃|狩俣繁久|岡﨑威生,,B1:機械翻訳(1),消滅の危機に瀕している琉球諸語の記録，記述や復興への一助のため，日本語を琉球諸語へ機械翻訳するモデル構築に向けた3 つの検証を行った．実験結果から，対象言語を含まない翻訳学習を一度行い，その上で日琉翻訳学習を行うことが翻訳品質の向上に寄与することを確認した．品質改善に向けては，本ドメインに特化した評価指標の構築，ルールベース翻訳した中間言語を介した翻訳，検証用・テスト用コーパスの構築，新規トークン埋め込みベクトルの検討が寄与すると考えられる．
B1-4,重文・複文翻訳における Transfomer の性質,丸山京祐|村上仁一,,B1:機械翻訳(1),本論文では，重文・複文の翻訳において対訳単文を学習することが精度に与える影響を Transformerと RNN を比較し調査した．その結果，自動評価指標では Transformer は RNN よりも対訳単文が翻訳精度向上に貢献することが分かった．しかし，人手評価で Transformer と RNN を比較した結果，自動評価指標の数値から期待されるほどの高い翻訳精度が得られなかったことを示す．
B1-5,多言語モデルを用いた日英対訳文集合のフィルタリング手法の分析,酒井大樹|宇津呂武仁|永田昌明,,B1:機械翻訳(1),本論文では，ウェブクロールコーパス であ るJParaCrawl-v3 に含まれる不適切な文対を，多言語モデルによるスコアを用いてフィルタリングすることを目指した．事前に異なる文の断片を含む文対応誤りデータを擬似的に作成し，その誤りの検出する様子を 4 つの言語モデルの間で調査した．その結果，Bicleaner-AI と marian-scorer の方が LEALLA，GPT-2よりも正しく誤りを検出する度合いが大きかった．その後，各モデルを用いて JParaCrawl-v3 のフィルタリングを実行した結果，Bicleaner-AI と marian-scorerは，フィルタリングにおいても英日方向に有意差を出すことがわかった．
C1-1,大規模言語モデルを用いた検索モデルの中間学習のためのコーパス作成手法,柴田幸輝|加藤誠|百合草陽介,,C1:検索・文書分類(1),"商品検索などのドメイン特化の検索タスクにおいては，言語モデルが事前学習するような一般的なコーパスには無い，ドメイン独自の意味を持つ語が存在し，語彙の意味のギャップが存在することが懸念される．このようなドメイン間の語彙の意味のギャップを埋めるために，事前学習を用いた転移学習手法が提案されている．しかしながら，実務においては十分なサイズのコーパスを用意することが難しいような場合がある．その場合，事前学習を用いた転移学習手法の適用は難しい．そこで本研究では比較的小さな対象ドメインのコーパスが存在する場合に，言語モデルの MLM loss と二値分類モデルに基づいて汎用大規模コーパスから語彙の意味のギャップを埋めるようなコーパスを作成する手法を提案する．提案手法の性能を評価するため,提案手法とベースライン手法を用いて複数のドメインを対象に大規模汎用コーパスからコーパスを作成し検索タスクにて実験を行った．実験を行った結果，全てのドメインで提案手法が高い性能を示した．"
C1-2,テキスト変換によるリポジトリレベルのコード検索の改善,近藤瑞希|河原大輔|倉林利行,,C1:検索・文書分類(1),大規模言語モデルによるコード生成能力は年々上昇しているが、リポジトリレベルでのコード生成の研究はあまり活発ではない。リポジトリレベルのコード生成では複数ファイルの中から関連するのコードの参照が必要となる。コード間の類似度を取ることで関連するファイルを検索し言語モデルに入力し、生成を行う。本研究では関連するファイルの検索(コード検索)を、コード間の類似度ではなく、コードを言語モデルで変換したテキストで類似度を取る手法を提案する。テキストに変換することでコード検索の精度が向上することを確認した。
C1-3,クロスドメイン検索型質問応答のためのニューラル疎ベクトル検索,西田光甫|吉永直樹|西田京介,,C1:検索・文書分類(1),検索型質問応答はコーパスからの検索を用いて質問に回答するタスクである．質問応答で機密性の高いドメインを扱う場合，ターゲットドメインの文書を訓練時に使えない・ユーザ環境で運用する必要がある，の制約がある．そこで本研究では，訓練と推論のドメインが異なるクロスドメイン検索型質問応答タスクに，CPU で高速に動作する疎ベクトル検索で取り組んだ．提案手法は，ソースドメインで学習したモデルの埋め込み行列をターゲットドメインに低コストに適応させ，新たな学習可能パラメータの導入によって出力のスパース性を強めることで，2つの制約に対処する．評価実験により，精度と計算効率双方における提案手法の有効性を確認した．
C1-4,Twitterデータを用いたヘビーユーザ特定,小川歩|鈴木愛海|櫻井義尚,,C1:検索・文書分類(1),SNS が提供するデジタル活動データは，ユーザ行動や意見の収集に貢献している．特にヘビーユーザからのフィードバックは，企業にとって重要な意見であり，直接的な収益に結びつく．しかし，手動でのヘビーユーザ特定は時間と金銭がかかる．そこで，本研究では機械学習を使って自動的にヘビーユーザを特定し，ChatGPT と比較する実験を行う．研究の成果が企業やプロバイダーにヘビーユーザ特性の洞察を提供し，マーケティング戦略の最適化に寄与することが期待される．
C1-5,レビューの多角的な有用性判別のための分析と分類モデルの構築,屋比久博文|當間愛晃,,C1:検索・文書分類(1),多角的な有用性判別の実現を目的として EC サイトのレビュー体系分析を行った．分析の結果，レビューの傾向は「日常的に利用する商品」と「一時的に利用する商品」で異なることがわかった．「日常的に利用する商品」に焦点をあてさらに分析することで 9 つのラベルを考案し，各ラベルに自動で分類するモデルの構築と精度向上のための 3 つのパターンで実験を行った．その結果，損失関数の重み調整が精度向上に寄与することが確認された．分類精度の更なる改善に向けて，オーギュメンテーション，不均衡データになりづらいラベル設計や交差検証の検討が必要であると考えている．
D1-1,サンスクリット文献『リグ・ヴェーダ』の韻律構造にもとづくクラスタ分析,塚越柚季|大向一輝,,D1:社会言語学・その他の言語学,本研究は，サンスクリット語の最古の文献である『リグ・ヴェーダ』の詩節を韻律の観点から分析する．韻律構造のみに着目し，詩節を軽音節，重音節，単語境界，行境界の 4 つの要素に還元してクラスタリングを行う．その結果，従来同一の韻律名とされてきた詩節の中にも異なるクラスタを形成するものが存在することが明らかになった．また，行数の異なる類似の韻律がひとまとまりとなるなど，韻律構造の共通性が示された．今後，この手法を用いて印欧語族の複数言語の比較が可能となることが期待される．
D1-2,語彙の多様性，密度，洗練性から見た語彙の豊富さ,鄭弯弯,,D1:社会言語学・その他の言語学,語彙は言語の根幹として認識されている中で，その豊かさを量的に示す課題は，計量言語学分野において依然として難題であり続けている．語彙の豊富さは，言語習得，言語変化，心理学および認知科学などの理論的および実践的な分野で幅広く適用されている．しかし，語彙は複雑であり，その豊かさは通常，語彙の多様性，密度，洗練度といった三つの側面から測定できる．その中で，語彙の多様性は広く研究されているが，テキストの長さに依存しない指標が依然として不足している．一方で，語彙の密度と洗練性の特性は十分に扱われていない．本研究は，日本語における語彙の多様性，密度，および洗練性の特徴を描き出し，それらの相互関係を探求することを目的とする．
D1-3,豊かな記憶が創る複数形の諸相,皆川翔,,D1:社会言語学・その他の言語学,英語の複数形は，英語学習者がその初期に学ぶ基本的な文法事項の 1 つである．しかし単数形に形態素‘s’をつけるという操作は後付けの文法的な説明であり，それは必ずしも英語話者がどのように複数形を運用しているのかという説明にはならない．今研究は大規模な言語データを用いて，複数形という文法を創りあげる背後に後述する「豊かな記憶」が複雑なネットワークを構築していることを単数形と複数形の使用頻度差と類似度の観点から検証し，複数形の習得と運用のプロセスを具体的に可視化することを目的としている.
D1-4,国会集団語の発展段階の分析,松田謙次郎,,D1:社会言語学・その他の言語学,"国会審議に見られる集団語 4 語の言語的・社会的生成過程に関する分析結果を報告する．76 年分の国会会議録から「テレビ入り」「総理入り」「お経読み」「つるし」を抽出しデータを分析した．言語的過程として原義⇒{ヘッジ共起,意味転換}⇒文脈拡大の 3 段階が確認され，段階を経るごとに前段階の形式が追加され共存に至ることが確認された．またいずれの語も 1～3 の政党所属の複数議員から始まり全政党に拡散したことから，少なくとも拡散の開始は政党単位であると見做せる．従来の集団語研究に欠けていた実際の言語使用データを用いた形成・拡散過程の分析を可能にする点で，国会会議録は理想的な言語資源を提供する．"
D1-5,Stability of Translation Across Sound Effect Type: Focusing on Onomatopoeia in Japanese Shonen Manga,◊ToddHooper|MarikoTakahashi,,D1:社会言語学・その他の言語学,"This paper investigates whether giongo and gitaigo inJapanese shonen manga retain their type (sound words/ descriptive words) when they are translated into English. Three  manga  representing  different  genres  of  shonen manga were selected, and sound effects were manually extracted  from  the  original  Japanese  version  and  the English translated version, compiling a database of 1000 instances of onomatopoeia. Statistical analysis indicated that giongo tended to retain their type, whereas gitaigo were  often  translated  into  sound  words. Qualitative analysis then showed that context affected the translation of sound effects. The findings indicate that translation of onomatopoeia varies depending on their type."
E1-1,Visual Question Answering における視線情報を用いた質問の曖昧性解消,稲積駿|河野誠也|湯口彰重|川西康友|吉野幸一郎,,E1:実世界接地と言語処理,ユーザ(話者)と対話システムの会話には，指示語や省略に起因した曖昧さが含まれる．こうした曖昧さは，話者の視線や指差しといった情報で補完することが可能である．本研究では視線情報を用いた話者の質問の曖昧性解消を，Visual Question Answering(VQA)のタスクにおいて実現する．このため，視線情報と曖昧な質問が紐づいた視線情報付き VQAデータセット(GazeVQA)，および注視対象の情報を活用した質問応答モデルを提案する．GazeVQA による実験では，提案モデルが注視対象の推定を用いない既存モデルと比較して優れた性能を達成した．
E1-2,SNS上の絵文字位置パターンの分析とLevenshtein距離を用いたサンプル抽出,山崎由佳|西村綾夏,,E1:実世界接地と言語処理,本研究は，SNS 上の投稿における絵文字の位置のパターンに着目する．SNS 上の投稿では，複数の絵文字が規則的に配されることを通じて，情報伝達を助ける機能が発揮されることがある．このような事象を探るにおいては，投稿中の絵文字単体のみでなく全体の位置を取り扱うことが有効である．本研究は，特徴的なパターンを持つ投稿データを効率よく抽出するために，絵文字位置ラベルの列に対する Levenshtein 距離を用いたサンプル抽出（および分類）の方法を提案する．実際に，X（旧 Twitter）の投稿データを対象としてこれを実施し，得られた特徴的なパターンについて説明する．
E1-3,基盤モデルと古典プランニングを用いたレシピ記述からの実世界調理計画認識実行ロボットシステム,金沢直晃|河原塚健人|大日方慶樹|岡田慧|稲葉雅幸,,E1:実世界接地と言語処理,ロボットによる調理実行においては，自然言語のレシピ記述に基づいて作業を行えることが望ましいが，大規模言語モデルが登場した現在においても依然として課題が存在する．本研究では特に重要な 2つの課題に着目し，大規模言語モデルと PDDL 記述の古典プランニングによる実世界で実行可能なロボット調理行動計画と，視覚-言語モデルを用いた少数データからの食材状態認識学習を行うロボットシステムを提案した．実世界でロボットが調理を実行する実機実験により提案システムの有効性を確認した．
E1-4,実世界対話におけるフレーズグラウンディングモデルの評価と分析,植田暢大|波部英子|松井陽子|湯口彰重|河野誠也|川西康友|黒橋禎夫|吉野幸一郎,,E1:実世界接地と言語処理,実世界の共同作業における対話では，物体に対する参照表現が多く出現する．本研究ではフレーズグラウンディングの枠組みで，実世界対話における既存モデルの物体参照表現に対するフレーズグラウンディング性能を評価・分析し，課題を明らかにする．また，分析に基づいた改善手法の検討を行う．
E1-5,都市環境における歩行者支援のための画像説明文生成用データセットの作成,西村千恵子|栗田修平|関洋平,,E1:実世界接地と言語処理,視覚障害者の歩行支援では、周囲の視覚情報を他の感覚に変換して提供することが必要である。そこで本研究では、画像説明文生成のデータセットを作成し、視覚言語モデルのファインチューニングを行った。現在の画像説明文の生成技術は、写真の意味理解等の分野においては大きく進歩したが、写真から特定の目的を持って説明するものはまだ少ない。そこで本研究では、視覚障がい者や晴眼者の歩行支援を目的とし、街頭の歩行動画から取得した画像から、歩行時の注意文を生成した。性能評価では、ファインチューニングを施したモデルにて、ファインチューニング前よりも画像中の局所的な障害物について情報提供ができることが示唆された。
P1-1,話し言葉における副詞の生起位置と係り先までの距離の関係,島崎英香|丸山岳彦,,P1:ポスター,日本語の話し言葉（独話）を対象として、副詞の「生起位置」および「係り先までの距離」の 2 点について議論を行う。副詞は「程度副詞」「情態副詞」「陳述副詞」の 3 種に分類されるのが一般的であるが、これらの区別が「副詞が発話中に生起する位置」「副詞が修飾する文節までの距離」とどのように関連するかについて、『日本語話し言葉コーパス』（CSJ）に出現した事例をもとに分析した。
P1-2,Finding structure in spelling and pronunciation using Latent Dirichlet Allocation,黒田航,,P1:ポスター,"Latent Dirichet Allocation (LDA) was used to revealhidden regularities in spelling and pronunciation amonglanguages, such as English, French, German, Russian andSwahili. Words, either in spell or pronunciation, wereregarded as “documents” and their characters as “terms.”For spelling, spells from the languages were mixed andencoded using LDA and analyzed. For pronunciation, IPAsymbols for English, French and German were encoded andanalyzed in the same way. Both gave promising results."
P1-3,関西方言を対象とした形態素解析用辞書の開発,小木曽智信|尹熙洙|王竣磊|岡田純子,,P1:ポスター,現代語用の UniDic をベースに関西方言の会話書き起こしテキストを対象とした形態素解析用辞書を開発・公開した。学習用のコーパスとして、新たに短単位データとして整備した「関西弁コーパス」の一部と「日本語歴史コーパス」に含まれる近世・近代の関西の資料等を用いた。辞書にはコーパスに出現した未登録語等から方言の語彙を追加したほか、方言形の助動詞類を活用表を含めて整備・登録した。これによって現代の関西方言の書き起こしテキストを、「現代話し言葉 UniDic」を上回る精度で解析することが可能となった。
P1-4,医療縮約表現の分析と課題,相良かおる|黒田航|東条佳奈|西嶋佑太郎|麻子軒|山崎誠,,P1:ポスター,"医療記録に含まれる合成語には，複合語に加えて，助詞が省略された句や節に相当するものがある．我々はこれらを「医療縮約表現」とし，現在 813 語の医療縮約表現の分析を行い，1,336 種類の語構成要素に 53 種類の意味ラベルを付与し，3 回目の見直しを行っている．分析の過程で，医療縮約表現には，①「文」相当となるもの，②接頭語「未」が語末に来るもの，③「施行」「あり」「術」などの語が省略されるものがあることがわかった．また，医療縮約表現の選定方法，語構成要素の認定，意味分類および意味ラベルについての課題も明らかになった．"
P1-5,複数短単位版「分類語彙表番号-UniDic」対応表の整備と公開,片山久留美|髙橋雄太|菊池そのみ|小木曽智信,,P1:ポスター,コーパスに語義を付与することのできる語彙資源として「分類語彙表番号-UniDic 語彙素番号対応表」が公開されているが，収録語は分類語彙表の見出し語が UniDic 短単位と完全一致するものに留まっていた．本研究では，これを補完するデータとして複数短単位に分割される分類語彙表見出しと UniDic との対応表を作成した．このデータを活用することで，国立国語研究所のコーパスや短単位解析結果に対して本来の分類語彙表番号を付与することが可能になったほか，分類語彙表見出し語の構造について UniDic の情報を利用した分析を行うことが可能となった．本データの構築方法や公開形式について報告する．
P1-6,トークナイザーの圧縮率を用いた有害コンテンツの判定法,梶浦照乃|山内璃乃|小柳響子|東出紗也夏|倉光君郎,,P1:ポスター,本研究では，大規模言語モデルの学習に用いられる大規模コーパスの有害コンテンツ除去を目的として，トークナイザーの圧縮率をもとにテキストを有害/無害に判定する方法を提案する．まず，有害コンテンツから有害語彙モデルを構築する．次に，有害語彙モデルを用いてテキストをトークン化し，圧縮率を算出する．これにより，有害なコンテンツは高い圧縮率を示し，一般的な無害なコンテンツは比較的低い圧縮率を示すため，有害コンテンツの判定に利用できると考える．本論文では，提案手法を用いて大規模なテキストにおける有害コンテンツの判定を評価し，有害コンテンツを実用的な速度で正しく判定できることを確認した．
P1-7,「昭和・平成書き言葉コーパス」の語彙統計情報の公開,相田太一|近藤明日子|小木曽智信,,P1:ポスター,本研究では、1933 年から 2013 年までの間を 8 年おきにカバーする「昭和・平成書き言葉コーパス」に関して、𝑛-gram 頻度形式と SVMlight 形式の共起情報を公開した1）。以前公開された統計情報に比べて昭和・平成の時代に限定されているが、今回は雑誌に加えて新たにベストセラー書籍と新聞のレジスター（ドメイン）を追加し、複数の時期だけでなく複数のレジスターを跨いだ分析が可能になった。本稿では、自然言語処理と日本語学の二つの側面において、この統計情報を用いた研究の可能性を示す。
P1-8,『日本経済新聞記事オープンコーパス』に対するメタデータと語義情報付与,加藤祥|浅原正幸,,P1:ポスター,本研究では『日本経済新聞記事オープンコーパス』に対して、メタデータとして新聞記事分類情報を付与した。さらに語義情報として分類語彙表番号を付与した。本研究で付与した情報は、『現代日本語書き言葉均衡コーパス』に含まれる新聞記事サンプルとの対照が可能である。分類情報の分布から『日本経済新聞記事オープンコーパス』は「経済」記事に特化していることが確認された。また、各新聞記事の「経済」記事との詳細な記事分類情報の分布や語義情報の分布を比較した。
P1-9,A Task of Cloze Explanation Generation for ESL Learning,◊ZizhengZhang|MasatoMita|MamoruKomachi,,P1:ポスター,"Addressing the lack of dedicated tasks for generating lan-guage learner explanations of cloze questions, this paperintroduces a new task focused on cloze explanation gen-eration in language assessment, particularly for English asSecond Language (ESL) learners. To support this task,we present a meticulously curated data creation method,which expands expert-designed high-quality cloze ques-tions and explanations. This data aims to assess languageproﬁciency and facilitates language learning by oﬀeringinformative and accurate explanations."
P1-10,日本語意味変化検出の評価セットの拡張と検出手法の評価,凌志棟|相田太一|岡照晃|小町守,,P1:ポスター,時代とともに意味が変化する単語をコーパスから自動的に検出・分析する研究は、言語学者だけでなく自然言語処理の研究者からも注目を集めている。英語やドイツ語などの言語では、時期の異なる学習用コーパス（通時コーパス）の公開や評価用単語リストの作成が進んでいるが、日本語では不十分である。本研究では、我々が作成した日本語の評価用単語リストを拡張し、意味変化検出手法の性能評価を行った。頻度に基づく手法をベースラインとして、タイプベースとトークンベースの代表的な手法の性能を比較し、それぞれの手法の特徴を議論した。
P1-11,マルチモーダルな野鳥の検索を目的とした知識ベースの構築,寺本優香|小島諒介,,P1:ポスター,実フィールドでの野鳥観測は自然環境理解や環境モニタリングのために重要である．本研究では，野鳥の観測を補助するための野鳥検索システムの構築を目指し，キーワード検索に加え，知識グラフ，音響情報での検索を可能とするためのマルチモーダルな埋込みからなる知識ベースを構築する．これらの複数のモダリティを組み合わせることで，単一モダリティでは見つけることが困難な関係性を互いに補うことで，より柔軟な検索システムの構築が期待できる．本研究では，その第一歩として，個別のモダリティ間のから得られる埋め込みベクトルの違いを分析し可視化することで，複数のモダリティを鳥種検索に用いることの重要性を確認した．
P1-12,Zero-shot Definition Modelling for Portuguese,EdisonMarrese-Taylor|◊EricaKidoShimomoto|EnriqueReid,,P1:ポスター,"In this paper, we propose to study the task of deﬁni-tion modeling for a new language: Portuguese. To thatend, we collect monolingual dictionary data and performan in-depth empirical study to test the multilingual abili-ties of Large Language Models (LLMs), utilizing zero-shotand few-shot approaches. We analyze the performance ofLlama-2 and Mistral LLMs on monosemic terms, as ourcollected data does not contain context information forpolysemic words. To address this limitation, we furtherpropose to utilize LLMs to generate usage examples thatcan assist deﬁnition modeling of polysemic terms in the fu-ture. To validate our ﬁndings, we performed a pilot humanstudy to evaluate the quality of generated deﬁnitions andusage examples. Our results are encouraging and suggestthat LLMs can generate plausible deﬁnitions of words inPortuguese and that the COMET metric aligns well withthe human evaluation. Finally, our human study indicatesthat using LLMs could be an alternative to obtain contextinformation of polysemic words in Portuguese."
P1-13,木形状分布の分析：自然言語の句構造とランダム木について,石井太河|宮尾祐介,,P1:ポスター,自然言語の構文木はランダムではない．では，自然言語の構文木は「木」として，どのような性質を持っているのか？本研究では，特に，左右の分岐の深さなどの木の形状に着目する．構文木の形状は，言語により異なることがあり，多様な言語を特徴付ける要素として重要である．一方で，同一言語内でも構文木の形状は一定ではなく，定性的には特徴を捉えきれない．そこで，本研究では，句構造ツリーバンクに関して木形状の分布を計算し，言語による差異・共通点をより詳細に調査する．また，ランダム生成した木と比較し，自然言語特有の現象について考察する．
P1-14,読解時の視線認識情報と音声発話コーパスを用いたポーズの予測とその比較,林小春|狩野芳伸,,P1:ポスター,人間が連続した文章を発話する際、文章中に音声的なポーズが発生する。また、ポーズの挿入は発話時だけではなく音読や黙読といった読解時も同様に行われ、人間は頭の中で文章にポーズを挿入しながら読解していると考えられる。そこで本研究では、文章読解時の視線認識情報データと音声発話コーパスの二種類を用いて様々な訓練と評価の組み合わせを作り、BERT のファインチューニングにより文章中におけるポーズの適切な挿入箇所を予測した。その結果とデータを比較することで、話し言葉と読解では大きくポーズの挿入パターンが異なることや、各データ内でも個人差やポーズの性質差があり、異なる非均衡パターンを生んでいるとの示唆を得た。
P1-15,性格特性用語におけるビッグファイブ構造の単語分散表現を用いた検討,鶴田健介|久野雅樹,,P1:ポスター,性格の心理学的研究におけるビッグファイブとは、人間の性格が 5 つの主要な特性因子によって表されるという考え方であり、性格構造のモデルとして有力なものである。本研究では、自然言語処理を活用し性格特性用語をビッグファイブに基づいて分類することを目的とする。日本語と英語の性格特性用語を単語分散表現に変換し、機械学習による分類を行ったところ、性格特性用語からビッグファイブの構造が抽出された。ただし日本語と英語とでビッグファイブの構造には違いがあることが確認できた。また各因子の分類性能においても差異が認められた。
P1-16,ArgVantage: the New Pedagogical System to Learn Argumentation,◊CaméliaGuerraoui|PaulReisert|NaoyaInoue|WenzhiWang|ShoichiNaito|JungminChoi|IrfanRobbani|KentaroInui,,P1:ポスター,"Argumentation in education can help students developtheir critical thinking, and computational models for argu-mentation have been developed to further assist this pro-cess. While existing argumentative systems have provenbeneﬁcial, existing works have emphasized a need for moreDetailed, Visual, Interactive, and Personalized (DVIP)feedback. In response, we introduce ArgVantage, an open-source web application designed to enhance users’ argu-mentation skills. By integrating the DVIP dimensions,ArgVantage aims to provide a comprehensive and interac-tive learning experience. This paper navigates through thedesign and implementation of ArgVantage, highlightingthe rationale behind its integration of the DVIP principleand discussing feasible evaluation methods."
P1-17,生成AIを用いた鹿児島方言生成―日琉諸語の低資源言語・方言の生成に向けた試み―,坂井美日,,P1:ポスター,本稿では GPT-4 をベースに、低資源方言のひとつである鹿児島方言の生成を試みる。一般に低資源言語・方言の生成は困難であり、鹿児島方言についても zero-shot では精度 0%である。本稿では、方言のテキストと辞書を標準日本語と対訳の形で整備し、更にその体系の言語知識をプロンプトに入力することで、精度を向上させられるということを示す。また、当方言については、言語知識を仮名ベースの分析を示す方が精度を向上させた。本稿の提案手法による精度は、現時点で 85%以上である。
P1-18,日本語と英語の歌詞における性差のテキスト分類を用いた検討,木田菜月|久野雅樹,,P1:ポスター,本研究では，歌手の性差による歌詞の違いに注目し，その違いを明らかにするためにニューラルネットワークモデルで日本語の歌詞を学習、歌詞から歌手の性別予測を行うテキスト分類を行い，その性能から性別による差異の実態を明らかにした．また，性別予測の際に算出される予測値を観察することで，性差による特徴や歌手ごとの違いが明らかになった．さらに，英語詞の楽曲でも同様に性差によるテキスト分類を行い，日本語歌詞での結果と比較すると違いが見られた．
P1-19,大規模言語モデルへの刈り込みによる精神疾患の思考障害シミュレーション,直江大河|原田宥都|前田ありさ|森田早織|中村啓信|大関洋平|沖村宰,,P1:ポスター,精神疾患の病態は、生物学的知見の集積にも関わらず未解決な点が多い．近年、精神疾患の脳変調の仮説と精神症状の関係を数理モデルで繋げ、理論的示唆を与える計算論的精神医学が注目されている．本研究は、脳の過剰なシナプス刈り込みが精神疾患の病態と関係するという仮説を、大規模言語モデルへの刈り込み（Pruning）に対応づけた障害実験で検証した．刈り込みをしたモデルでの統合失調症の思考障害様の言語出力を、臨床評価尺度と埋め込み表現を用いた定量分析で明らかにした.失語症様や語用論障害様の出力も認めた．ヒトの脳と大規模言語モデルの対応は慎重に考えるべきだが、本研究は精神医学に重要な理論的示唆を与える．
P1-20,単語ベクトルに基づく新たな meaning-frequency law の検証,永田亮|田中久美子,,P1:ポスター,本稿では，meaning-frequency law として知られる単語頻度と語義数に関する法則を従来とは全く異なるアプローチで検証し，従来より多様な種類の単語について同法則が成り立つことを示す．また，その過程で，同法則を通じて，言語モデル（具体的にはBERT）の能力差を計測できることを示す．
P1-21,日本語医療テキスト平易化の評価用データセットの構築,堀口航輝|梶原智之|荒瀬由紀|二宮崇,,P1:ポスター,"本研究では、医療用語を患者が理解しやすい表現に言い換える医療テキスト平易化のための日本語の言語資源を構築し、公開する。患者の闘病ブログから抽出した 1, 425 文に対して、病名や症状に関する表現に対応する医療用語をアノテーションし、医療テキスト平易化のための評価用パラレルコーパスを構築する。また、訓練用パラレルコーパスが存在しない本タスクに取り組むために、他のドメインにおける日本語テキスト平易化モデルを援用しつつ、指定した表現を避ける出力文のリランキング手法を提案する。評価実験の結果、提案手法が医療テキスト平易化の性能改善に貢献することを確認できた。"
P1-22,日本語における医療用語の難易度辞書の半自動構築,杉原壮一郎|梶原智之|二宮崇|若宮翔子|荒牧英治,,P1:ポスター,本研究では，日本語における医療用語の難易度辞書を構築する．医療従事者と患者のコミュニケーションを円滑化するために，難解な専門用語を平易に言い換える医療テキスト平易化の研究が英語を中心に進められている．しかし，日本語では本タスクのための言語資源が充分に整備されていない．そこで我々はまず，20 代から 50 代までのアノテータ 40人を対象に，日本語の医療用語 1 万語の難易度を調査した．そして，アノテーション結果に基づき医療用語の難易度推定器を訓練し，万病辞書に含まれる全 37 万語の難易度を自動推定した．本稿では，難易度調査および難易度推定の結果を報告する．
P1-23,YOASOBI楽曲に関する考察,池田盛那|◊西口純代,,P1:ポスター,YOASOBI の特徴をほかの要素と比べて明らかにして、なぜ今有名なのか考察したい。例えばもし自分が曲を作って YouTube に投稿するとして、どんなポイントを押さえれば人気になりやすくなるのかのヒントになる論文というイメージである。
P1-24,日本語終助詞「ね」と「よ」で受け手の印象はどう変わるか,木山幸子,,P1:ポスター,本研究は、日本語母語話者が終助詞「ね」「よ」から受ける印象について、複数の形容詞対で刺激に対する印象を測定する意味微分（semantic differential:SD）法による調査に基づいて検討した。総じて終助詞をつけた文の印象評価は、終助詞のない文に比べ、形容詞対の肯定方向に推移していた。「よ」と「ね」の比較では、概ね「ね」より「よ」に対して強い肯定的評価が認められた。各終助詞をつけた文の印象評価データの因子分析では、先行研究で一貫して認められている評価、活動、力動の 3 因子を支持する解が得られた。「よ」と「ね」の使用は、受け手に肯定的な印象を与える助けになっているようだ。
P1-25,Non-autoregressive Pre-trained Sequence-to-Sequence Modeling with BERT-NAR-BERT,◊MohammadGolamSohrab|MasakiAsada|MatissRikters|MakotoMiwa,,P1:ポスター,"We introduce BERT-NAR-BERT (BnB)– a pre-trainednon-autoregressive sequence-to-sequence model, whichemploys BERT as the backbone for the encoder and de-coder for natural language generation tasks in general andbiomedical domains. We adopt length classiﬁcation andconnectionist temporal classiﬁcation models to control theoutput length of BnB. Evaluation results on language un-derstanding, abstractive summarization, question genera-tion, machine translation and biomedical text summariza-tion show substantial improvements in inference speed(∼10x) with a slight deﬁciency in output quality com-pared to our autoregressive baseline. Code is releasedon GitHub1）under the Apache 2.0 License."
P1-26,単一トークン適応による大規模言語モデルに基づく文埋め込み,趙開顔|呉奇宇|苗中濤|呉梓隆|鶴岡慶雅,,P1:ポスター,文埋め込み学習では、対照学習に基づいたエンコーダのみのモデルが広く使われている。一方、大規模言語モデル(LLM)は様々なタスクで有効性が示されているにもかかわらず、LLM を文埋め込みの生成に利用する方法はまだ確立していない。本研究では、LLM の学習済みの知識や生成能力を維持しつつ、文全体の情報を捉えることができ、唯一の更新可能な特殊トークンである< 𝑡2𝑒> を導入する新しいアプローチを提案する。文類似度タスクの実験結果から、単一の特殊トークン< 𝑡2𝑒> を更新することで、本手法は他の微調整されたモデルと近い結果を達成できることが示された。
P1-27,Oblique and verb word order relates to speakers' thought patterns,TerumasaEhara,,P1:ポスター,"The  author  has  quantitatively  investigated  therelationship  between  the  word  order  of  languages  and speakers' thought patterns. In this paper, it will be focused on oblique (X) and verb (V) word order feature (X:V). There are not many languages for which the word order feature values for X:V was revealed. So, I first expand thefeature values for X:V using the Universal DependencyDatabase. After  expansion, correlation  coefficients between nine word order features including X:V and four quantitative metrics reflecting thought patterns (thought pattern metrics) are calculated. Results show that X:V has significant  correlations  with  all  four  thought  pattern metrics, although  object (O) and  verb (V) word  order feature (O:V), which is  considered  the  most  important word order feature, has significant correlations with only two thought pattern metrics."
A2-1,大規模言語モデルは自身の Hallucination を検知できるか?,門谷宙|西田光甫|西田京介|齋藤邦子,,A2:LLM分析評価(1),大規模言語モデルは，流暢で説得力のある応答を生成できるが，hallucination を引き起こすことがある．本研究では，大規模言語モデルが自身のhallucination を検知できるか検討する．hallucination検知をある文の真偽判定タスクとして定式化し，LLM の hallucination 検知性能を測るフレームワークを提案する．また，LLM のパラメータから上手く知識を引き出すために Chain-of-Thought を用いる真偽判定手法も提案する．実験の結果，GPT-3.5 Turbo は自身の hallucination を 58.2%検知することができ，検知率は LLM のパラメータに内包されている知識量に関係することが明らかになった．
A2-2,大規模言語モデルにおける日本語ゼロ照応解析能力の分析,野末慎之介|石月由紀子|松林優一郎|坂口慶祐,,A2:LLM分析評価(1),GPT-4 に代表される大規模言語モデルは言語処理の様々な下流タスクで好成績を収めることが明らかになっているが，その能力が真に言語の基礎的理解能力に由来するものであるかは明らかではない．本研究では，自然言語処理の基礎解析タスクの中でも困難なものの一つとされてきたゼロ照応解析タスクについて，大規模言語モデルの能力を評価する．実験の結果，GPT-4 はゼロ照応解析において十分な性能を発揮しないことが明らかになった．その原因を特定するための検証実験とエラー事例分析の結果から，ヲ格とニ格に関する格フレーム知識と，ニ格に関する選択選好知識の不足が原因であると示唆された．
A2-3,LLM生成コンテンツのSEO観点での品質評価,益子怜|木村賢|越仲孝文,,A2:LLM分析評価(1),"様々な分野で大規模言語モデル(LLM)の活用が進む中, Web コンテンツ制作における LLM の有用性に着目する.検索エンジン最適化(SEO)においてしばしば行われる,ユーザによるコンテンツの主観評価(ユーザ評価)のスキームにならい, LLM が生成するテキストコンテンツを定量評価する. Google 検索により収集したコンテンツにユーザ評価ラベルを付与したデータからユーザ評価予測モデルを構築し,いくつかの LLM (GPT-3.5, GPT-4, CyberAgentLM2)が生成したコンテンツの自動ユーザ評価を行った.結果,文字数が比較的少ない LLM 生成コンテンツはユーザ評価において不利であるものの, 10 段階評価で 7, 8 程度という高品質のコンテンツを生成できることを確認した."
A2-4,物語文に対する大規模言語モデルの読解能力の分析,板橋康知|松林優一郎,,A2:LLM分析評価(1),"GPT-4 に代表される大規模言語モデル（LLM）は，知的に高度な人間のための資格試験においても高い能力を示している。本研究では、LLM の心情理解能力を評価する目的で，公立高校入試の国語物語文問題における，LLM の読解能力を調査した。調査対象として，ChatGPT（GPT-3.5-turbo, GPT-4）を調査対象とし、2017 から 2023 年の物語文読解問題から 108 問の 4 択問題をランダムに選び分析した。その結果、GPT-4 はランダム選択期待値を大きく上回り、GPT-3.5-turbo はわずかに上回った。両モデルは正解した問題の解答理由やテキスト参照箇所も適切であった。分析の結果，GPT-4 は特に文章全体の表現の特徴を問う問題に強い一方で，局所的な部分を参照し読み解く問題においでは，能力の向上が求められることが分かった．"
A2-5,インタラクティブフィクションにおける大規模言語モデルの性能,BinggangZhuo|村田真樹,,A2:LLM分析評価(1),インタラクティブフィクションにおける人工知能エージェントは主に強化学習に基づいているが、近年の大規模言語モデルの急速な発展を考慮し、我々は大規模言語モデルを使用してインタラクティブフィクションタスクを解く方法を提案する。我々が選んだテストデータセットは TextWorldCommonsense (TWC)である。TWC ゲームでは、エージェントのタスクは部屋を整理し、アイテムを適切な位置に配置することであり、タスクを上手く解くにはエージェントが「どのアイテムがどの位置に属するか」という常識を持つ必要がある。提案手法の性能をテストした結果、大規模言語モデルは微調整を受けずに、トレーニングセットで学習された強化学習ベースラインと同等ぐらいの性能を持っていることが分かる。具体的には、GPT4.0 one-shotは Easy および Medium レベルの総計 10 個の TWCゲームですべてのタスクを完璧に遂行し、Hard レベルのゲームでは、提案手法（スコアは 0.52）は性能の一番良いベースライン（0.57）に負けたが、この差はプロンプトの改良によって補われる可能性がある。
A2-6,大規模言語モデルに対する語彙置換継続事前学習の有効性の検証,野崎雄太|中島大|佐藤諒|伊藤真也|近藤宏|麻場直喜|川村晋太郎,,A2:LLM分析評価(1),英語モデルに日本語データを継続事前学習することによって日本語性能を高めるというアプローチにおいて，最も重要な課題の１つに日本語に最適化されていないトークナイザーによる学習効率の低下が挙げられる．トークナイザーの語彙拡張など様々な対策手法があるが，モデルパラメータの増大という副作用もある．そこで本研究ではトークナイザーの語彙拡張をせずに，既存モデルの埋め込みを活用することによって学習効率と精度を高める手法，語彙置換継続事前学習を提案する．検証の結果，語彙拡張と同等の精度が確認された．
B2-1,双対学習機械翻訳モデルのドメインシフトに対する頑健性の検証,加藤龍兵|秋葉友良|塚田元,,B2:機械翻訳(2),近年，Transformer ベースモデルがニューラル機械翻訳（NMT）の分野で盛んに研究されている．一般に Transformer は単方向翻訳を行うように学習されるが，翻訳問題には逆方向の翻訳問題が必ず存在する．単一モデルで双方向の翻訳を行うモデルには Dualformer がある．Dualformer は両方向の Transformer ベースモデルのデコーダ部を組み合わせたモデルである．実験では，ドメインの内外問わず独英および日英の両言語対で Dualformer がTransformer の性能を超える結果となった．この結果は，Dualformer が言語対にかかわらずドメインシフトに頑健なモデルであることを示している．
B2-2,Optimal Transport for Document Alignment based on Overlapping Fixed-Length Segments,XiaotianWang|TakehitoUtsuro|MasaakiNagata,,B2:機械翻訳(2),"To acquire large-scale parallel corpora for NLP taskssuch as Neural Machine Translation, web crawling hasemerged as a popular methodology. When aligning withdocuments in various languages obtained through webcrawling, the Sentence Movers’ Distance (SMD)[1, 2]based on Optimal Transport (OT) has shown promisingperformance. However, we observed that compared to theSMD method using original web-crawled sentences, SMDbased on overlapping ﬁxed-length segments results in a sig-niﬁcant improvement. Simultaneously, we conducted ac-curacy and speed comparisons of this approach with otherconventional methods, and proposed a novel approach uti-lizing multiple feature vectors to represent documents."
B2-3,疑似参照訳文ベクトルの重心に基づく高速なニューラル最小ベイズリスク復号,出口祥之|坂井優介|上垣外英剛|渡辺太郎,,B2:機械翻訳(2),翻訳品質の人手評価スコアを予測する COMET モデルを用いた最小ベイズリスク復号法の COMET-MBR が，従来のビーム探索等を用いた最大事後確率復号と比較して，翻訳品質の人手評価における最高性能を達成している．しかし，典型的な最小ベイズリスク復号では，ある仮説文のベイズリスクは全仮説文との間のスコアの期待値計算によって求められるため，翻訳仮説の文数を𝑁 とするとO(𝑁2)の計算時間を要する．本研究では，COMET-MBR の復号速度を改善するため，COMET モデルが計算する翻訳候補集合の文ベクトルをクラスタリングし，各クラスタの重心表現を用いてスコアを計算することで，期待値計算を近似する．WMT’22 翻訳タスクの英↔ 日，英↔ 独，英↔ 中の 6 言語方向の翻訳実験を行ったところ，従来の MBR 復号より，同等のCOMET スコアを維持しながら，ベイズリスクの計算時間が 13.6 倍，うち期待値計算が 26.2 倍高速化することを確認した．
B2-4,対訳データを用いた継続事前訓練による大規模言語モデルの翻訳精度評価,近藤海夏斗|宇津呂武仁|森下睦|永田昌明,,B2:機械翻訳(2),大規模言語モデルが，多くの自然言語処理タスクで成果を収めている．しかし，パラメーター数が100 億前後の大規模言語モデルでは，既存手法である Encoder-Decoder モデルより，翻訳精度が大きく劣ることが報告されている．そこで本論文では，対訳データを用いた継続事前訓練を提案する．対訳データで大規模言語モデルを継続事前訓練した後，少量の人手データで Supervised Fine-Tuning し，WMT22のテストデータをはじめとする 12 種のテストセットで評価した．その結果，提案手法を適用したモデルは，対訳データで訓練された Encoder-Decoder モデルより BLEU・COMET の両方で統計的に有意な差が示された．
B2-5,ニューラル機械翻訳モデルにおける構成的汎化能力の評価,九門涼真|松岡大樹|谷中瞳,,B2:機械翻訳(2),構成性は，複合的な表現の意味がその部分の意味と全体の構造をもとに定まるという言語の性質である．ニューラルモデルの構成的汎化能力の評価は主に上流タスクで行われており，機械翻訳のような下流タスクにおける評価は十分でなく，特に文の構造に関する汎化についての研究は少ない．そこで本研究では，様々な種類の構成的汎化能力を問う翻訳データセットを構築し，機械翻訳タスクにおけるニューラルモデルの構成的汎化能力を評価する．結果から，ニューラルモデルの構成的汎化能力には改善の余地があることを明らかにした．
B2-6,NMTでの学習データの単語数制約による翻訳精度の向上,細川楓|村上仁一,,B2:機械翻訳(2),ニューラルネットワーク翻訳 (Neural MachineTranslation：以下，NMT) に関する研究はこれまでに多数行われている [1]．しかし，極端に単語数の多いテスト文の翻訳は困難である．この原因として，学習文とテスト文の単語数の差に着目した．機械翻訳を回帰分析と考えると，入力に対して学習文を基に出力の予測を行っている．そのため，学習データ中に入力と同じ単語数の学習文が多いほど，より正確な出力の予測ができると考えた．本論文では，テスト文の単語数と学習文の単語数を揃えて機械翻訳を行う．そして，テスト文に対する学習文の単語数による影響を調査する．実験の結果，提案手法による翻訳精度の向上が確認できた．
C2-1,汎用言語モデルを用いた効率的な類似特許検索,山本隼輔|加藤康聡|綱川隆司,,C2:特許・論文解析,本研究では汎用言語モデルを使用した教師なしの類似特許検索手法を提案する。予め絞り込んだ類似特許候補の中から、特許明細書中の「請求項」同士のテキスト間の BERTScore による類似度を用いて検索を行う。また、検索性能向上のため汎用言語モデルを分野ごとにファインチューニングする。評価実験において TFIDF による類似文書検索手法と比較し、提案手法の効果を確認した。
C2-2,IPCと要約文を用いた特許Encoderと教師なし分類手法の提案,東将己|内海祥雅|中田和秀,,C2:特許・論文解析,特許には，その特許の技術分野を表す IPC（国際特許分類）が付与されている．しかし，この分類は粒度は荒いため，企業が経営戦略の立案に利用するには，その企業が行っているビジネス・技術分野を踏まえた特許分類の方が望ましい．そのため本研究では企業独自の詳細な特許分類を機械学習を用いて行う．１つ目として，特許の IPC と要約文を入力とした特許 Encoder からなる教師あり学習を行い，さらに IPC の表現力を高めるために，IPC と要約文の関連性を利用した事前学習法と組み合わせる手法を提案する．２つ目として，アノテーションを行わず一般的な特許文書データのみを用いた教師なし学習を行い，その結果を利用して企業独自の特許分類を行う手法を提案する．
C2-3,引用文脈の類似度に基づく局所的引用論文推薦の改良,田中陸斗|杉山弘晃|平博順|桒原龍生|堂坂浩二,,C2:特許・論文解析,科学技術論文の数が急増する現代において，関連論文の効率的な推薦が重要になっている．本研究では，科学技術論文の関連研究の章を執筆する際，引用すべき個所が明示された場合，その周囲の文に基づいて適切な引用論文を推薦する局所的引用論文推薦タスクに焦点を当てる．我々は，これまで，対象論文の引用文脈と既存論文の引用文脈の類似度を活用して引用論文を推薦するという引用文脈参照法を提案してきた．この方法には，未引用の論文に対応できないという問題が存在する．本論文では，この問題に対処するために，引用文脈参照法と従来のタイトル・要旨参照の新たな組み合わせ方を提案する．大規模なデータセットを使った評価実験の結果，２つの手法の新たな組み合わせ方により論文推薦の性能が向上することが示された．
C2-4,論文の文献リストにおける研究データ引用の検出,生駒流季|松原茂樹,,C2:特許・論文解析,オープンサイエンスの機運の高まりとともに，研究データに関する情報を集約した研究データリポジトリの構築が進められている．しかし，その構築には多大な時間と労力を要する．本論文では，研究データリポジトリの自動構築に向けて，学術論文の参考文献リストから，研究データとして引用されている文献を検出する手法を提案する．引用されている文献の内容に言及する文字列を特定し，その周辺のテキストも用いて，研究データを検出するモデルを学習する．実験により，本手法の有効性を確認した．
C2-5,推薦理由提示のためのアブストラクトの観点に基づく学術論文推薦,小林恵大|QiYang|成松宏美|南泰浩,,C2:特許・論文解析,学術論文数の急増によって研究者の論文調査の負担が増大し，論文推薦システムの重要性が高まっている．本稿では，類似する論文リストだけでなく，要旨の観点に着目した推薦理由も提示する推薦手法を提案する．従来手法は，クエリの論文と推薦候補論文群との類似性を文章全体の内容で判断しており，どの点で類似するかを説明することは困難であった．本稿では，要旨中の各文を背景，手法，結果の観点に分類し，Transformer Encoder を用いて観点の埋め込み表現を生成し，観点ごとに類似度を算出することで観点の類似性を根拠として論文推薦を行う．観点に基づく論文推薦タスクのベンチマークデータ CSFCube を用いて提案手法を評価した結果，従来手法を超える精度を示した．
C2-6,数式識別子の文書内曖昧性の解消,朝倉卓人|宮尾祐介,,C2:特許・論文解析,数式識別子の文書内曖昧性解消は、自然言語中の数式理解を実現する上で重要である。文書をまたいだ数式識別子の曖昧性解消については一定の進展が得られてきたが、文書内曖昧性は十分に研究されないまま残されてきた。本研究では、どのような情報が文書内曖昧性解消に必要であるのかを明らかにする。我々は文書内の位置データと数式識別子周辺の数式内ローカル構造が特に有効であると結論付けた。構築した多層パーセプトロンモデルは、人間アノテータに近い精度（一致率 85%、カッパ値 0.73）で文書内曖昧性解消を実現する。また、重要な情報種は対象文書の科学分野に依存しないことを確認した。
D2-1,フランス語動詞補語の下位分類と組合せ範疇文法による漸進的解析,高橋直人|竹内泉|一杉裕志,,D2:形式言語学,本稿では，組合せ範疇文法を用いたフランス語二重補語構文の解析に関して考察する．文法的に正しい文のみを受理し，非文法的な文を排除するためには，補語にどのような下位分類が必要か分析し，更にそのような二重補語構文を人間同様に文頭から１語ずつ漸進的・逐次的に解析するための統語範疇および意味表示を提案する．
D2-2,言語学的に妥当な日本語 CCG ツリーバンクの構築と評価,富田朝|谷中瞳|戸次大介,,D2:形式言語学,"日本語 CCG パーザが日本語を正しく分析するためには、パーザの学習・評価に用いられる日本語 CCG ツリーバンクの言語学的妥当性を向上させる必要がある。しかし、既存の日本語 CCG ツリーバンクである日本語 CCGbank には誤った分析が含まれていることが指摘されており、日本語 CCG ツリーバンクの新たな構築アルゴリズムが提案されている。本研究では、CCG ツリーバンクを構築するアルゴリズムを実装し、特に複合動詞を含む文に対して正しい統語構造を出力できるようにアルゴリズムを改良した。さらに、13,653 文からなる日本語 CCGツリーバンクである lightblue CCGbank を構築し、ツリーバンクの統語構造と意味表示に対して、人手で評価を行った。"
D2-3,Autoformalization に向けた自然言語証明構造の形式化,服部清志|松崎拓也|藤原誠,,D2:形式言語学,数学証明の自動形式化は数学論文の内容検証やシステムの安全性保証のために有用な技術である。しかし、現在主流である大規模言語モデル(LLM)を用いた手法の精度は高校・学部レベルの数学を内容とする形式化のベンチマークに対しても 50%程度に留まっている。本研究では証明の議論構造の解析を中心とした、自動形式化を実現するための新たなプロセスを示し、各段階の実現のための提案を行う。また、大学初年級レベルの解析学の教科書に掲載されている証明の形式化を行い、矛盾の導出に関わる表現など、自動形式化における課題を分析する。
D2-4,依存型意味論によるモダリティと照応の統一的分析に向けて,飯村葵|戸次大介,,D2:形式言語学,本研究は，依存型理論に基づく自然言語の意味論である依存型意味論により，様相(modality)の分析を試みる．依存型意味論は，照応などの複雑な言語現象を扱うことができる理論だが，モダリティとの関係に着目する研究は，ほとんどなされていない．本論文が対象とする Modal Subordination は，モダリティと照応が相互作用する言語現象であり，両者を同時に分析可能な体系が必要となる．そこで，依存型意味論を様相型で拡張した Modal DTS を提案し，この枠組みの中で分析を与える．
D2-5,証明論的アプローチを用いた整合性判定による照応解析手法の提案,小斉平ひな|高橋優太|戸次大介,,D2:形式言語学,"近年の意味解析における照応解析 では，語の間の 意味 的類 似度 を用 いて 照応 表現 (apaphoricexpression)の先行詞を同定するといった深層学習・機械学習によるアプローチが主流となっている．一方，依存型意味論(Dependent Type Semantics, DTS)は，依存型理論による自然言語の意味論の一つであり，特に照応(anaphora)と前提(presupposition)はDTS が説明できる意味現象の中枢となっている．この論文では，DTS の未指定型(underspeciﬁed types)を用いて照応表現の可能な先行詞を全て探索し，その前後の文脈から照応が可能な先行詞のうちどの対象が整合性が取れているかを判定する手法を提案する．また，提案する手法が，どれだけの照応解析の問題を解くことができるかを評価する．"
D2-6,主節と関係節におけるWeak Crossover現象の非構造的要因を制御した経験的検証,福島遥|DanielPlesniak|戸次大介,,D2:形式言語学,主節における Weak Crossover 現象と関係節における Weak Crossover 現象は，どちらも容認可能性判断について様々な主張が存在する．本研究では，Language Faculty Science (LFS)の方法論を使用して各被験者の容認可能性判断に注目した実験を行い，主節における Weak Crossover 現象と関係節におけるWeak Crossover 現象について特定の解釈に対し制約があるかを調査した．そして，この実験の結果は，主節においては特定の解釈に対し制約があるが，関係節においてはそのような制約はないことを示している．
E2-1,テキスト生成による議論マイニング,川原田将之|平尾努|内田渉|永田昌明,,E2:データ生成,本研究では，テキスト生成により議論マイニングを行う手法を提案する．この手法では，議論構造を表すアノテーション付きテキストを生成し，生成したテキストから議論構造を抽出することで議論マイニングを行う．エンコーダ・デコーダモデルを採用し，議論マイニングのモデル構造をシンプルにすることで，従来手法の課題であったハイパーパラメータの調整や複雑な後処理を大幅に簡易化することができる．実験の結果，ベンチマークデータセットに対して，世界最高性能を達成したことを報告する．
E2-2,修辞構造に基づき言語モデルを制御するテキスト生成手法,横川悠香|石垣達也|宮尾祐介|高村大也|小林一郎,,E2:データ生成,本研究では，言語モデルによるテキスト生成に，修辞構造に基づく制御を加える手法の提案を行う．分類器を用いて言語モデルを制御する手法を適用し，言語モデルに修辞構造を取り入れた既存の手法と比較する．評価の対象として幅広い対象者を持つテキストを用い，精度に加えて文を接続する単語の観点から評価を行い，精度向上を確認した．
E2-3,嘘がなく、面白いクイズの自動生成,島田克行|折原良平|森岡慎太|市川尚志,,E2:データ生成,本研究では、教育的効果や題材に対する興味の喚起を目的とした、回答モチベーションを高める早押しクイズ生成をテーマとした情報推薦に取り組む。具体的には、情報源からクイズ問題文に採用する情報を選定するプロセスを、人の手で作問されたクイズを教師データとした機械学習に基づく推薦システムにより再現する。また、 訓練 した 推薦 システムの 出力 を用 いてChatGPT による問題文生成を行い、その「嘘のなさ」「面白さ」を評価する。
E2-4,大規模言語モデルによる症例報告の構造的要約,八幡早紀子|清丸寛一|FeiCheng|黒橋禎夫|佐藤寿彦|永井良三,,E2:データ生成,われわれは医学的知見の共有を促進する基盤システムの構築を目的として、症例報告の中から重要な情報を抽出し、それらの関係を構造化するタスク、構造的要約に取り組んでいる。本稿では、大規模言語モデル（Large Language Model; LLM）が関係抽出タスクにおいて高い性能を達成していることを背景に、症例報告の構造的要約における LLM の有効性を検証する。実験の結果、ファインチューニングした LLM が既存手法と同程度の性能を達成することを確認した。
E2-5,新聞記事からの都々逸生成のための訓練データの作成手法と生成アルゴリズムの改良,高昕|小坂想太朗|佐山龍之介|松崎拓也,,E2:データ生成,新聞記事を入力とし，記事の内容を要約する都々逸を出力する齊藤ら[?]の手法の改良を試みた．具体的には，訓練データとなる都々逸の作成数を従来より増やし，候補の絞り込みを TF-IDF，BERT の回帰モデルを使用し改良した．また，生成アルゴリズムの制約を追加し，単語の重複を排除するように改良を行った．結果として，大幅な都々逸候補数の増加と生成する都々逸の質の向上に成功した．1）
E2-6,物語を対象とした登場人物の関係図抽出,内野太智|DanushkaBollegala|NaiwalaP.Chandrasiri,,E2:データ生成,本研究では，小説の物語テキストから登場人物を抽出し，人物関係図を作成するシステムを提案する．小説を選ぶ際に，作成した人物関係図を使用することで，小説を読まなくても内容の全体像の概要を把握でき，好みの内容の小説だけ選択できる．また，物語の進行を忘れた場合にも，それまでの物語の全体像を把握でき，読書の再開を手助けする．本システムで，少しでも読書をする際のストレスになりうる要因を無くすことを目指す．詳細な手法としては，物語テキストから人名を抽出し，登場人物リストを作成した後，GPT-2 を使用して代名詞を最も適切な単語に置き換え，関係性を出力し関係図を作成した．定量評価の結果，代名詞の変換を行った関係図の方が正解率が高いという結果となった．
P2-1,クラスタリングによる自由記述回答の要約と選択肢回答空間に射影による解答群間の連関の可視化,根本颯汰|藤本一男,,P2:ポスター,本研究では，非階層型クラスタリングによって自由記述回答を「要約」，それを構造化データ解析（MCA/SDA）の手法で生成された選択肢回答空間に射影し，この二つの回答群の連関を幾何学的に可視化する手法を開発した.本研究では，自由記述回答を非階層型クラスタリングによって分類し，そのクラスタ番号を，選択肢回答のデータフレームに接続し，多重対応分析における追加変数として処理した.この処理によって，選択肢回答によって生成された変数/個体空間上にクラスタ番号として「要約」された自由記述回答をプロットすることが可能になる.こうして，自由記述部分の分析条件が拡大することを示した.
P2-2,STaMP: 個人の性格や政治的立場等の多面的特性と紐づくSNS データの構築及び文章スタイルによる個人特性予測,福畠汐音|仲田明良|佐橋優人|増川哲太|三輪洋文|野中尚人|木下翔太郎|岸本泰士郎|五十嵐彰|岡久太郎|狩野芳伸,,P2:ポスター,言語は人と人のコミュニケーションにおける重要なツールであると同時に，その表現には性別・年齢・学歴・政治的立場・性格特性などの個人特性が表出すると考えられる．本研究では，そうした個人を形成する特性とその個人が作成したテキストとの関係を明らかにすべく，日本語 SNS ユーザを対象に，1 千人規模のクラウドソーシングによる個人特性に関連したアンケート調査を行い，STaMP データセットを構築した．また，独自に構築した文章スタイルのベクトル表現を獲得した言語モデルを用いて文章からの個人特性の予測を行い，個人特性と文章の関係に関する分析及び考察を行った．このような個人特性と SNS 上のテキストを紐づけたデータはこれまで存在せず，オンラインテキストに現れるユーザ行動を形づくる要素の解明に貢献すると期待される．
P2-3,絵文字の量を制御可能な絵文字自動挿入,冨田龍平|田村晃裕|加藤恒夫|藤田杏樹,,P2:ポスター,本研究では，絵文字の量を制御可能な絵文字挿入手法を提案する．従来の絵文字挿入手法は，1 つの絵文字を挿入することを前提としている．しかし実際には，複数の絵文字が使われることが多々ある．そこで本研究では，指定された絵文字割合（文中の文字数に対する絵文字数の割合）に基づき絵文字を自動挿入する手法を提案する．提案手法は，まず，BERT により絵文字の挿入位置と各位置における絵文字数を推定する．その後，RNN により挿入する絵文字系列を生成することで，文中の複数箇所に複数絵文字の挿入を可能とする．X から作成したデータを用いた実験の結果，F 値は低い値であったが，人手による主観評価では，人が行った絵文字挿入よりも好ましい挿入ができることを確認した．
P2-4,自由会話のトピックモデルに基づいた軽度認知障害の検出,長江勇樹|岡田智哉|入部百合絵|横井克典|中村昭範|北岡教英|勝野雅央,,P2:ポスター,先行研究では，話題が限定されたタスク型音声を用いて認知症傾向を検出していることが多い．本研究では，複数の認知機能検査および画像検査から専門医が診断した診断結果と雑談対話音声を用いて研究を行う．また，認知症検出の新たな特徴量として話題の類似度を提案する．話題の類似度と複数の言語特徴量に Kruskal Wallis 検定を施し，特徴量選択とデータ拡張を行った上で，アルツハイマー型認知症者(AD)，軽度認知症者(MCI)，健常者(HC)の 3群間を分類した．その結果，形容詞総発話数割合と対話間のトピックの類似度の分散に有意差が確認された．また，認知症の分類は Accuracy 0.658，Recall0.7200 の精度を得た．
P2-5,言語モデルによる心理的構成概念の再構成,藤澤逸平|山田祐樹|川北源二|濱田太陽,,P2:ポスター,"言語モデルを活用し,学術的研究を加速させる取り組みが行われている.心理学では,言語モデルが特定の被験者群の回答を模倣できるか,またモデル自身の心理学的バイアスを検証する研究が行われている.これらの出力を言語モデルが可能な理由の一つとして,言語モデルが概念間の関係性を学習している可能性がある.本研究では、GPT-4 を含む言語モデルによって,質問項目から概念のカテゴリー分類の再構成が可能かどうかを検証した.複数の言語モデルを用いて心理学的質問紙の項目間の類似度を計算し,概念のカテゴリー分類性能を比較した.実験結果は、GPT-4 が最も高い分類性能を示し,言語モデルが心理学的概念間の関係性を保持している可能性を示唆している."
P2-6,RAGを備えたチャットボットに自然言語処理の研究動向を聞いてみた：文書分析作業を効率化するAI アシスタント活用方法の検討,李康穎|宋疏影|TiagoRamalho,,P2:ポスター,"近年，⼤規模⾔語モデル (LLM)が急速に⼈気を集めており，これに基づくさまざまなサービス，プラットフォーム，アプリケーションが増えている．この流れの中で多くの研究者がLLMのドメイン特化,精度の向上,知識更新,計算効率化,モデルの軽量化に貢献してきたが，⼀般ユーザーや⾃然⾔語処理以外の分野の学⽣にとっては，LLMを⽤いて知識を蓄積し，作業や研究の効率を向上させる⽅法が求められている，本⽂では，これらの⽅法を今後の開発研究実践に統合することを⽬指し，⽂書分析作業の効率化に焦点を当て，実際の事例を通じて検索拡張⽣成を備えたAIアシスタントの活⽤を検討する．"
P2-7,日本のSNSにおける有害な投稿と健全な投稿の比較分析,松帆愛|彌冨仁,,P2:ポスター,本研究は，日本語 SNS 上の有害な投稿と健全な投稿を比較して分析することで，オンライン環境の理解と健全なコミュニケーション環境の促進を目指している．X（旧 Twitter）上の 100 人のユーザーから収集されたデータを用いて語彙，それらの単語の組み合わせならびにトピックの解析を行ったところ，有害な投稿はネガティブな感情や攻撃性の高いトーンが顕著で，健全な投稿はポジティブなトピックや穏やかな言葉を含む傾向があった．本解析により，有害な投稿と健全な投稿の単語やトピックの違いが明らかにされ，特に有害なトピックの一つとして「育児」が挙げられる可能性が，日本独自の文化的背景に関連して示唆された．
P2-8,計量テキスト分析のための文埋め込みによる探索的カテゴリ化,新妻巧朗|田口雄哉|田森秀明,,P2:ポスター,"本論文は,計量テキスト分析の一手法として,テキストに対する探索的なカテゴリ抽出とラベル付与に関する手法を提案する.さらに,ケーススタディとしてオープンデータに対して提案手法を適用し,その有用性を確認した.報道や市場調査の現場におけるテキスト分析では,予測ではなく洞察を得ることが目的の,仮説構築のための探索的な解析が求められている.このような場合は内容分析による手法が有効であるが,既存の手法では単語の統計情報や辞書,分類モデルの活用が中心であり,意味空間を考慮した探索的なカテゴリ分類はあまり考慮されてこなかった.そこで,文埋め込みと独立成分分析（ICA)を用いて,意味空間を俯瞰してテキストを抽象化し,オープンドメインに対して教師なしでカテゴリを付与する手法を提案する."
P2-9,テレビアニメ作品に関するSNS上の情報拡散傾向と感情の関係,石倉直樹|土屋雅稔|吉田光男,,P2:ポスター,"Twitter（現在は X）上でのテレビアニメ作品の情報拡散傾向は多様であり,その作品に関するツイートを行うユーザが増加する作品もあれば,減少していく作品もある.このように情報拡散傾向が異なる場合,ユーザの行動も異なることが予想される.そのため,本稿ではテレビアニメ作品を対象に情報拡散傾向の違いによる,ツイートに含まれる感情の違いに注目して分析を行う.最初に情報拡散傾向の種類を週間ツイートユーザ数の推移データによるクラスタリングと,平均週間ツイートユーザ数によるクラスタリングにより定義した.そして,感情分析モデルを用いて,情報拡散傾向の種類ごとにツイート内容に対して感情分析を行なった.その結果,週間ツイートユーザ数の推移傾向が上昇傾向にある場合,他の傾向よりもネガティブツイートの割合が高いなど,情報拡散傾向の違いにより,ツイートに含まれている感情にも違いが現れることを確認した."
P2-10,ソーシャルメディア上の発話の攻撃性推定と会話補助,藤原知樹|伊藤彰則|能勢隆,,P2:ポスター,"本研究の目的は,読み手や文脈によって攻撃的ともそうでないとも受け取られる可能性がある発言(グレーゾーンの発言)への自動的な対応によって,ソーシャルメディア上での円滑なコミュニケーションを促進することである.これを実現するために,グレーゾーンの発言を自動的に検出し,その発言に対する補足情報を読み手と書き手の双方に提供する会話補助手法を提案する.本稿では,グレーゾーンの発言の自動検出に向けて攻撃性推定モデルを構築する.さらに,提案手法によって読み手が感じる攻撃性を緩和できるか検証する.本実験で使用したデータセットおよび構築した攻撃性推定モデルは, https://huggingface.co/TomokiFujihara で公開中である."
P2-11,Sequential Recommendation におけるテキスト情報を活用した未知アイテムへの対処法に関する分析,深澤祐援|山口泰弘,,P2:ポスター,"Sequential Recommendation Model は履歴中に出現するアイテムの順序情報を元にして次にアクションし得るアイテムを推薦する実世界の応用に適したモデルである.このモデルは未知ユーザであっても既知アイテムで構成された履歴を持つならば推薦が可能である一方で,未知のアイテムが入力として与えられた場合そのアイテムを用いた推薦は多くの場合で困難である.本研究では,モデルの種類に依存しない手法としてテキスト情報を活用して未知アイテムの ID 埋め込みを推測する方法を検討した.実験結果からは,テキスト情報に基づく推測手法は限定的ながらも一定の効果を示した.また,類似度が高いアイテムによる置換や未知アイテムを入力履歴から除外することで推薦精度を保つことが確認された."
P2-12,商品へのカテゴリ付与誤り事例に対する修正作業支援の検討,井上翔太|稲田和明|張信鵬,,P2:ポスター,E コマースで取り扱う商品に付与されるカテゴリ情報は、商品検索をはじめとする E コマースの様々なサービスを提供する上で重要な情報である。商品の新規登録やカテゴリ構造の変更の際に、商品に対するカテゴリ情報の付与が適切かを確認する必要があるが、人手による保守のコストが大きい。一方で、商品のカテゴリを自動的に分類する研究が存在するが、E コマースで実用できるレベルの非常に高精度なモデルの構築は現実的ではないため、人手による確認が必要不可欠である。そこで本研究では、商品へのカテゴリ付与・整備作業の支援を目指して、商品とカテゴリの合致度を判定するモデルを作成し、現状のモデルの問題点や改善点について分析する。
P2-13,多様な表現を含む攻撃的テキストの自動分類,山崎慶朋|白井清昭,,P2:ポスター,テキストの攻撃性の強さを推定するモデルの学習用データセットを構築する手法を提案する．多くの人から非難を浴びている炎上ツイートに着目し，それに対する反応を攻撃的テキストとして収集する．さらに，収集されたテキストから攻撃的でないものを自動的に除外することでデータセットの品質を高める．提案手法は攻撃的キーワードを手がかりとしないため，多様な表現を含む攻撃的テキストを収集できる．実験の結果，提案手法によって構築されたデータセットから学習された攻撃性判定モデルがベースラインを上回ることを確認した．
P2-14,JTweetRoBERTa: 大規模SNS投稿テキストによる事前学習と各種タスクによる性能検証,高須遼|狩野芳伸,,P2:ポスター,"SNS 投稿は一般の書き言葉と異なり口語的かつ特有の傾向があり，書き言葉にもとづくモデルではうまく対応できない可能性がある．本研究では 6,000万件のツイートデータで事前学習モデルを作成し，JGLUE，WRIME，メンタルヘルス不調の有無のツイート 2 値分類など 8 つのタスクでファインチューンを行い評価し，既存モデルとの比較を行った．すべての評価タスクで Wikipedia および CC100 で事前学習したベースラインを上回り，大規模ツイートで事前学習した提案手法の効果を示した．また，ほとんどの評価で多言語ツイート事前学習モデルTwHIN-BERT をも上回り，提案手法は日本語 SNS 投稿を対象とするタスクにおいて世界最高の性能であると考えられる．"
P2-15,マイクロブログの再発するトレンドを予測する,赤崎智|山下達雄,,P2:ポスター,我々はマイクロブログにおけるトレンドを日々認識し，最新情報へのキャッチアップを行なっている．これらのトレンドの中には，新しく発生するもののほか，既に発生したものが再度盛り上がる例がある．そこで本稿では，マイクロブログにおけるトレンドの再発を予測するというタスクに取り組む．我々は，マイクロブログである X の過去のトレンドで 2 回以上発生したものを正例，それ以外のものを負例としてデータセットを構築し，どのようなトレンドが再発するかを分析する．予測モデルは，トレンドに含まれるポスト及びユーザプロフィールなどのテキスト情報と，トレンドの勢いなどの時系列情報を用いて再発を予測する．実験では，提案手法がトレンドの勢いのみを特徴量として用いた手法よりも高精度で予測ができることを示す．
P2-16,Eコマースにおけるユーザー行動ログと大規模言語モデルを活用したクエリ拡張のための辞書作成,浅野孝平|稲田和明|張信鵬,,P2:ポスター,情報検索において，ユーザーの意図をより正しく捉え，適切な検索結果に改善する方法の 1 つとしてクエリ拡張が知られている．クエリ拡張の実現には人手で整備された辞書をはじめとする言語資源が必要だが，特定の E コマースなどの専門性の高いドメインで利用可能な言語資源は一般に公開されておらず，また人手での作成コストが高い．本研究では，E コマースの商品検索サービスのログデータにおけるユーザー行動の類似度に基づいて，言語資源のための候補データを抽出し，大規模言語モデルを用いて言語的な類似度の評価を行うことで，クエリ拡張のための高精度な言語資源を作成する．
P2-17,SNSの煽り投稿における受け手の属性に着目した分類,富田真生|村井源,,P2:ポスター,近年，SNS におけるトラブルが問題となっている．要因はいくつか存在するが，その一つに「煽り」が存在する.しかし，SNS における「煽り」の詳細な定義付けはされておらず，正確な検出は実現されていない.また，煽り表現の分類を行った研究も存在するが，特徴の分析が十分ではない．そこで，本研究では，SNS における「煽り」の精度の高い検出を実現するために，先行研究をもとに話者が想定しているまたは，対象となりうる煽りの受け手の属性に着目して統計的・言語的な分析を行った．得られた結果は，SNS における「煽り」の受け手に関する特徴と，その他の要素との関係性に関する特徴を示しており，煽り表現の分類に有用であると考えられる．
P2-18,Style SimSCE: SNSユーザ同一性に基づく対照学習によるスタイル類似性を捉えた文ベクトルの獲得,仲田明良|狩野芳伸,,P2:ポスター,自然言語には，意味的内容だけでなくどのように表現するかという書き手特有のスタイルが含まれる．X（旧：Twitter）をはじめとする SNS では特にその傾向が強く，ユーザの投稿文におけるスタイルはユーザ自身の個性や社会的背景を反映しており，多種多様であると考えられる．本研究では，同一アカウントの投稿が大量に取得可能なことに着目し，投稿文ペアが同じユーザが書いたものか異なるユーザのものかユーザ同一性に基づいた対照学習を用いて，SNS 投稿文のスタイル類似性を捉えた文ベクトルを学習させることを提案する．この手法によって得られる文ベクトルは，単純なコサイン類似度の比較のみで高精度に同一ユーザによる投稿文かを識別することを可能にする．さらに人手評価により，提案手法の出力する文ベクトルの類似度は既存の文埋め込みモデルよりもスタイルの近さを反映していることを示した．
P2-19,Effectiveness of Multi-task Training for Prediction of Helpfulness of Online Movie Reviews,◊CheWang|TakuyaMatsuzaki,,P2:ポスター,"This study examined the eectiveness of a multi-tasklearning for classifying review helpfulness, sentiment po-larity, and ratio of sentences expressing positive sentimentin online movie reviews from IMDb. Employing a BERT-based model, the research demonstrates that integratingthese tasks enhances model accuracy more eectively thanhandling them independently."
P2-20,Robust Neural Machine Translation for Abugidas by Glyph Perturbation,◊HourKaing|ChenchenDing|HaiyueSong|JiannanMao|HidekiTanaka|MasaoUtiyama,,P2:ポスター,"Neural machine translation (NMT) systems are vulnerable when trained on limited data. This is a common scenario in low-resource tasks in the real world. To increase robustness, researchers intently added realistic noise in the training phase. Noise simulation using text perturbation has been proven to be efficient in writing systems that use Latin letters. In this study, we further explore perturbation techniques on more complex abugida writing systems, for which the visual similarity of complex glyphs is considered to capture the essential nature of these writing systems. Besides the generated noise, we investigated three training approaches such as subword regularization, adversarial training, and consistency training. Finally, we propose to combine them to maximize the translation performance. We conducted experiments on six languages: Bengali, Hindi, Myanmar, Khmer, Lao, and Thai. Our training approach obtained the best performance for five languages."
P2-21,ファッションブランドのSNS投稿における絵文字の使用頻度と特徴,西村綾夏|山崎由佳,,P2:ポスター,本研究では、ファッション小売チェーン「アダストリア」系列の 20 ブランドが運営するX（旧 Twitter）の投稿データをもとに、（RQ1）どの ブラ ンド にお いて絵文字の使用頻度が高いのか、（RQ2）どの よう な絵文字の使用頻度が高いのかを調査した。その結果、（RQ1）絵文 字の 使用 頻度 には ブラ ンド のタ ーゲ ット年齢層、価格帯、世界観が影響している可能性があること、（ RQ2）ブラ ンド によ って 絵文 字の バリ エーションに差があり、（ⅰ）突出してよく用いられる絵文字、（ⅱ）とくに頻度の高いカテゴリ、（ⅲ）ブランドごとの特色があることが明らかになった。
P2-22,認知症病因物質がもたらす会話内容への影響分析と発症前アルツハイマー病の予測,岡田智哉|入部百合絵|北岡教英|横井克典|勝野雅央,,P2:ポスター,アルツハイマー型認知症(AD)の早期発見を目的とした研究の多くは，神経細胞死が起こり始めた軽度認知症を早期段階としている．しかし，神経細胞が死後に回復しないことを考えると，原因物質の蓄積が認められるプレクリニカル AD 期での予測が必要である．そのプレクリニカル AD の診断には侵襲性を有する高価な検査が必要である．本研究では，雑談対話音声を用いてプレクリニカル AD を識別した．BERT や RoBERTa を特徴量抽出器として用い，AD の識別に有用な言語特徴量と組み合わせた識別器を構築することで， F 値 0.8，Recall 1.0 を得ることができ，雑談対話音声からのプレクリニカル AD早期予測への応用が期待できる．
P2-23,翻訳とBabelNetを利用した日本語の語義曖昧性解消,NaranbuuveiGanbat|浅田宗磨|古宮嘉那子,,P2:ポスター,本研究では、BabelNet の synset ID を語義ラベルに用いて日本語の語義曖昧性解消を行う。語義曖昧性解消では、あらかじめ正解ラベルとなる辞書の項目が与えられる。日本語では、分類語彙表の分類番号を利用することが多いが、多言語を扱うためには、BabelNet の多言語共通の synset ID を利用する必要がある。そこで、本研究では BabelNet の synsetID を語義ラベルに用いて、英語の語義つきコーパスから訓練した WSD モデルと、機械翻訳によって英語から和訳された語義つきデータで WSD モデルを学習し、それらを日本語のテストデータで評価して、比較と分析を行った。結果として、英語から学習したモデルが日本語のモデルより性能が高いことが分かった。また、日英のハイブリッドモデルを三つ提案した。
P2-24,方言コーパスを用いた感情分析モデルの構築と炎上・ネットいじめ検知手法の提案,加藤大造|Le-MinhNguyen,,P2:ポスター,インターネット上でユーザーが自らの感情や考えを自由に，かつ簡単に投稿できるようになってから久しい．また，ネット上での会話は日常生活の一部に組み込まれている．これらの投稿は主に口語で投稿されるため，ユーザーの居住地や出身地の方言が含まれていると推察される．本研究では，方言を含む文章は書き手の感情を強く反映している，と仮定し，SNS に投稿された方言を含むテキストデータを用いて DialectBERT モデルを構築した．このモデルは，感情分析や炎上・ネットいじめの発生検知に優れた結果を示した．
P2-25,大規模言語モデルを用いた傷害事件の関連法律予測,中下咲帆|藤後英哲|菊池英明|藤倉将平|則竹理宇,,P2:ポスター,大規模言語モデル（以下，LLM）の発達に伴い，高度な知識を必要とする法的な業務の自動化が期待されている．本研究では，特に法律相談場面に注目し，法的な相談に回答するための関連法律予測に取り組んだ．法的な相談事例と関連法律のデータセットを用いて GPT-3.5 をファインチューニングした結果，提案モデルの F1Score が GPT-4 に比べて僅差で下回った．また分析の結果，刑法 208 条の予測においてはベースラインを上回る正答数を示した一方，刑法 204 条についてはベースラインの正答数を下回った．学習時に使用したデータセットやハイパーパラメータの影響により，提案モデルが過学習を起こしている可能性が示唆された.
P2-26,LLMを用いた文脈考慮による攻撃性検出性能の改善,中野雄斗|佐藤志貴|赤間怜奈,,P2:ポスター,本稿では，長期文脈を扱える最新の大規模言語モデルは，SNS 投稿の攻撃性検出において適切な文脈考慮が可能か検証する.そのために，検出対象の投稿単体で攻撃性を評価するベースラインモデルと対話履歴を考慮して攻撃性を評価するモデルの比較実験を行った．実験の結果，対話履歴が特に必要とされる攻撃性を含まない投稿の検出に関しては，人手による検出と同様の傾向を示すなど，適切な文脈考慮ができている可能性があることがわかった．一方で，本来攻撃性のある投稿まで攻撃性が無くなったと誤った判断をしてしまうという課題が残った．
P2-27,L2日本語学習者によるエッセイ評価：語彙的多様性と文法的複雑性に焦点を置いて,小畑文佳|田川拓海|小野雄一,,P2:ポスター,本研究は，日本語学習者のエッセイ評価において，言語的特徴量に基づく新しい指標の有効性について検討を試みたものである.従来，日本語のエッセイにおける言語的特徴量の研究は，主に語彙的多様性に関するものが多かったが，日本語学習者を対象とした研究は十分ではなかった.本研究では，日本語解析器 KWJA を使用して，用言及び体言の句単位の指標を分析し，これらが構造的複雑性の一側面を示すことを示した.特に，1 文あたりの用言の割合（Yougen_rate）が日本語学習者の言語習熟度と強く関連していることが，線形回帰モデル，決定木分析，ランダムフォレストモデルによって示された.この結果は，用言の使用頻度が日本語学習者の言語能力，特に複雑な文構造の生成能力と密接に関連していることを明らかにしている.
A3-1,NoisyICL: A Little Noise in Model Parameters Can Calibrate In-context Learning,◊趙羽風|坂井吉弘|井之上直也,,A3:LLM分析評価(2),"In-Context Learning (ICL), where language modelslearn tasks in a generative form from few-shot demonstra-tions without parameter update, is emerging while scalingup the language models. Nevertheless, the performance ofICL is still unsatisfactory. Some previous studies suggestedthat it is due to under-calibration and they ﬁne-tuned lan-guage models for better ICL performance with enormousdatasets and computing costs. In this paper, we proposeNoisyICL, simply perturbing the model parameters by ran-dom noises to strive for a calibration. Our experimentson 2 models and 7 downstream task datasets show thatNoisyICL helps per form ICL better. Our fur ther analysisindicates that NoisyICL can enable the model to providemore fair predictions, with less unfaithful conﬁdence. So,NoisyICL can be considered as an eﬀective calibration."
A3-2,日本語LLM構築におけるコーパスクリーニングの網羅的評価,新里顕大|高瀬翔|清野舜|李凌寒|加藤卓也|水本智也|小林滉河|佐藤潤一|柴田知秀,,A3:LLM分析評価(2),本稿では日本語 LLM の事前学習用のコーパスをクリーニングすることがモデルの性能向上に有効であることを示す．評価実験として，クリーニングの条件を変え 1.3B パラメータの日本語 LLM を学習し，複数の質問応答タスクおよび事後学習後の自由記述質問応答における性能を比較した．その結果，計算資源が比較的限られている場合（250B トークンの学習）では，クリーニングによりモデルの性能が向上し，計算資源が十分な場合（1T トークンの学習）では，クリーニングにより性能維持，タスクによっては性能向上することを確認した．
A3-3,汎用言語モデルは日本語学習者データに基づく語彙難易度を予測できるのか,梁震|彭悦|笹尾洋介,,A3:LLM分析評価(2),日本語学習における語彙習得の重要性を踏まえ，本研究では汎用言語モデル GPT-4を用いて日本語の語彙難易度を分析した.具体的には，GPT-4 に語同士の難易度関係を出してもらい，その結果を基に機械学習で語彙難易度を算出する方法を採用した.検証には，中国語母語話者にとっての日本語語彙難易度が判明している語を用いて，本稿の手法で語彙の難易度を推定した.その結果，既存の調査結果の 99%信頼区間内に収まるデータの割合は71%と比較的高く，従来の手法よりも迅速かつ広範囲にわたる難易度評価が可能となった.この研究により，日本語教育における効果的な教材開発や教授法の改善に寄与する可能性が示された.
A3-4,LLM による合成文脈データを用いた表のエンティティリンキング,大嶋悠司|進藤裕之|寺西裕紀|大内啓樹|渡辺太郎,,A3:LLM分析評価(2),論文の表には実験結果などの重要な情報が含まれるため，表を解析して知識ベースと紐づけるエンティティリンキングは有用な技術と期待されている．このタスクでは表のセルを読解して，それが指す知識ベースのエンティティと紐づけるには，幅広い文脈理解が必要になる．しかしながら，論文の本文からセルの文脈を適切に抽出する必要があるという課題があった．本研究では，大規模言語モデルを活用し，セルの文脈を生成する合成文脈を提案する．このアプローチにより，既存手法よりリンキング精度が 5 ポイント以上向上することを実証した．また，合成文脈は場合によって論文には記述されていない補助知識も補完されることを明らかにした．
A3-5,固有表現抽出における大規模言語モデルのLoRAファインチューニングの学習設定の調査,鬼頭泰清|牧野晃平|三輪誠|佐々木裕,,A3:LLM分析評価(2),大規模言語モデルを低コストでファインチューニングする LoRA と呼ばれるファインチューニング手法が注目を集めている．一方で，LLM の固有表現抽出(NER)に対する性能は低く，未だ BERT を用いた最先端モデルの性能に追いついていない．本研究では，生命医学分野の NER に有効な LLM の LoRAを用いたファインチューニングの学習設定を調査した．結果として，最先端モデルの性能を上回る結果は得られなかったが，(1)プロンプトが不要であること，(2)タグ付けによる NER が高性能であること，(3)学習可能な全ての層に LoRA を適用することで少ない学習パラメタ数でも Full Fine-tuning と同等の性能を達成することを明らかにした．
A3-6,LLM はユーザーに適したテキストの難易度を暗黙的に考慮しているのか？,郷原聖士|上垣外英剛|渡辺太郎,,A3:LLM分析評価(2),学生の理解度向上には、個人の学習レベルに適した教育が必要である。また、言語学習などの指導では、教員は各学生の理解度の把握が重要である。ただし、教員が全学生に個別指導を行うのは時間的な制約から困難である。解決策として、大規模言語モデル（LLM）で学生の質問応答をサポートする方法が考えられる。LLM は、幅広い分野への回答が可能なため、LLM を活用した細かな指導の自動化が期待される。しかし、LLM が指導者の代わりに質問応答できるとして、細かな指導の限界は未知である。そこで本研究では、教育分野での LLM の活用を促進するために文章の難易度に焦点を当てて、LLM が持つユーザへの暗黙的な難易度調整能力を調査する。
B3-1,中間言語を利用したデータ多様化とアンサンブル学習に基づくゼロリソース機械翻訳,BuiTuanThanh|秋葉友良|塚田元,,B3:機械翻訳(3),本研究では、対訳データのない（ゼロリソース）言語対のニューラル機械翻訳システムを対象として、中間言語を介して擬似対訳データを構築する手法を提案する。提案手法はソース言語・中間言語と中間言語・ターゲット言語の２つの対訳コーパスを利用し、多様性のあるかつ品質の高いソース・ターゲットの擬似対訳データを構築する。本稿では、中間言語の単言語データを利用することの効果も調べる。実験では、４つの翻訳タスクを用い、提案手法が有効であることを示した。ピボット翻訳手法と比較すると、翻訳性能(BLEU スコア)は+1.27〜+6.09向上した。
B3-2,Estimating Japanese Essay Grading Scores with Large Language Models,◊OkgethengBoago|KoichiTakeuchi,,B3:機械翻訳(3),"In Natural Language Processing (NLP), the role of LargeLanguage Models (LLMs) has been transformative, partic-ularly in automatic essay scoring. However, their applica-tion for Japanese essay scoring remains under-researched.This study investigates the eﬀectiveness of the Open-CalmLLM family in grading Japanese essays, using a datasetof about 300 essays annotated by native Japanese educa-tors, spanning four thematic categories with three types ofprompts.Our evaluation focused on two key metr ics: QuadraticWeighted Kappa (QWK) and accuracy. The results high-lighted the Open-Calm Large model as the standout per-former, achieving an accuracy of 59% and a QWK scoreof 0.52. In contrast, the Open-Calm Small model showedlower eﬃcacy, with 54% accuracy and a QWK of 0.32.Notably, essays from the ’Global’ category received thehighest accuracy rate of 63%. Performance also variedacross diﬀerent prompts, with Prompt 1 showing the high-est accuracy at 62%, while Prompt 3 lagged at 50%.These ﬁndings demonstrate the signiﬁcant potential ofLLMs in automated Japanese essay grading, emphasizingthe importance of model choice based on essay type andcategory. This study contributes to the understanding ofLLMs in educational assessment tools, showcasing theirpromising application in diverse linguistic contexts."
B3-3,Non-literal Neural Machine Translation by Exploiting Non-literal Bitext,◊LianhaoYu|NaokiYoshinaga|MasatoNeishi|YumaTsuta,,B3:機械翻訳(3),"To avoid unnatural-sounding translations produced byexisting neural machine translation (NMT) systems, wepropose training an NMT model for non-literal translationsby exploiting possibly non-literal translations in trainingdata. Speciﬁcally, we split the training bitext into two setsin terms of non-literalness and applied domain adaptationtechniques to acquire an NMT model adapted to non-literaltranslations. Our best-performing model achieved a BLEUscore of 25.20 and a COMET score of 0.7932 in producingnon-literal translations."
B3-4,多数決による自己回帰モデルに基づく機械翻訳,村上仁一,,B3:機械翻訳(3),ニューラルネットワーク機械翻訳（以後NMT）は，現在の機械翻訳において主流である．NMT は，encoder-decoderモデルに基づいている．このencoder-decoder モデルは，自己回帰モデル（以後 AR モデル）に極めて類似している．そこで，NMT において AR モデルを仮定し，この仮定の下で，機械翻訳システムを構築した．具体的には，従来の NMT において，AR モデルを想定して，多数決で翻訳文を選択した．また，入力文ごとに少数の類似文を用いた再学習をおこなった．その結果，少量の学習データにも関わらず，現在の google に接近した，高い翻訳性能が得られた．
B3-5,双方向翻訳モデルの相互学習におけるデータ多様化の適用,紺谷優志|秋葉友良|塚田元,,B3:機械翻訳(3),"ニューラル機械翻訳では大量の学習データが必要となるが,十分な量のデータを用意できないドメインにおいては高性能なモデルを作ることは難しい.この問題に対し,単言語コーパスで学習データを拡張する Back Translation (BT)や, BT を 2 方向のモデルで相互に繰り返す Itarative Back Translation (IBT)が提案されている.本研究では,複数のモデルによる出力文を用いた学習とアンサンブル翻訳により,通常の IBT の効果を更に向上させる手法を提案する.英日・英独コーパスの実験を通して,通常の IBT と比較して提案手法がより高い BLEU スコアを達成することを確認した."
B3-6,字幕機械翻訳における自動訳抜け検出の試みとその分析,石川隆太|須藤克仁|松島朝子|中村哲,,B3:機械翻訳(3),本研究では、英語から日本語への字幕翻訳を題材として、機械翻訳結果における訳抜けの自動検出を試み、その結果の分析を行う。字幕翻訳では字幕表示の制約により省略や言い換えを通じて訳出が短くなる傾向にあり、そうした事例を学習した機械翻訳は訳抜けをしやすく、自動訳抜け検出により翻訳後編集の効率向上が期待される。映像字幕データに対する実験では、自動訳抜け検出は一定の効果が認められるものの、字幕翻訳の特性に起因する訳抜けの過剰検出が目立ち、省略と訳抜けのトレードオフ解消の難しさが示唆される結果が得られた。
C3-1,ClipQA: 言語特徴埋め込み空間における3D画像質問応答,東慶多|EdisonMarrese-Taylor|宮尾祐介,,C3:質問応答,"近年,自然言語処理とコンピュータビジョンの融合分野では,３次元質問応答（3D-VQA）などの空間理解に関する研究が関心を集めている.本研究では既存の 3D-VQA モデル ScanQA [1]に対し, ContrastiveLanguage-Image Pretraining (CLIP)特徴量を活用した２つの改善手法―1.質問埋め込み及び物体特徴量に CLIP 特徴量を付加する手法, 2.質問応答に用いるマルチモーダルモデル（Transformer）の注意機構にCLIP 特徴量から計算したバイアスを加える手法―を提案し,その効果を検証する.実験の結果,提案手法 1., 2.ともに質問応答の精度改善に有効であり,両手法を用いることで質問応答の精度がベースモデルと比べて 5 ∼ 10%向上することを示した."
C3-2,長文生成の多面的評価:人手評価と自動評価の向上を目指して,鴨田豪|浅井明里|AnaBrassard|坂口慶祐,,C3:質問応答,"大規模言語モデル(LLM)は幅広いタスク目覚ましい成長を遂げているが，情報検索クエリに対する長文応答の評価は依然として困難である．本研究ではそのような長文生成に対して網羅的な評価基準を定め，人手評価と自動評価の質を高める．評価には4 つの軸を設け，それぞれに対し絶対評価を行う．この枠組みに従い，人間の回答と LLM が生成した回答に対して総計 3,600 件の人手評価を収集し，総合評価に最も影響を与える重要な評価軸を明らかにする．更に，従来の手法を人手評価との相関で凌駕する，LLM を利用した自動評価手法を確立する．github.com/gokamoda/LFQA-MultiAspectEval"
C3-3,日本語Natural QuestionsとBoolQの構築,植松拓也|王昊|河原大輔|柴田知秀,,C3:質問応答,"頑健な質問応答(QA)モデルの訓練、評価を行うためには、様々な QA データセットを用意する必要がある。しかし、多様な QA データセットが存在する言語は英語だけであり、日本語においては少数の基本的な QA データセットしか存在しない。本研究では、人間の情報欲求から自然発生する質問からなる Natural Questions (NQ)と BoolQ の日本語版(JNQ,JBoolQ)を構築する。構築は、検索エンジンのクエリログから日本語の自然な質問文を収集し、クラウドソーシングを利用したアノテーションによって行う。また、JNQ から 2 つのタスク、JBoolQ から 1 つのタスクを定義し、QA モデルを評価する。"
C3-4,InstructDoc: 自然言語指示に基づく視覚的文書理解,田中涼太|壱岐太一|西田京介|齋藤邦子|鈴木潤,,C3:質問応答,自然言語指示に基づいて，文書を視覚的に理解するための基盤データセットであるInstructDocを提案する．InstructDoc は 12 種類の視覚的文書理解（VDU）タスクから構成されており，多様な自然言語指示を提供した最大規模のデータセットである．さらに，大規模言語モデル(LLM)の推論能力を活用し，視覚的文書理解を行う新たなモデルを提案する．実験により，我々のモデルは自然言語指示を基に未知の VDU タスクに適応できることを示し，従来のマルチモーダル LLM の性能を凌駕することを確認した．
C3-5,JDocQA: 図表を含む日本語文書質問応答データセットによる大規模言語モデルチューニング,大南英理|栗田修平|宮西大樹|渡辺太郎,,C3:質問応答,実用的な文書にはテキストだけでなく様々な図表等が含まれる．このような文書への高精度な質問応答を実現するためには，視覚情報とテキスト情報の両方の理解が必要となる．本研究では図表を含む日本語文書をもとにして，視覚情報とテキスト情報の両方を参照する質問応答データセット JDocQA を提案し，複数の日本語大規模言語モデルや画像を入力とするモデルを使用して，データセットのベンチマーキングを行った．その結果，JDocQA を用いて大規模言語モデルのチューニングを行うことで，図表を含む日本語文書の質問応答課題の性能を向上することができた．また，文書中の情報から解答できない質問を学習することにより，モデルのハルシネーション抑制に有効であることを確認した．
C3-6,絵本を題材とするクイズの生成と評価,水上雅博|藤田早苗|小林哲生,,C3:質問応答,特定のドメインにおける知識量や理解度の確認を楽しく行うために，しばしばクイズが用いられる．クイズには高い需要がある一方で，クイズの作成は，クイズの題材となるドメインの理解だけでなく，クイズの目的や場面に応じた様々な明示的・暗示的条件を考慮する必要があり，作業のコストが高いという問題がある．本研究では絵本を題材とした子ども向けクイズの自動生成に向けて，クイズデータの人手作成，複数条件でのインストラクションの生成，LLM の追加学習を行い，インストラクションごとのクイズ生成の性能を評価することで，どのような情報がクイズ生成に有益であるか調査した．
D3-1,文字系列情報による性能への影響からニューラルモデルが有する言語的な傾向を見出せるか,黒澤友哉|谷中瞳,,D3:形態素・構文解析・固有表現,本研究では，文字系列情報を付加的に利用するニューラルモデルにおいて，文字系列情報による性能への影響度を定義し，その値がどのような言語的な傾向を反映しているかを検証する．実験では 48の言語を対象に，品詞タグ付けと依存構造解析の 2つのタスクにおいて，文字系列情報による性能への影響度を調査する．文字の数が多いほど情報量も多いことから，仮説として「文字系列情報が与える性能への影響度は，その言語の平均単語長が長いほど大きい」と立て検証する．実験の結果，ラテン文字を用いる言語において仮説を支持する値が得られた一方で，検定の結果，依存構造解析においては仮説を示すことができなかった．
D3-2,サブワード系列の変化が固有表現抽出に与える影響の調査,辻航平|平岡達也|鄭育昌|岩倉友哉,,D3:形態素・構文解析・固有表現,サブワード正則化によって，複数の分割結果を考慮することで，翻訳や文書分類タスクで精度の向上が得られている．しかし，複数のサブワード系列を用いた推論の調査はあまり行われてはいない．本稿では，固有表現抽出において，複数のサブワード系列から得られた推論結果と本来の推論結果との関係を調査した結果を報告する．結果として，サブワード分割に依らずに一致した推論結果を多く得られていた文はそうでない文よりも精度が良いことが確認でき，モデル間で比較した場合，サブワード分割に依らない推論ができているモデルほど精度が上がることが確認できた．また，固有表現抽出においてもサブワード正則化を用いた単一モデルアンサンブルにより精度を向上させる余地があることも分かった．
D3-3,木構造自己注意機構を用いた教師なし統語構造解析,成田百花|持橋大地|小林一郎,,D3:形態素・構文解析・固有表現,X (旧 Twitter)などのソーシャルメディアでは，口語に近い文体で文章が記述される傾向にある．こうした文は文法規則にとらわれない自由な文体で，構文構造について従来のルールベースの手法では解析することができない文が数多く存在する．そこで本研究では，実データの例として X コーパスを対象に，深層学習を用いて統語構造解析を行う教師なし学習モデルを提案する．提案手法では，条件付き確率場（CRF）による構文木の解析精度の向上を促すよう，Transformer の自己注意機構を入力文の統語構造を反映するように変更したエンコーダを用いる．提案モデルを用いることで，従来のモデルと比較して X コーパスにおける構文解析精度が向上することが確認された．
D3-4,系列ラベリングデータにおけるCutMIX によるデータ拡張,田村光太郎,,D3:形態素・構文解析・固有表現,"固有表現抽出モデルを構築するにあたり，訓練データとして，固有表現の位置をアノテーションする系列ラベリングデータが必要となる．しかし，データ構築の際のアノテーションでは，テキストの精読が必要となり，継続的に高品質な教師データを作成することが難しい．そのため，少量のデータを利用した効率的な学習として，テキストに対する拡張手法を適用することを試みた．ここではニューステキストにおける情報抽出タスクを題材として，画像データで利用される Mix-based の手法を適用しデータ拡張を行った．これらの拡張手法におけるデータ量やその強度での精度変化を調べ,モデルの精度向上を行った．"
D3-5,"BPEを用いたトークナイザーの性能に対する, 言語・語彙数・データセットの影響",中島大|野崎雄太|佐藤諒|麻場直喜|川村晋太郎,,D3:形態素・構文解析・固有表現,"大規模言語モデル(Large Language Model: LLM)への入出力に使われているトークナイザーについて,下流タスクから評価した研究が複数行われているものの,タスク内容やモデルの種類など議論の難しい要素が非常に多く,実際の開発では経験的な決め打ちによってトークナイザーを作成している場合が多いと推察する.そこで,本研究ではトークナイザーの定量的な指標となる,評価用テキストをトークナイズしたときの 1 トークンあたりの平均文字数(Length per Token: LPT)を複数の場合で調べた.結果として, LPT は語彙数に対していずれの言語でも log的に増加し,ただしその係数は言語特性を強く反映することが明らかとなった.また,英語に比べて日本語の場合で特に LPT がデータセットのドメインに影響を受けることが明らかとなった."
D3-6,固有表現を対象とした小説登場人物検出,大島一海|窪田智徳|小川浩平|佐藤理史,,D3:形態素・構文解析・固有表現,人間は，小説中の登場人物を容易に把握できる．この処理を機械的に行うのが，登場人物検出である．本論文では，固有表現を対象とする登場人物検出器を提案する．本システムは，3 つのモジュールから構成されており，小説テキスト中の人物を指し示す表現（人物表現）を認定し，同一人物を指し示す人物表現に同一の人物 ID を割り当てた後，小説テキスト中の人物表現の出現箇所にタグを付与する．
E3-1,深層学習モデルにおける言語特徴分布に関する研究,平野颯|上垣外英剛|渡辺太郎,,E3:言語モデル分析・計算言語学,Transformer ベースの言語モデルは、自然言語処理の幅広いタスクで活用されるようになった。モデルが行った判断の解釈のため、複数の分析方法が提案されてきた。以前の研究により、複数言語のコーパスで学習した言語モデルにおいて、言語の系統的な分布がモデル内部で学習されることが知られているが、事前学習の目的関数にそのような制約は含まれていないため特筆すべきである。本研究では、そのような分布が得られることが、言語特徴を学習できているためであると結論づけられるかどうかを、モデル表現の分布と比較することで分析する。
E3-2,時間関係に基づくテ形節の用法分類,野口咲帆|戸次大介,,E3:言語モデル分析・計算言語学,テ形節は日本語において頻出する形式である.テ形節の用法を判定できれば，テ形節と後続する節の意味関係を考慮した意味解析が可能となるが，その基礎となるのはテ形節の用法分類と，それに基づくテキストアノテーションである．日本語学においてはこれまで多様なテ形節の用法分類がなされてきた．ところが先行研究の用法分類をもとにアノテーションを試みると，一つの表現に複数の用法が当てはまってしまう，といった問題がある．そこで本研究ではアノテーションを念頭に置いたテ形節の用法分類を提案する．本研究の用法分類はテ形節と主節の時間関係を軸に行い，その中で継続動詞／瞬間動詞のテ形で形成されたテ形節が「動作の継続」／「結果残存」を表す場合に着目した分類を設けた．
E3-3,依存型意味論における暗黙的な文脈拡張による慣習的推意の分析,松岡大樹|戸次大介|谷中瞳,,E3:言語モデル分析・計算言語学,文や発話の争点とはならない補足情報のことを慣習的推意といい，これは聞き手が直接的に応答できない形で会話の文脈を更新するという特殊な性質を持つ．本稿は慣習的推意に対して依存型意味論という枠組みに基づく分析を与える．具体的には，型検査の過程で型付け文脈を拡張するような型を提案し，これにより慣習的推意に関する意味現象に対して適切な予測ができることを示す．
E3-4,長距離相互作用する文脈依存言語における相転移現象 -言語モデルの創発現象を統計力学の視点で理解する-,都地悠馬|高橋惇|横井祥|栗林樹生|上田亮|宮原英之,,E3:言語モデル分析・計算言語学,最近，大規模言語モデル(LLM)のスケーリング則や創発的な能力が報告され，LLM のメカニズムを理解する上で重要な手掛かりになることが期待されている．実は統計力学においてもこれらの概念に相当する「相転移」と呼ばれる概念が存在する．本研究では，言語モデルの性質を相転移の観点で再検討する．具体的には，長距離相互作用を持つ 1 次元イジング模型を念頭にした単純な言語モデルを構成し，統計力学的な意味での相転移現象が起きることを示す．さらに，シンボル数が増えるという統計力学モデルにはない言語モデル特有の過程に注目することで，統計力学モデルにはない現象を発見したことを報告する．
E3-5,BERTはどのように逆接の談話関係を判定しているか─Attentionと品詞を手がかりとして─,佐藤拓真|窪田愛|峯島宏次,,E3:言語モデル分析・計算言語学,本研究は、BERT が自然言語処理・計算言語学の中でも特に複雑な意味構造の把握が必要な逆接等の談話関係認識を行う際に、どのような品詞にAttention を向けているかを明らかにする。分析の結果、BERT は談話関係認識において、各品詞に満遍なく注意を向けているものの、各 layer や head はそれぞれ異なる品詞に注意を向けており、アーキテクチャにおいてそれぞれの layer や head が異なる役割を果たしているという先行研究の結果が日本語における逆接等の談話関係認識においても同様に認められることが明らかになった。
E3-6,神経科学に着想を得たシナプス刈り込みによる大規模言語モデルの原理解明,原田宥都|前田ありさ|森田早織|大関洋平,,E3:言語モデル分析・計算言語学,言語モデルが大規模化し、高度な言語能力を獲得していくにつれ、モデルの内部処理は更にブラックボックス化している。これに対して近年の言語モデルの説明性は、内部情報を直接取得し解釈するというよりはむしろ、入力プロンプトに対するモデルの振る舞いをもって担保する傾向にある。そこで本研究では、大規模言語モデルの新たな説明手法としてプルーニングを利用した方法を提案する。意図的にモデルを損傷させ、その振る舞いの変化を定量的に評価することで、モデルの内部処理についての示唆を得ることを目的とする。実験の結果、モデルをプルーニングする際には、対象とするレイヤーによってベンチマークでの性能に影響が出るかどうかが異なる可能性が示唆された。
P3-1,外国人介護職員のためのやさしい日本語を用いたオノマトペ変換辞書の自動生成手法の提案,小野愛佳|中島陽子|本間宏利|秋葉友良|プタシンスキミハウ|福田未来|桝井文人,,P3:ポスター,介護現場において，介護サービスをしたり入居者の状況を職員間で共有する際の会話や介護記録の中でオノマトペは状況やニュアンスの伝達が容易なため頻繁に使用されている．近年，外国人介護士が増加している一方，日本語を修得した外国人介護士でもオノマトペのように文化的な背景を暗示する日本語を理解するには時間を要するため，外国人介護士が日本人介護士や入居者とのコミュニケーションに苦慮している．一方，日本人介護士は，オノマトペを使わない作業指示や状況説明を外国人介護士にわかりやすく行うことに苦慮している.そこで，本研究では，やさしい日本語や母国語を用いた説明文や例文など，オノマトペの理解に有効な 5 項目の情報を自動的に収集，生成し介護に特化したオノマトペ変換辞書を自動生成する手法を提案する．本辞書は，介護方法支援システムに導入することで外国人介護士とのコミュニケーションを円滑にし，介護職員の作業効率の向上が期待できる.
P3-2,科学知識発見を目的とした特許のアノテーション,日浦隆博|吉田奈央|松井陽子|河野誠也|野中尋史|吉野幸一郎,,P3:ポスター,科学知識発見や仮説生成を行おうとする場合、その用途に特化した知識ベースと知識推論モデルが必要となる。本研究ではその第一歩として、特許文書へ科学知識発見を目的としたアノテーションを行うためのアノテーションスキーマを構築した。アノテーションスキーマの構築にあたっては、特許の非専門家でもアノテーションが可能なように文法や手がかり語に着目した定義を行った。
P3-3,事故事例文章構造化システムの構築,福岡康大|東明幸太|森辰則|伊藤拓海,,P3:ポスター,製造業の企業では現場からの問い合わせに対し、部署の担当者が過去の事故事例文書を活用し、人手で回答を作成している。しかし、企業に蓄積されているものは構造化されていないプレインテキストであるため活用が難しい。本稿では、現場利用者の情報要求に応じて、事故の流れを可視化して提示することで原因等をわかりやすく示すために、構造化を行うシステムを構築することを目的とし、「抽出」、「分類」、「共参照解決」、「並べ替え」といった 4 つのサブタスクを組み合わせて構造化を行う手法を提案する。また、それぞれのサブタスクを扱うサブシステムを構築し、各サブシステムに対する評価実験を行った。評価の結果、各サブシステムの正解率は、「抽出」システムは0.862、「分類」システムは0.577、「共参照解決」システムは 0.676、「並べ替え」システムは 0.833 であった。
P3-4,言語横断ラベル射影を用いた日本語文書レベル関係抽出データセットの構築,YoumiMa|AnWang|岡崎直観,,P3:ポスター,文書レベル関係抽出（DocRE）は文書中の全てのエンティティ組の関係を推定するタスクである．英語 DocRE の研究は活発に行われてきたが，日本語の DocRE 言語資源はまだ存在しない．本稿では，英語 DocRE 言語資源を活用しつつ，日本語 DocRE言語資源の構築を目指す．まず翻訳とラベル射影に基づいた日本語 DocRE データセットを自動構築したが，得られたデータセットが実用に耐えないことが分かった．そこで，モデルの予測に人手で修正を加える半自動構築手法を提案した．提案手法はアノテータの負担を軽減しながら，自動構築よりも高品質なデータセットを構築できることを報告する1）．
P3-5,イベントの発生条件のアノテーションと条件の予測性能評価,市村裕章|三輪誠|佐々木裕,,P3:ポスター,本論文では，イベントとそのテキスト内の条件の言及を紐付ける手法を提案する．テキストからの情報抽出では，テキスト中のイベントをあらかじめ決められたタイプに汎化して，構造化して抽出する．しかし，イベントはそのテキスト中の特定の条件において起こせるものであり，そのイベントがいつでも起こせるわけではない．本研究では，イベントが起こせる条件を明確化することを目的として，テキスト内のイベントの発生条件の言及をイベントと紐付けるアノテーションを提案する．さらに，アノテーションしたデータを用いて，テキスト内の対象のイベントに対してテキスト内の条件言及を自動検出する手法を提案・評価する．実験では日本の交通ルールのデータセットにおいて，高いアノテーション一致率を達成したが，条件の予測性能は低い結果となった．
P3-6,マッチング数制約下でのアノテーション検証割り当ての自動化,守山慧|中山功太|馬場雪乃,,P3:ポスター,自然言語処理のためのデータセット構築において，アノテーションの質と量が重要である．アノテーションの労力を軽減するために，LLM 等の機械学習モデルにアノテーションを任せる方法が考えられる．機械学習モデルによるアノテーションは正しいとは限らないため，アノテーション結果を検証する必要がある．アノテーション検証を人間のアノテータに依頼すると検証の正確性が高い代わりにコストも高い．コストを下げるために，クラウドワーカーや LLM の活用が考えられるが，検証の正確性は下がる．データに応じて異なるエージェントに検証タスクを割り当てることで，予算を有効活用したい．本研究では，エージェントごとに割り当て可能な検証タスク数に制約がある下で，自動的に検証タスクを割り当てる手法を提案する．エージェントとタスクの相性を捉えた重みを正解既知のデータから推定し，タスクの割り当てを重み付き 2 部グラフの最適化問題として定式化して解く．特に，そのエージェントのみが正解している時に重みが大きくなるようにする．実データを用いた実験で，ランダム割り当てと比較して，提案手法により正解率が改善することを確認した．
P3-7,特定の専門分野を対象とした意味役割付きデータ作成手法〜有機合成手順の抽出を例として〜,町光二郎|秋山世治|長田裕也|吉岡真治,,P3:ポスター,文書から作業手順などの詳細な情報を抽出するためには、述語の意味役割に注目した解析が役立つ。このようなタスクに活用可能な言語資源として、PropBank などの意味役割付与コーパスが提案されている。しかし、このようなコーパスは、専門分野における手順などの情報を表現するには意味役割のバリエーションが不十分である。本稿では、我々が提案した有機化学反応手順解析のための意味役割付きコーパスを紹介すると共に、特定の専門分野における意味役割付きデータ作成の方針について議論する。
P3-8,RecipeSTS: レシピのための類似性評価,山口泰弘|深澤祐援|原島純,,P3:ポスター,STS (Semantic Textual Similarity)は異なる 2 つのテキストの意味的な類似性を評価するための基本的なタスクである．レシピは自然言語で書かれる文書の一種であるものの，既存の STS データセットが対象とするテキストとは異なる性質を多く有するため，既存の STS ベンチマークで高い性能を達成するモデルがレシピデータにおいても高い性能を示すかどうかは明らかでない．本研究では日本語のレシピタイトルの意味的な類似性を評価するために新たなデータセットを作成し，学習済み言語モデルのレシピにおける性能評価を行った．
P3-9,小説発話への発話意図アノテーションのための末尾部分析の試み,夏目和子|佐藤理史,,P3:ポスター,実際の小説の発話文において、どのような発話意図がどのような文型で表現されているかを整理するためには、発話文に対して発話意図を付与する作業が必要となる。しかしながら、この作業は、発話意図のラベルセットが確定していないため、試行錯誤を伴う作業となる。我々は、発話文の末尾部（終助詞および終助詞相当句）に注目し、発話意図の付与と発話ラベルセットの整理を同時に行う方法を採用する。この方法に基づいて、「かしら」「かよ」「から」の３種類の末尾部を持つ約 400 の小説発話文に対して発話意図を付与した。
P3-10,否定アノテーション付きコーパスの統一に向けた否定スコープの自動変換,吉田朝飛|加藤芳秀|松原茂樹,,P3:ポスター,"否定スコープ認識は，否定要素の影響範囲を特定するタスクである．このタスクに利用される主要コーパス BioScope, SFU, Sherlock は，異なる基準の否定スコープアノテーションをもつ．そのため，否定スコープ認識モデルのﬁne-tuning においてこれらのコーパスを単に結合したデータを用いると，モデルの性能が低下するという問題がある．本論文では，同一の否定スコープアノテーションをもつデータを増やすために，BioScope と SFU の否定スコープを Sherlock の否定スコープへ自動変換する手法を提案する．提案手法により変換した BioScope, SFUと Sherlock を結合したデータセットを用いて否定スコープ認識モデルをﬁne-tuning することで，モデルの性能が向上することを確認した．"
P3-11,見出し意味具体化に向けた日本語ベンチマークの構築,白井穂乃|石原祥太郎,,P3:ポスター,新聞・雑誌などの記事の見出しには独特の文体があり，音声読み上げや機械翻訳の品質を低下させる懸念がある．本研究では，見出しの内容を補完し一般的な文体に変換する見出し意味具体化に焦点を当て，日本語の新聞記事 96 本を用いて，ルールベースや大規模言語モデルの性能を評価する．最初に，人手によるアノテーションを通じて，助詞の省略や略語に関する見出しと本文の文体の違いを明らかにした.次に，大規模言語モデルの性能を計測したところ，助詞の補完では人手評価で誤りがほとんど確認されないが略語の展開に関しては改善の余地があり，自動評価の検討の必要性も示唆された．
P3-12,Templates for Fallacious Arguments Towards Deeper Logical Error Comprehension,◊IrfanRobbani|PaulReisert|NaoyaInoue|SurawatPothong|CaméliaGuerraoui|WenzhiWang|ShoichiNaito|JungminChoi|KentaroInui,,P3:ポスター,"Fallacious arguments often lead to misinformation. Pre-vious studies have primarily focused on creating bench-marks for fallacy detection, neglecting the need to logicallyexplain why a fallacy is committed. To address this issue,we propose 20 templates for annotating the reasons behinda fallacy for 5 types of informal logical fallacies. Ourtemplates are designed to capture an underlying structureof fallacies by making implicit assumptions explicit. Ourpreliminary annotation study using the LOGIC dataset [1]shows substantial inter-annotator agreement, and obtaininga coverage score more than 74%, indicating the feasibilityof our templates."
P3-13,Find–the–Common: Benchmarking and Assessing Inductive Reasoning Ability on Vision-Language Models,◊YutingShi|HoujingWei|TaoJin|YufengZhao|NaoyaInoue,,P3:ポスター,"Recent advances in Instruction-ﬁne-tuned Vision and Lan-guage Models (IVLMs) have revolutionized the landscapeof integrated vision and language understanding. How-ever, Inductive Visual Reasoning—a vital skill for text-image understanding—remains underexplored due to theabsence of benchmarks. So, in this paper, we introduceFind–the–Common (FTC): a new vision and language taskfor Inductive Visual Reasoning. In this task, models arerequired to identify an answer that explains the commonattributes across visual scenes. We create a new datasetfor the FTC and assess the performance of several contem-porary approaches including implicit reasoning, symbolicreasoning, and implicit-symbolic reasoning with variousmodels. Extensive experiments show that even state-of-the-art models like GPT-4V can only archive with 48%accuracy on the FTC, for which, the FTC is a new chal-lenge for the visual reasoning research community. Ourdataset is available online."
P3-14,小説を利用した日本語日常対話コーパス構築のための台詞間の発話応答関係の判定,岩本和真|安藤一秋,,P3:ポスター,対話コーパスを構築するには，膨大なコストがかかる．この課題を解決する 1 つの方法として，小説内の台詞を利用した対話コーパスの構築が考えられる．しかし，単純に連続する台詞群を 1 会話として抽出するのみでは，1 会話に含まれる発話数が少なくなる課題がある．そこで本稿では，1 会話に含まれる発話数を増やすために，台詞と台詞の間に状況や感情などを説明する文章が存在するが，両台詞に発話応答関係が成立する場合があることに注目し，このような台詞間の発話応答関係の有無を判定する手法について検討する．
P3-15,機械翻訳向け原文編集の支援に向けた日英翻訳品質推定データセットの設計と構築,島田紗裕華|山口大地|宮田玲|藤田篤|梶原智之|佐藤理史,,P3:ポスター,"機械翻訳向けの原文編集(前編集)を支援する方法の 1 つとして、単語レベルの翻訳品質推定ラベル(OK/BAD)を原文側に表示する方法が考えられる。本研究では、そのような技術の実現に向けて品質ラベル付きデータセットを構築した。具体的には、前編集支援を目的とした品質ラベルの付与指針を定め、行政分野の日本語原文書(18 文書)と日英機械翻訳出力(2 種類)における計 2,090 文対に、人手で品質ラベルを付与した。また、構築したデータセットを用いて翻訳品質推定モデルを実装・評価することで、前編集支援における既存の自動ラベル付け手法の不十分さと現在の品質推定技術の課題を示した。"
P3-16,日本語自然言語処理リポジトリ分類データセットの構築,池田大志|樋本一晴|寺中駿人,,P3:ポスター,日本語の自然言語処理に関連する言語資源を集約し，「日本語自然言語処理リポジトリ分類データセット」を構築した．本研究では，6752 件の GitHubリポジトリに対して，日本語の自然言語処理に関連するか否かの二値の分類ラベルを付与した．本データセットのタスク難易度を評価するために，テキスト分類による実験を行った．本稿では，本データセットの構築方法，テキスト分類の実験結果，既存研究との差分，今後の展望を述べる．本データセットは，Hugging Face1）で公開されている．
P3-17,ディスコースからみた文末表現抽出,ホドシチェクボル|阿辺川武|仁科喜久子|ベケシュアンドレイ,,P3:ポスター,"本稿では日本語非母語話者の論文作成支援のために学術論文の構造，特に接続表現と文末表現がディスコースマーカーとして重要な役割を果たすことに着目する．まず，学術論文 14 件に対して文末表現と思われる文字列を人手でアノテーションし，接続表現，文末表現と命題との境界に関して定性分析を行った．次に 40 項目の文末表現を 10 機能別に分類し，科学技術系と人文社会系の 6,371 論文に対しパターンを定義して抽出を行い，頻度情報から論文中の文末表現分析の妥当性を検証する．"
P3-18,JEMHopQA:日本語マルチホップQAデータセットの改良,石井愛|井之上直也|鈴木久美|関根聡,,P3:ポスター,説明可能な QA システム開発のための日本語マルチホップ QA データセットを改良した JEMHopQAについて報告する．クラウドソースを用いた既存のプロセスに LLM を用いた作成プロセスを追加することでデータセットを拡張し，品質改善のため後処理におけるチェックの強化を行ったものである．後処理において除外・修正したエラー内容をあわせて報告する．
P3-19,TaCOMET: 時間を考慮したイベント常識生成モデル,村田栄樹|河原大輔,,P3:ポスター,"常識的知識は言語モデルの通常の学習では獲得されにくい.そのため,人手で常識を収集した常識知識グラフやそれらをニューラル化した常識生成モデルが構築されている.しかし,イベントを扱う既存の常識生成モデルは,粒度や時間を考慮していない.我々は時間を考慮した常識生成モデル TaCOMET を提案する.まず時間付きの常識知識グラフ TimeATOMICを構築し,これを用いて既存の常識生成モデルを継続訓練することで TaCOMET を構築する.評価実験において, TimeATOMIC や継続学習により時間を考慮した生成がなされることを確かめた.さらに,ロボットの意思決定タスクにおいて TaCOMET の応用可能性を確かめた."
P3-20,有価証券報告書を対象とした機械判読が困難な表構造の分析,奥山和樹|木村泰知,,P3:ポスター,"本研究では，機械判読が困難な表について，有価証券報告書における詳細な実態を明らかにする．分析の結果，機械判読が困難であると考えられる表は対象とした有価証券報告書に合計 3,215 件，全体の約 37 ％あることを確認した．困難な表は「小見出し行を含む表」「複数の Header や Attribute を持つ表」「空白セルを含む表」「非スカラ値のセルを含む表」「特殊な形の表」の 5 種類に分類できた．そのなかでも「複数の Header や Attribute をもつセルを含む表」「小見出し行を含む表」「空白セルを含む表」が多く存在していた．"
P3-21,妊娠・出産・育児に関する情報サイトを対象とした母親が求めている回答の特徴分析,黒沢匠|木村泰知|内田ゆず,,P3:ポスター,"本稿では,妊娠・出産・育児に関する情報サイトを対象として,ベストアンサーが付与された要因を「投稿時間」「文字数」「ベストアンサー付与理由」の観点から分析を行った.分析 1 (回答文の投稿時間)では,質問に対して初回答がよりベストアンサーに選ばれやすく,分析 2 (回答文の文字数)では,文字数がより多くなっている回答がよりベストアンサーに選ばれやすく,分析 3 (ベストアンサーの付与要因)では,回答者自身の経験に基づく内容を語っている回答がベストアンサーに選ばれやすいことがそれぞれ明らかになった."
P3-22,有価証券報告書に含まれるデータの企業間比較における課題について,佐藤栄作|木村泰知,,P3:ポスター,"本研究は,有価証券報告書に含まれるデータを企業間で比較する状況において生じる課題を明らかにした.具体的には,企業間の比較ができるデータを「要素 ID とコンテキスト ID の両者が完全一致しているデータ」と定義し,そのようなデータがTOPIX100 算出対象企業の有価証券報告書にどの程度含まれているのかを可視化した.加えて,要素 IDとコンテキスト ID が付与されていても,企業間の比較ができないケースについても考察した.また,改善策として XBRL と CSV を利用したデータセットの構想を示した."
P3-23,日経企業 ID リンキングのための類似度ベース EL システムの構築と分析,澤田悠冶|安井雄一郎|大内啓樹|渡辺太郎|石井昌之|石原祥太郎|山田剛|進藤裕之,,P3:ポスター,本研究は，日本経済新聞社の記事に登場する企業名を日経企業 DB へリンクするタスクを設計し，新聞記事中に企業名に対するリンキング性能を分析する．企業名へのリンキング性能を分析するため，新聞記事に出現する企業名と日経企業 ID を紐づけしたデータセットを作成し，事前学習済み LUKE モデルのスパン類似度学習によるリンキングシステムを構築する．作成したデータセットを用いた評価実験では，実装システムが既存システムを上回るリンキング性能を示すことを確認し，実装システムの企業ID リンキングにおける課題について整理する．
P3-24,大規模言語モデルを用いた日本語文中の並列構造の抽出,島森瑛貴,,P3:ポスター,本稿では、大規模言語モデルを用いて日本語文中の並列構造を抽出した。提示したテキスト中の並列構造を抽出するプロンプトを作成し、slack のチャットテキストを利用して評価した。オープンテストの結果、F1 値はベースラインで 0.2036、提案手法で0.3693 となり、適切なプロンプトを選択することで抽出の精度が向上することが明らかとなった。また、チャットテキストとはスタイルの異なる書き言葉のテキストについても評価し、スタイル毎の精度の変化を評価した。実験の結果、F1 値はチャットテキストで 0.3693、書き言葉で 0.2129 となった。
P3-25,Uzushio: A Distributed Huge Corpus Processor for the LLM Era,ArsenyTolmachev|MasayoshiHayashi|TakuroNiitsuma|RintaroEnomoto|HaoWang|ShuheiKurita|DaisukeKawahara|KazumaTakaoka|YoshitakaUchida,,P3:ポスター,"We introduce Uzushio — a distributed huge corpus pre-processing tool, which was used to create the Japanesepart of v2 training corpus for the LLM-jp1）project. Ituses paragraph-centric text extraction and near-duplicatedetection approaches with sampling-based deduplication.Running the detection and ﬁltering pipeline on the ABCIsystem takes approximately 10 hours for 1.4B Japanesedocuments extracted from the Common Crawl dumps."
P3-26,日本語徳倫理データセットの開発に向けて:英語データセットの翻訳と日本語データセットの比較,竹下昌志|連慎治|ジェプカラファウ|荒木健治,,P3:ポスター,本研究では AI の安全性に対処するためのデータセットとして、規範倫理学の主要な立場である徳倫理を参照したデータセットの開発を試みる。既存の英語のデータセットを日本語に翻訳したもの、またそのデータセットと同様の構築方法によって新しく日本語のデータセットを作成する。日本語の大規模言語モデル(LLM)を用いて評価実験を行ったところ、F1 スコアが 0.5 以上である LLM はなく、多くの日本語 LLM にとって道徳に関する性格用語の理解が難しいことが示唆された。また翻訳データセットと日本語で新たに作成したデータセットを比較したところ、翻訳データセットでは翻訳上困難な部分があることが示唆された。
P3-27,反論の論理パターン解析: データセット構築と実現性検証,内藤昭一|王文質|PaulReisert|井之上直也|CaméliaGuerraoui|山口健史|JungminChoi|IrfanRobbani|乾健太郎,,P3:ポスター,反論は批判的思考力を育成する有効な手段として教育の現場で用いられている．立論と反論の論理構造を精緻に解析する技術は，反論の評価やフィードバックの提供といった応用につながる可能性があるが，反論を対象とした取り組みは少ない．そこで，本研究では新たなタスク「反論の論理パターン解析」を提案する．反論が立論をどのように攻撃しているか，その要点を表した論理パターンを定義し，778 件の反論に対して論理パターンのアノテーションを行った．また，大規模言語モデルを用いてタスクの実現性を検証した結果，現行の言語モデルにとっても挑戦的なタスクであることが分かった．構築したデータセット及びアノテーションガイドラインは公開する予定である．
P3-28,日本語の日常会話における言い直し表現の検討,吉田奈央|丸山岳彦,,P3:ポスター,本稿では、日常会話の中に現れる「言い直し表現」（self-repair）に着目し、その特徴について議論を行う。会話は参与者同士のインタラクションの影響を受けながら動的に構成されていくものであり、一人の話者がインタラクションの影響を受けずに発話し続ける独話とは、発話様式としての性質が大きく異なる。我々はすでに独話における言い直し表現をモデル化しているが、このモデルを会話に適用するにはどのような拡張が必要か検討する必要がある。よって本稿では『日本語日常会話コーパス』（CEJC）に含まれる日常会話のデータを観察し、独話では見られなかった言い直しのタイプの例を調査及び分析することでその枠組みについて検討する。
A4-1,日本語論理推論ベンチマークJFLD の提案,森下皓文|山口篤季|森尾学|角掛正弥|友成光|今一修|十河泰弘,,A4:LLM分析評価(3),大規模言語モデル(LLM)はその広汎な課題解決能力が魅力を集め，日本語を含めた様々な言語で開発されてきている．しかしながら LLM は依然として論理推論を苦手としており，今後の研究が求められる．この研究を促進するため，本研究は日本語における論理推論ベンチマーク JFLD (Japanese FormalLogic Deduction)を提案する．JFLD を用いた評価の結果，日本語 LLM の論理推論能力は未だ未熟なことが分かった．なお，ベンチマーク・ベンチマーク構築用コード・LLM 評価用コードを公開する1）．
A4-2,NeuBAROCO データセットによる大規模言語モデルの推論能力の検証,森下貴允|安東里沙子|阿部裕彦|小関健太郎|峯島宏次|岡田光弘,,A4:LLM分析評価(3),この論文では、「現在の大規模言語モデルが論理推論をどれくらい正確に行うことができるのか」という問いを、特に大規模言語モデルが人間と同様の推論バイアスを示すかどうかという点に着目して探究する。論理推論として、論理学だけでなく認知科学の中で人間が自然に行う演繹推論の形式として広く研究されている三段論法に注目し、NeuBAROCOという三段論法データセットを導入する。このデータセットは、もともと三段論法を用いて人間の推論能力を評価する心理実験のために設計されたもので、英語と日本語の三段論法推論を含んでいる。現在の代表的な大規模言語モデルで実験を行った結果、現行のモデルは人間と同様の推論バイアスを示し、特に含意関係が含意でも矛盾でもない推論問題で大きな改善の余地があることが示唆された。
A4-3,LLMの出力結果に対する人間による評価分析とGPT-4による自動評価との比較分析,関根聡|小島淳嗣|貞光九月|北岸郁雄,,A4:LLM分析評価(3),本論文では、2 つの LLM の出力結果に対して「複数の人間による評価の分析」および「人間の評価とGPT-4 による自動評価結果の比較分析」を報告する。人間による評価は 5 人で行い、回答が質問に答えているかという関連性、回答内容の正確性、回答の流暢性、情報量を5 スケールで評価した上で、出力の優劣を判定した。このデータを概観し、優劣の判定がどのようになされたかについての仮説を立てた。また、この人間による評価結果と GPT-4 による評価結果は大きく食い違っていたが、その原因を突き止めた。一方の LLM は情報量が多いが正確性に欠けるものであり、もう一方が一般的なことしか書かれていないため正確性には問題が少なかったシステムであった。最初のシステムに対し、人間の評価では情報が不正確であると判断されて低い評価を受けたが、GPT-4 は正確性が判断できず「具体性があり情報量が多い」というコメントと共に高い評価を下した。GPT-4 は正確性の判断に弱いということは、評価コメント中に認められたハルシネーションからも観察され、これが判定の食い違いの大きな理由であったことが分かった。これらの分析を基に今後の LLM開発における課題を考察した。
A4-4,制約が異なる指示で生成された文章に対するLLM生成検出の頑健性,小池隆斗|金子正弘|岡崎直観,,A4:LLM分析評価(3),大規模言語モデル(Large Language Model; LLM)は，剽窃や誤情報の流布など様々な場面での悪用が懸念されており，LLM の生成文と人間が書いた文を頑健に分類する LLM 生成検出の実現は急務である．LLM の出力は生成指示に大きく依存するが，どのような指示で LLM にテキストを生成させると検出性能が変動するかは検証されていない．本研究では，文体や構造などの項目に着目し，指示によるLLM の制約項目を変えることで検出器の頑健性の評価を行う．提案手法はサンプリングや言い換えによる頑健性評価と比較して，検出性能の標準偏差を最大 14.4 ポイントに増加させた．
A4-5,語彙置換継続事前学習による日英バイリンガルモデルの構築と評価,麻場直喜|野崎雄太|中島大|佐藤諒|池田純一|伊藤真也|近藤宏|小川武士|坂井昭一朗|川村晋太郎,,A4:LLM分析評価(3),ニューラルベースの LLM (Large Language  Model)は，大量の英語データで事前学習が行われることが多い．これに英語以外の言語データで継続事前学習を行うことで，比較的少量の資源でその言語の高い性能を得ることが期待される．本稿では，オープンな LLM である事前学習済み Llama  2  13B  Chat に対して日英 2 言語データで語彙置換継続事前学習を行い，LLM ベンチマーク 2 種で性能評価した結果について報告する．トークナイザは語彙置換により日英2 言語に適応させ，カリキュラム学習により言語間の知識転移と学習効率化を図った．ベンチマーク結果より，日本語性能の向上を確認した．
B4-1,視写課題の自動採点へ向けた子供らしい文字の自動生成による OCR 精度の向上,関歩実|滕昱璇|野坂瞭太|大井淳司|松崎拓也,,B4:マルチモーダル(1),本研究では，児童による文章の視写結果の自動採点へ向けた基礎技術開発を行った．自動採点の前提として，お手本の文字列と視写結果の文字画像列を正確にアラインし，視写の誤りを検知する必要がある．そして，正確なアラインメントのためには，児童の手書き文字に対する OCR の精度を向上させることが必要である．そこで本研究では，文字のスタイル変換手法を利用して，児童の手書き文字を大量に生成し，OCR の訓練データとして利用することを試みた．結果として，大人の手書き文字のみを訓練データとした場合と比べて，児童の手書き文字の認識精度が向上し，これに伴ってお手本と視写結果のアラインメント精度も向上した1）．
B4-2,Large-scale Vision Language Modelによる芸術作品に対する説明の生成,林和樹|坂井優介|上垣外英剛|林克彦|渡辺太郎,,B4:マルチモーダル(1),Large-scale vision-language models（LVLMs)は，ユーザーから入力された画像と指示に基づき文章を生成する巨大言語モデルである．これらのモデルを画像の創作支援に利用する際には，画像の構図や工夫，他作品との比較，歴史的背景，深い芸術的な知識に基づく説明の生成が要求される．しかし LVLM が芸術作品の説明に必要な知識，及び複雑な知識間の関連をどの程度理解し，それらを統合して説明に応用できるかは，明らかにされていない．本研究では，芸術作品に関する深い知識の理解と利用を定量的に評価するための新たなタスク，データセット及び評価尺度を提案し，さらに LVLM が芸術に関する知識を伴う説明を学習するための訓練データセットも公開する．このタスクは，芸術作品の画像とタイトルからの説明生成，及び画像のみを使用した説明生成の二つで構成され，LVLM の言語に基づく知識と視覚に基づく知識の両方を評価する．検証の結果，LVLM は元の LLM と同等の言語に基づく知識を保持しているものの，視覚に基づく知識の獲得は限定的であることが判明した．
B4-3,Vision Language Modelが持つ画像批評能力の評価手法の提案,齊藤成輝|林和樹|井手佑翼|坂井優介|鈴木刀磨|郷原聖士|大西雄真|上垣外英剛|林克彦|渡辺太郎,,B4:マルチモーダル(1),Large-scale vision language models（LVLMs）は，画像を基に文章を生成する LLM である．本研究ではLVLMs の応用として，画像の良い点や悪い点を批評するタスクを考えるが，LVLMs がそのような能力をどの程度備えているのかは明らかとなっていない．そのため，本研究では LVLMs の画像批評能力を評価する手法を提案し，人間のアノテータによって付けられた批評文の優劣と LVLMs によって判断される批評文の優劣にどの程度の相関が見られるか調査した．提案手法で作られた評価用データセットに対して，一般に性能が高いとされている LVLM ほど人間との間に正の相関が見られ，評価手法として一定の妥当性が確認された．
B4-4,外国手話データセットを活用した日本手話動画からの音節構成要素認識,木全純大|三輪誠|佐々木裕|原大介,,B4:マルチモーダル(1),本研究では日本手話の「手の位置」・「手の動き」・「手型」から構成される音節構成要素を深層学習を用いて自動認識するシステムの構築において，限られた日本手話動画データから音節構成要素を高い性能で認識するため，日本手話と外国手話の言語間の共通の特徴を活かす転移学習手法を提案する．「手の位置」・「手の動き」・「手型」の認識では，マルチタスク学習を行なった．利き手における音節構成要素を対象とした実験では，原らが作成した日本手話データセットにおいて，本稿で提案する外国手話データセットを利用した転移学習が音節構成要素認識の性能向上に繋がることを明らかにした．
B4-5,Forgetful Multi-store Memory System for a Cognitive Assistive Robot,◊AngelFernandoGarciaContreras|河野誠也|川西康友|中村泰|齊藤智|吉野幸一郎,,B4:マルチモーダル(1),"Domestic robots are intended to coexist with humans,providing assistance and companionship. A key element torealize these interactions is life-long learning from their en-vironment. Even with promising progress, the state of theart remains far from realizing life-long robotic cognition,complicated by the complexity of multi-modal, ambigu-ous real-world data and the limits of storage capacity. TheGuardian Robot Project at RIKEN is developing Indy, anautonomous helper robot. In this work we present the ﬁrststep towards Indy’s long-term memory system, inspiredby two concepts from cognitive psychology: a three-storememory model, and forgetting heuristics that help retainuseful information and discard irrelevant sensor data. Weoutline the general framework of this system, and evalu-ate the impact these techniques have on the total size ofstored memory using metrics to estimate the space growthof memory and its accuracy."
C4-1,企業の環境活動における収益性の関係解析と改善案の自動生成,児玉実優|酒井浩之|永並健吾|高野海斗|中川慧,,C4:テーマセッション２：金融・経済ドメインのための言語処理(1),本研究では，環境活動について方針の記述のみの企業と実行まで記述がある企業とで業績に影響を与えるのか調べた．エネルギーや大気への排出など環境活動に関する記述項目はいくつかある．方針を記述している項目において，実行までを記述している項目数が多い企業の方が少ない企業よりも業績が良い傾向があることが分かった．しかし，実行している項目はなく方針のみの企業の業績も高い傾向であった．また，経済産業省，環境省が，ESG 関連情報を階層１:上位方針，階層２:実行，階層３:PDCA の３つの階層に応じて一貫したストーリーとして説明を行うことを求めている．このことから，数少ない階層３：PDCA までの記述がある企業の文を学習データとし，階層２で止まっている企業に対して，環境活動についての文章の改善案を ChatGPT を用いて精度良く自動生成した．
C4-2,T5を用いた技術課題・解決手段推定による特許マップ自動生成,小堀佑樹|酒井浩之|永並健吾,,C4:テーマセッション２：金融・経済ドメインのための言語処理(1),本研究では，T5 モデルを使用して特許文書から特許マップを生成するための技術課題・解決手段の端的な表現を生成する．技術課題の学習データは人手で作成し，解決手段の学習データはタイトルデータをターゲット文として機械的に作成する．推定された技術課題・解決手段のカテゴリを Word2Vec により統合することで直感的な特許マップを生成する．推定された技術課題は人手評価，解決手段はタイトルデータとの一致度合いを機械的に評価する．また，人手で作成された特許マップのカテゴリと自動生成された特許マップのカテゴリの類似度を評価する．
C4-3,Beige Bookのセンチメントとマクロ経済データを用いた米国金利変動予測,藤原真幸|中川慧|水門善之|秋田祐哉,,C4:テーマセッション２：金融・経済ドメインのための言語処理(1),本研究では、連邦公開市場委員会（FOMC）の決定に大きく影響される米国の金利変動を予測するモデルを提案し、その効果を検証した。具体的には、10 年金利・2 年金利・イールドスプレッド、の 3 種類の金利変動予測に XGBoost モデルを使用し、特徴量として FinBERT モデルから得られた Beige Book のセンチメントデータと月次マクロ経済データを組み合わせた。特に金融政策との関連が強いイールドスプレッドの予測に関しては、センチメントデータとマクロ経済データの両方を使用することで、変動予測の精度とトレーディング収益が向上した。また、連邦準備制度の Dual Mandate に基づき、物価と雇用に関するセンチメントデータを利用することで、予測精度と収益率がさらに向上することがわかった。
C4-4,投資家の情報選択に対する重みを考慮した金融推奨,高柳剛弘|村山友理|和泉潔,,C4:テーマセッション２：金融・経済ドメインのための言語処理(1),金融市場において個人投資家の目的は多岐にわたる．そのため，株式取引などの金融行動は個人投資家ごとの異質性が大きく，金融行動を予測する投資家行動予測は重要なタスクである．個人投資家は金融意思決定の際に数値情報やテキスト情報など様々な情報を参照するので，これらのプロセスを考慮することでより良い投資家行動予測につながることが期待できる．本研究では投資家の情報選択に対する重みを考慮した金融推奨モデルである PersonalizedFinancial Recommendation with InvestorsAttention andContextual Information (PFRIC)を提案する．個人投資家の取引データを用いて行なった評価実験において，提案手法の精度が既存手法の精度を上回ることを確認し，金融推奨に対して個人投資家の情報選択の選好を考慮することの有用性を示した．
C4-5,加法構成性を活用した最適輸送による文書類似度の定量化,赤松朋哉|中川慧,,C4:テーマセッション２：金融・経済ドメインのための言語処理(1),本研究は，自然言語処理の基本タスク であ るSenmantic text similarity (STS)の精度向上を目的とし，単語ベースと文章ベースの STS 手法の差異に着目する．特に，金融経済分野をはじめとする専門分野のフレーズ表現に焦点を当て，加法構成性を持つ単語埋め込みによって得られている単語の分散表現に対し，加法構成性を活用した最適輸送問題に基づく新しい文書類似度の定量化手法を提案する．
D4-1,移動軌跡解析：文章中の人物の地理的な移動を読み取る,山本和太郎|大友寛之|大内啓樹|東山翔平|寺西裕紀|進藤裕之|渡辺太郎,,D4:テーマセッション５：ことばと地理空間の情報処理(1),本研究では，計算機によって，文章中の人物の地理的な移動を読み取り，その移動軌跡を地図上に再現することをめざす．入力文章中の場所に対し，移動者の訪問状態・訪問順序を予測するタスクを定義するとともに，100 記事からなるアノテーションデータセット ATD-VSO を構築し，ベースラインモデルの学習・性能評価を行った．
D4-2,Word2Box を用いた人々の移動に基づく地域メッシュの領域表現,奥島海|廣田雅春,,D4:テーマセッション５：ことばと地理空間の情報処理(1),単語の埋め込み表現は，自然言語処理の様々なタスクで用いられている重要な技術である．また，地理情報に関する様々なタスクで，位置情報から得た地域メッシュの埋め込み表現が用いられている．本研究では，地域メッシュの埋め込み表現の作成に，Word2Box を用いることで集合演算が可能な埋め込み表現を作成する．Word2Box は，単語の意味の広がりや階層関係などを表すことが可能な BoxEmbeddings を獲得するための教師なし学習の手法である．獲得された領域表現に対して集合演算を行い，地図上に可視化した結果を分析する．
D4-3,言語情報と地理情報を融合した魅力的な経路案内,大滝啓介|吉村貴克|徳久良子,,D4:テーマセッション５：ことばと地理空間の情報処理(1),経路案内アプリを用いる際、移動時間などの客観的な指標だけではなく、経路景観の「楽しさ」や「美しさ」といった主観的な指標も用いることで、より魅力的な経路案内が実現できると考えられる。本研究では、事前に収集された経路上の景観画像、景観画像の説明文、基盤モデルを用いて魅力度スコアを計算する枠組みを構築し、経路探索に組み込むことで、魅力的な経路を案内する手法を提案する。本稿では提案手法を実装したプロトタイプについて説明し、アンケート調査を行った結果を報告した上で、今後の課題や展望について述べる。
D4-4,メンション文脈とエントリ属性を考慮した Transformer Bi-Encoder によるジオコーディング,中谷響|寺西裕紀|東山翔平|大内啓樹|渡辺太郎,,D4:テーマセッション５：ことばと地理空間の情報処理(1),ジオコーディングは，地名や施設名など，実世界の特定の場所を指す言語表現（メンション）に対し，経緯度あるいは地理データベース上のエントリを推定する基盤技術である．本研究では，類似の名前を持つエントリの曖昧性の問題に対処するため，メンションが出現する入力テキストの文脈情報および候補エントリの属性情報を捉えるジオコーディング手法を提案する．実験により，これらの情報を考慮することの有効性を確認した．
D4-5,日本語旅行記ジオパージングデータセットATD-MCL,東山翔平|大内啓樹|寺西裕紀|大友寛之|井手佑翼|山本和太郎|進藤裕之|渡辺太郎,,D4:テーマセッション５：ことばと地理空間の情報処理(1),ジオパージングは，文章中に含まれる実世界の場所に関わる情報を解析する基盤技術である．本研究では，文書レベルのジオパージングシステムの開発・評価に向けた第一歩として，日本語旅行記データセットの構築と現在のシステムの評価を行った．本データセットが，日本語ジオパージング研究の推進・高度化に貢献することを期待している．
E4-1,不法行為としての誹謗中傷検出と検出理由の説明可能性の検証,久田祥平|矢田竣太郎|若宮翔子|荒牧英治,,E4:テーマセッション３：法ドメインにおける言語処理(1),オンライン上での誹謗中傷の問題に取り組む自動検出研究において，社会実装の観点で検出理由の説明が求められている．しかし，テキスト生成により説明するアプローチは，説明の論理性に課題があり，社会科学の専門家の介在がなく人間や社会にとって有益な説明を行えているか人手評価が不十分である．本研究は，裁判例に基づく誹謗中傷データセットを用いて，不法行為の観点から，誹謗中傷の分類タスクと，その理由の生成タスクに取り組んだ．そして，生成された理由に，裁判における判断が反映されているか法律の専門家が評価した．結果として，言語モデルを用いた，裁判例に基づく分類タスクの精度には課題があることや，理由の生成では論理的整合性のある回答を得られるが，モデルの学習データセットに含まれる価値観の影響を受け，法律や裁判での判断と異なる解釈を示す事例多くが確認された．本研究は，オンライン上の誹謗中傷の自動検出の社会実装において重要な，法的観点の導入の端緒となる．本論文では，誹謗中傷の事例を扱う性質上，不快な表現が含まれることにご注意下さい．
E4-2,日本語不法行為事件データセットの構築,山田寛章|徳永健伸|小原隆太郎|得津晶|竹下啓介|角田美穂子,,E4:テーマセッション３：法ドメインにおける言語処理(1),"本研究は日本語・日本法における法的判断予測研究のためのデータセットである，日本語不法行為事件データセット(Japanese Tort-case Dataset, JTD)を提案する．JTD は不法行為判断予測タスク及びその根拠抽出タスク向けに設計されている．根拠抽出タスクは不法行為の成否判断に際して重要な根拠となった主張を，原告または被告の主張の中から抽出するタスクである．JTD には 41 人の法律専門家によって注釈付けされた 3,477 件の民事事件判決書に基づいて構築されており，7,978 事例（事例に内包される原告・被告らの主張は 59,697 事例）が収録されている．ベースライン実験により JTD の各タスクの実現可能性を確認し，さらに不法行為判断予測・根拠抽出の両タスクを同時に学習させることで性能が改善することを示した．"
E4-3,法令データの現状と法令分野へのデジタル技術適用の展望,山内匠,,E4:テーマセッション３：法ドメインにおける言語処理(1),法令は経済活動や権利義務関係に影響する重要な情報であり，言語処理技術や AI 技術を含むデジタル技術を組み合わせることによるサービス創出や政策立案の高度化が期待される．本稿では，法律，政令，府省令といった法令データの整備の経緯と現状，法令 XML や法令 API などの法令データ公開方法の技術概要，法制事務デジタル化や法令データ利活用の未来像について，デジタル庁における政策や有識者会合iにおける議論を中心に解説する．
E4-4,大規模言語モデルを用いた日本語判決書の自動要約,新保彰人|菅原裕太|山田寛章|徳永健伸,,E4:テーマセッション３：法ドメインにおける言語処理(1),日本語判決書の自動要約の需要の高まりに伴って，大規模言語モデル（LLM）によって高品質な判決書の要約文を出力することが期待されている．本研究では One-shot 文脈内学習に用いるサンプルを近傍事例検索を用いて選ぶ手法を提案する．ベースライン手法と比較し，提案手法を用いることによって判決書要約の精度が高まることを示す．
E4-5,GPTs and Language Barrier: A Cross-Lingual Legal QA Examination,◊NguyenHaThanh|山田寛章|佐藤健,,E4:テーマセッション３：法ドメインにおける言語処理(1),"In this paper, we explore the application of Genera-tive Pre-trained Transformers (GPTs) in cross-lingual le-gal Question-Answering (QA) systems using the COLIEETask 4 dataset. In the COLIEE Task 4, given a statementand a set of related legal articles that serve as context, theobjective is to determine whether the statement is legallyvalid, i.e., if it can be inferred from the provided contex-tual articles or not, which is also known as an entailmenttask. By benchmarking four diﬀerent combinations of En-glish and Japanese prompts and data, we provide valuableinsights into GPTs’ performance in multilingual legal QAscenarios, contributing to the development of more eﬃ-cient and accurate cross-lingual QA solutions in the legaldomain."
P4-1,オンライン動画サービスにおけるBERT及びGPT-3.5を用いた視聴者感情の推定,菅野祐希|坂野遼平,,P4:ポスター,近年のインターネットやスマートフォンの普及により，動画共有サービスに多くの人がアクセスするようになった．それにより動画共有サービスはビジネスやマーケティングの場としても活用されるようになった．視聴者が動画を閲覧することでどのような感情を得るかという情報は，視聴者とマーケターの両方において有益となる．本研究では過去に行った動画のコメントから視聴者の感情を推定する手法の拡張として，BERT と GPT-3.5-turbo を利用した動画視聴者の感情推定を行った．結果として，単純な感情であれば BERT が向いており，複数の感情が混在したり推定の難易度が高い感情においてはGPT-3.5-turbo が優勢となった．
P4-2,コメントフィルタリングのための感情分析を用いたコメント評価尺度の検討,笠原璃音|大和淳司,,P4:ポスター,本研究では，インターネット上でのコメント炎上やエコーチェンバー現象に対処するため，閲覧者が自らコメントを調整できるシステムを目指し，コメントフィルタリングの検討を行った．具体的には，TF-IDF と極性辞書を用いてコメントを数値化し，これを適切・不適切なコメントを分けるための尺度とした．提案した尺度の有用性を検証し，コメントの適切・不適切性を決定するコメントの特徴量を分析した．
P4-3,感情の顕現性を考慮した書き手の感情強度推定,岡留司真|白井清昭,,P4:ポスター,本論文では，書き手の感情の強さを推定する新しい手法を提案する．書き手の感情がテキストの表層にどれだけ明示的に表現されているかを感情顕現性と定義し，書き手と読み手の感情強度が付与されたデータセットからこれを推定するモデルを学習する．また，書き手の特徴を表す単純な特徴量として書き手 ID を導入する．未知の書き手に対して，それと類似した書き手を訓練データから選択し，その書き手 ID を入力として与える．感情顕現性と書き手 ID を感情強度推定モデルに組み込むことの有効性を実験により検証する．
P4-4,Xのポストデータに対するレーティング予測,森廣勇樹|南條浩輝|馬青,,P4:ポスター,本研究では，複数の深層学習モデルで X のポストデータに対するレーティング予測を行った．ポストデータは話し言葉表現に近いことに着目し，事前学習モデルとして日本語話し言葉 BERT を導入した．他のモデルとの比較の結果，日本語話し言葉 BERTを用いた場合に高いレーティング予測精度が得られた．これはポストデータ特有の話し言葉表現が適切に捉えられているためと考えられる．次に，学習データである amazon レビューデータと X のポストデータの性質（文字数とテキストスタイル）が異なることから，学習データの書き換えを検討した．具体的には，ChatGPT と要約ツールを用いて amazonレビューデータを X のポストデータに近いデータに書き換えを検討したので，その報告もあわせて行う．
P4-5,日本酒の味わい表現の分析のための程度表現の定量化,小澤奈泉|山田剛一|増田英孝,,P4:ポスター,日本語で何かを表現する際に程度表現を用いることで，より細かな度合いで表現することが可能になる．これまで日本酒の味わい表現の分析を行ってきたが，「ちょっと」「とても」などの程度表現は考慮していなかった．そこで，本研究では程度表現に着目し，それが修飾する語句の度合いをどの程度変化させるのかを定量化するために，程度表現の表す程度の範囲を問うアンケート調査を実施した．得られたデータから範囲の上限値下限値を求めることで，程度表現それぞれの表す程度の範囲を確認した．
P4-6,多言語評価極性判定における文法・語彙知識と生成モデルの統合,金山博|趙陽|大湖卓也|岩本蘭,,P4:ポスター,本研究では、生成モデルを用いた多言語の評価極性判定の際に、構文や語彙の知識に基づく評価表現抽出器と組み合わせることにより、性能の改善を図る。極性を持つ語句の情報をプロンプトに含めることによって、大規模言語モデルにとって分類が難しい言語において特に正解率の向上が見られた。
P4-7,XLM-RoBERTa を利用した実データの英日評判分析,大井恵奈|古宮嘉那子|佐々木稔,,P4:ポスター,本研 究で は，XLM-RoBERTa を用 いて，実際 に企業 に寄 せら れた レビ ュー の評 判分 析を 行う．XLM-RoBERTa を用いた二値分類タスクの手法を元に，実際に日本企業に寄せられた多くの日本語レビューと少量の英語レビューを用いて Fine-tuning を行った．英語に日本語を追加し学習したモデルと英語のみで学習したモデル，日本語に英語を追加し学習したモデルと日本語のみで学習したモデルそれぞれについて AUC と正解率を算出し考察する．
P4-8,精神障害を視野に入れたツイート行動における感情状態の検討,市村真衣|久野雅樹,,P4:ポスター,"健常と精神障害を視点として,感情という現象の構造を解析することを目指す.本稿ではツイートを分析しており,ユーザーごとに Plutchik の 8 感情の推測値を箱ひげ図でまとめたところ,感情に個人差を確認できた.また,精神障害クラスは対照クラスより投稿量が少なく,社会から解離気味であった.コロナ前とコロナ中の年月別投稿量や感情の推測値を算出すると,両クラスともにコロナ禍以前よりネガティブな感情に寄っており,感情面において精神障害クラスは現状の精神疾患以上にコロナ禍による影響が大きいと推測できた."
P4-9,短歌固有の属性に対応する脳内情報表現,佐藤杏奈|近添淳一|船井正太郎|持橋大地|小林一郎,,P4:ポスター,ヒト脳内における情動活動の理解は，脳神経科学における中心的な課題である．本研究では，情動理解の探究として言語芸術である短歌を取り上げ，文から誘起される詩的な情動が，脳内でどう表現されるのか，詩的感覚は文のどのような要素から構成されうるのかを，短歌を読んだ際の fMRI データを用いて調査する．サーチライト解析を行い脳内状態を調査した結果，文の詩的さと関連する情報は，後頭葉，ブローカ野をはじめとした大脳皮質上で広く表現され，また，詩的感覚はその文の珍しさや構造などに細分化される可能性が示唆された．
P4-10,自由記述からセルフ・コンパッションを推定することは可能か？―BERTによる心理学的構成概念の定量化―,岡野裕仁|河原大輔|野村理朗,,P4:ポスター,苦しい状況や失敗を経験したときに自分に向けられる「自分への思いやり」を、心理学ではセルフ・コンパッション(self-compassion)と呼ぶ。従来、セルフ・コンパッション等の心理過程に関わる個人差の多くは、自己報告式の質問紙尺度によって測定・定量化されてきた。本研究は、人々から回答の自由度が高い記述式テキストを収集し、質問紙スコアを予測する BERT 回帰モデルを構築した結果、自由記述から個人のセルフ・コンパッションを高精度に推定しうることを示した。自由記述テキストによる心理の定量化は、質問紙と比べて先入観やバイアスが生じにくいという利点があり、本研究の結果から、今後の研究展開が期待される。
P4-11,センチメント分析を用いた感情を重視した物語の階層的要約手法,酒井健壱|上乃聖|李晃伸,,P4:ポスター,物語におけるあらすじはストーリー全体を簡潔に要約したものであるが，同時にその作品の魅力を未読者へ十分に伝えるものであることが求められる．本研究では，物語の魅力はその登場人物の感情の発露およびその変化と強く結びつくという考えのもと，感情表現を重視した魅力ある物語のあらすじの自動生成を目指す．LLM を用いてセンチメント分析を行い文単位の感情ラベルを付与したうえで，Hierarchical merging を用いて要約を作成する．生成したあらすじの印象と正確さのそれぞれを測る実験を行い，提案法の効果を検証した結果を述べる．
P4-12,Exploring Task Decomposition for Assisting Large Language Models in Counter-argument Logical Structure Analysis,WenzhiWang|ShoichiNaito|PaulReisert|NaoyaInoue|CaméliaGuerraoui|JungminChoi|IrfanRobbani|KentaroInui,,P4:ポスター,"Counter-Argument Logical Structure Analysis(CALSA) is an intricate task that focuses on the automaticanalysis of logic patterns of a counter-argument in relationto an initial-argument. It holds signiﬁcant educationalvalue as informative feedback can be provided based onthe analyzed logic pattern. Nevertheless, the complexity ofthe reasoning skills required for logical structure analysismakes CALSA particularly challenging for current LLMs.To overcome this issue, we explore decomposing thetask into several manageable sub-tasks with a pre-deﬁneddecision tree and utilize an LLM to reason through thetree. Our experimental results highlight a remarkable im-provement in our approach over the baseline, emphasizingthe substantial eﬃcacy of our proposed method."
P4-13,大規模言語モデルによる授業改善に向けた小学校における授業の発話シミュレーション,大西朔永|児嶋祥成|椎名広光|保森智彦,,P4:ポスター,小学校の教員の授業改善については，省察活動が有効であるとされている．省察活動は自己内省的な面や時間がかかることから客観的な評価が可能でかつ短時間で評価ができるシステム化が望まれている．本研究では，熟達教員によるシミュレーションを用いた教員に対するフィードバックのシステム化を目標としている．一方，自然言語処理分野では，大規模言語モデルによって，発話生成が容易になってきている．そこで，本研究では，授業中の教員と児童の発話の収集を複数教員で実施し，LoRAでファインチューニングした教員ごとの大規模言語モデルを用いて，ある場面での発話を別の教員として，発話生成させるシミュレーションを行った．
P4-14,確信度と得点の予測精度を両立する論述回答自動採点モデル,高橋祐斗|宇都雅輝,,P4:ポスター,近年，深層学習を用いた論述回答自動採点モデルが高精度を達成し，実用化が期待されている．しかし，高性能な自動採点モデルであっても，得点予測を誤る可能性は依然として残っており，このことがハイステークス試験における自動採点導入の妨げの一つとなっている．この問題を解決する方法の一つとして，得点予測に加えて，予測した得点に対する確信度も出力できる深層学習自動採点モデルを用いて，予測誤りの検出を試みる研究がなされている．本研究では，確信度を推定可能な従来の深層学習自動採点モデルを拡張することで，確信度推定と得点予測の両面における性能向上を目指す．
P4-15,日本語小論文に対する採点およびフィードバックの生成,中本さや香|嶋田和孝|岡本芳明|中河内孝,,P4:ポスター,自動文書評価(Automated Writing Evaluation)は教育工学分野で広く研究されているテーマのひとつである．本研究では生成 AI である GPT-4 を用い，児童が書いた日本語小論文の自動採点を行う．採点基準として複数の観点を設定し，各観点について点数，その点数を与える根拠，児童へのフィードバックを生成する．GPT-4 による採点および人手による採点を行い，その比較を行った．また，GPT-4 によって生成された根拠文やフィードバックに対し，定性評価や考察を行った．その結果，GPT-4 による高品質な採点結果およびフィードバックの生成が確認され，小論文教育への活用可能性が示された．
P4-16,T5 を用いた日本語記述式答案の文字認識誤り訂正,鈴木里菜|臼井久生|尾崎太亮|NguyenTuanHung|古宮嘉那子|石岡恒憲|中川正樹,,P4:ポスター,本研究では，事前学習済みの日本語 T5 モデルを用いて，手書き答案の文字認識結果の誤り訂正を行う．文字認識の誤り訂正には，これまで N-gram を用いた手法や BERT を用いた手法が提案されてきた．本論文では，自動で手書き答案を読み取った文字認識結果に対して人手で訂正を行い，これらのペアを用いて T5 をﬁne-tuning することで，文字認識誤りの訂正モデルを作成する．今回用いた答案データは，中学生約 50 名によって回答された，国語ドリルの記述式問題の日本語手書き答案である．さらに，誤認識のパターンをより多く学習させるため，学習データのデータ拡張を行った．実験の結果，T5をﬁne-tuning することで，文字認識結果をより実際の答案に近い文章に訂正できることを示した．また，データ拡張の結果，訂正モデルの BLEU 値は向上した．
P4-17,ChatGPTの過剰回答に対する自己フィードバック機構を組み込んだ医療面接試験向け仮想模擬患者,進藤尚希|宇都雅輝,,P4:ポスター,近年，医療系学生が受験する客観的臨床能力試験における医療面接を標準化する手法の一つとして，人工知能技術に基づく仮想模擬患者が多数提案されている．しかし既存手法の多くは，ルールベースのアプローチを採用しており，回答ルールの構築などに大きな負担を要する．そこで本研究では，ChatGPT を用いて人手によるルール構築を必要としない仮想模擬患者の実現を目指す．ただし，ChatGPT は受検者の質問に対して過剰に回答する場合があるため，提案手法ではそのような過剰回答を抑制する機構を新たに導入し，試験目的に則した回答を出力させることを目指す．
P4-18,文法項目の多様性と誤り情報を利用したエッセイ自動採点,土肥康輔|須藤克仁|中村哲,,P4:ポスター,本研究では，エッセイ自動採点において文法特徴を考慮することの効果について検証した.エッセイの分散表現に加えて，学習者が正しく使えている文法項目の情報や，文法誤りの情報をモデルの入力に用いることで，モデル性能が向上した.また，文法特徴の利用に加えて，エッセイの総合スコアと文法スコアでマルチタスク学習を行うと，モデル性能がより大きく向上した.しかし，学習者が正しく使えている文法項目の情報と文法誤りの情報を組み合わせて用いても，それぞれを単独で用いたときと同等のモデル性能となり，両者を同時に用いることの相乗効果は見られなかった.
P4-19,プログラミング課題文からの重要箇所抽出,門井仁弥|南條浩輝|馬青,,P4:ポスター,本研究では BERT を用いてプログラミング課題文からの重要箇所の抽出を行った．具体的には，コード作成に必要な『入力』『出力』『条件』『繰り返し』が書かれた箇所を重要箇所とし，それらの抽出（ラベリング）を行う．複数の文が連なった課題文を対象とし，全体から重要箇所を直接ラベリングする方法と，段階的にラベリングする方法を提案する．後者は，第一段階で課題文を 1 文ずつ分類をし，第二段階でその分類情報を利用して系列ラベリングする方法である．直接ラベリングでは，出現頻度が低いラベルに対する精度（F(0.5)）が低いことがわかった．次に，段階的ラベリングを行ったところ，直接ラベリングよりも全てのラベルで F(0.5)の改善が得られた．特に，出現頻度が低いラベルに対して大きな改善が得られることがわかった．
P4-20,文法誤り訂正の包括的メタ評価: 既存自動評価の限界と大規模言語モデルの可能性,小林正宗|三田雅人|小町守,,P4:ポスター,評価尺度の評価（メタ評価）は主に人手評価との相関に基づいて行われる．しかし，従来の英語文法誤り訂正(GEC)のメタ評価は，評価粒度の不一致によるバイアスや，現在の主流システムとの乖離などの問題に直面している．これらの問題に対処するために，12 の最先端システムを対象に，2 つの評価粒度で人手評価することで，より妥当性のあるメタ評価を可能にするデータセット(SEEDA)を構築する．さらに，SEEDA を用いた包括的なメタ評価を通して，GEC における既存自動評価の現状と大規模言語モデルの評価性能を調査する．
P4-21,項目反応理論を用いた難易度調整可能な多肢選択式読解問題自動生成,富川雄斗|宇都雅輝,,P4:ポスター,近年，教育場面において難易度調整可能な読解問題自動生成が注目されている．我々は，項目反応理論を用いて学習者の能力にあった難易度の読解問題を生成する技術を開発してきた．しかし，この手法は答えが読解対象文中に存在する抽出型の問題形式を対象としており，教育現場で広く使われている多肢選択式の問題形式には対応できない．そこで，本研究では難易度調整可能な多肢選択式問題自動生成手法を開発する．また，提案手法によって生成した問題を項目反応理論に基づいて分析し，生成の性能を評価する．
P4-22,JGLUE データを用いた模範解答との差異に基づく汎用採点モデルの構築,齊藤隆浩|古宮嘉那子|石岡恒憲|中川正樹,,P4:ポスター,本研究では、日本語学習済み BERT モデルを用いて短答式記述問題の採点システムを作成した。短答式記述問題の採点に関しては、個別の問題に特化してモデルを学習した岡ら[1]の研究などがあるが、本研究では答案と模範解答の両方を入力し、それらの差異をとるようにモデルを学習することで、一度の学習で複数の設問に対応することができ、かつ限られた数の答案でも採点の正解率を高める手法を提案する。学習・評価データには中学生の国語ドリルの答案データを使用した。学習データに JGLUE:日本語理解ベンチマーク[2]のコーパスを加えたところ、国語ドリルのみで学習した場合に比べて、採点結果が大きく改善し、文ペア分類のコーパスによる学習が汎用的な採点モデルの構築に効果があることが分かった。
P4-23,自動採点技術と項目反応理論に基づくテスト等化を通じた論述式回答評価の高精度化,荒巻洸太|宇都雅輝,,P4:ポスター,論述式試験の問題として，評価結果が評価者の特性に依存してしまう点が挙げられる.この問題を解決するために，評価者の特性を考慮した項目反応理論が近年多数提案されている．他方で，現実の試験運用ではしばしば，複数の異なる受検者集団に同一の論述式問題を出題し，各集団の回答をそれぞれ異なる評価者集団が採点する場合がある．そのような評価結果に項目反応理論を適用して結果を比較するためには，等化と呼ばれる手続きが必要になる．等化を行うためには，集団間に共通する受検者や評価者が一般に必要となる．これに対し，本研究では，自動採点技術を用いて，共通受検者や共通評価者なしに等化を実現する手法を提案する．また，この方法を用いて，人間の評価者と自動採点を連携させた高精度な論述式回答評価を目指す．
P4-24,教育を目的とした日本語初等数学問題に特化した大規模言語モデルの構築,苗中濤|趙開顔|呉梓隆|呉奇宇|鶴岡慶雅,,P4:ポスター,近年、様々なオープンソース大規模言語モデルの登場に伴い、特定の領域向けの大規模言語モデルを開発することが可能になっている。しかし、日本語での初等数学教育を目的とした大規模言語モデルは未だに存在していない。本稿では、基礎的な数学問題を解き、教育に有用な推論過程が付いた答えが出力できる日本語大規模言語モデルを構築する方法について報告する。具体的には、日本語の初等数学問題データセットを構築し、Japanese Stable LM Beta7B をファインチューニングし、日本語数学専門言語モデル JElementaryMathGPT を構築した。さらに、モデルの評価方法について議論し、既存の言語モデルと性能を比較した。
P4-25,文法誤り訂正の自動評価のための原文・参照文・訂正文間のN-gram F-score,古山翔太|永田亮|高村大也|岡崎直観,,P4:ポスター,本稿では𝑛-gram の頻度に基づき𝐹 値を計算する文法誤り訂正のための自動評価尺度 GREEN を提案する。GREEN は従来の手法よりも人手評価と高い相関を示す。また、計算量が小さく高速に計算ができる。さらに、人手評価で評価が低いシステムの出力に対して従来手法が高い評価を与える場合でも、GREEN は人手評価と近い評価が可能である。
P4-26,読み情報を利用したニューラル日本語入力誤り訂正モデルの構築と評価,金本勝吉|麻生貴裕,,P4:ポスター,日本語の入力誤りは読み手にとって負担を強いたり文章の信頼性を損ねたりするため，計算処理によりその訂正を支援することが求められる．本研究では読み情報を推定させたり，読み情報も含めて訂正させたりするなど，読み情報を利用する多様な条件で Seq2Seq 形式の誤り訂正モデルを構築した．比較実験の結果，モデルに読みを推定させると精度が悪化し，別途読みを与えつつ，2 つの Decoder で原文の訂正と併せて読みの訂正を行うことで誤り訂正精度が向上した．
P4-27,大規模言語モデルによる和文英訳問題の自動採点,三浦直己|舟山弘晃|松林優一郎|岩瀬裕哉|乾健太郎,,P4:ポスター,本研究では，L2 学習においてよく用いられる和文英訳問題を対象とし，大規模言語モデル(LLM)を用いた記述式答案の自動採点手法を提案する．LLMによる few-shot の文脈内学習を行うことで，既存採点モデルの運用面での課題の解決を試みた．モデルの採点性能を測定するため，実験では，モデルの予測得点と人手の採点結果の一致率を算出した．実験の結果，LLM の採点性能は少量の学習データを用いた教師あり学習に基づく既存手法を下回った．さらにエラー分析によって，LLM が採点タスクを適切に解釈できていない可能性も示唆された．これらの結果は，現行の最先端 LLM が本タスクにおける難易度と挑戦性を有していることを明らかにした．
P4-28,An Automatic Question Generation System for High School English Education,◊TianqiWang|TeruhikoTakagi|MasanoriTakagi|AtsushiTamura,,P4:ポスター,"The multiple-choice question is a highly prevalent as-sessment tool in educational contexts, yet manual questioncreation can be a costly endeavor. In this paper, we presenta system designed to generate multiple-choice questionsfor English education. Our approach involves breakingdown the question generation process into distinct stepsand applying various techniques to each step. We explorethe enhancements in question generation eﬃciency andalso address the limitations of this system. The system’sperformance is evaluated based on feedback from humanexpert question creators."
A5-1,GPT for Extraction of Biomedical Fields from Clinical Study Texts,◊RyanAndrew|伊藤眞里|黒田正孝|高村大也|夏目やよい,,A5:知識獲得,"Generative  transformer  models  are  powerful  toolsused in a wide variety of natural language processingapplications. One  area  in  which  the  application  ofgenerative  pre-trained  transformers (GPT) hold  greatpotential  in  the  field  of  biomedical  research  is  auto-mated data curation. In this study, we utilized GPTstosystematically  extract  structured  data  from  scientificarticles within PubMed and ClinicalTrials.gov. In ourresearch  we  usedOpenAI's  GPT-3  and  GPT-4  lan-guage  modelsto  efficiently  populate  text  fields  thathave  been  pre-selected by  domain  experts  in the cor-responding biomedical fields and present the outcomesin  JSON  format. Initial  findings  suggest  that  genera-tive  transformers  such  as  GPT-3  and  GPT-4  holdpromise as potent tools for automating data curation inthe biomedical domain."
A5-2,文字起こしテキストから得た質問のタグ推定,自見仁太朗|大野正樹|橋本泰一|嶋田和孝,,A5:知識獲得,本論文では，営業員と顧客の会話の文字起こしテキストから得られた質問のタグを推定するタスクに取り組む．質問には冗長性や言い間違えを含まれるため，その内容を理解することが難しい．私たちは大規模言語モデルによって質問のトピックを推定することで，質問を簡潔な文書に変換した．さらに，質問の内容を理解することに適した単語のみをタグとして獲得した．評価では，実際の営業員と顧客の会話から得た約 1 万件の質問とオープンなモデルである Llama2 を用いた．
A5-3,大規模言語モデルによる少数かつ短文の文書に対するトピックモデリング,土井智暉|磯沼大|谷中瞳,,A5:知識獲得,"短文の文書に対するトピックモデリングは，近年研究されているニューラルトピックモデルにとっても,依然として挑戦的なタスクである．一方で，大規模言語モデルは様々なタスクで優れた性能を示しており，トピックモデリングにおいても優れた性能が期待できる．本研究では,大規模言語モデルとして GPT-3.5, GPT-4 を取り上げ,少数かつ短文の文書に対するトピックモデリングの性能を調査する.実験の結果から,大規模言語モデルは少数かつ短文の文書においては既存のトピックモデルよりも高性能であり, hallucination などの懸念についても影響は実用上無視できるほど小さいことを示す."
A5-4,文献理解のための人間の応答を利用したプロンプト最適化,今川涼平|守山慧|楊明哲|馬場雪乃,,A5:知識獲得,大規模言語モデルを利用した自然言語システムの性能は，プロンプトの設計に影響される．人間の試行錯誤に基づく従来のプロンプト設計に代わる方法としてプロンプト最適化が取り組まれている．既存のプロンプト最適化手法では，正解ラベル付きデータの利用を前提としている．代わりに，システムの出力に対する人間からのフィードバックを利用することが考えられる．本研究では，学術論文のタグ抽出システムの運用を想定し，プロンプト最適化において，人間から得られるフィードバックの有効性を調査する．実験の結果，フィードバックを利用した最適化により，再現率の向上が確認できた．一方，精度の悪化も確認され，フィードバック設計の再考の必要性などの課題も確認した．
A5-5,潜在的正規分布によるイベントの時間関係の推定,船曳日佳里|持橋大地|浅原正幸|小林一郎,,A5:知識獲得,本研究では，自然言語で表現されるイベントにおける時間的常識の推定タスクの精度向上を目的として，イベントの時間を Allen の区間代数[1]を参考に，潜在的な正規分布として捉えてイベント間の時間関係を確率的に推定する．実験の結果，ベースラインと比較して 10%以上の精度の向上を確認できた．また，正解に至らずとも正しい分布に近い分布を推定できたことも確認でき，これは時間関係認識において，確率分布を使用することの有用性を示している．
B5-1,正書法および音韻の複雑さによる音声認識の精度への影響,田口智大,,B5:マルチモーダル(2),本研究は，諸言語の正書法や音韻体系の複雑性が，個別言語の音声認識の精度にどのように影響を与えるのかを検証する．音声認識の精度に悪影響を与えうる複雑性として，書記素の数，書記素と音素の対応の不規則性，音素の数，という三つの要因を仮説として提示する．実験の結果，明らかに悪影響となりうる要因は書記素の数のみであり，その他二つの要因は精度にあまり影響を与えないことが明らかとなった．
B5-2,ラベル付き系列予測による音声シグナルの Textless 依存構造解析,神藤駿介|宮尾祐介,,B5:マルチモーダル(2),音声言語処理技術の多くは音声認識モデルとテキスト処理モデルを直列接続することで実現されるが，近年は音声認識を介さずに（=Textless に）音声表現ベクトルから直接的に学習を行う研究も盛んである．本研究ではその中でも特に依存構造解析に注目し，音声表現ベクトルを用いた Textless 構文解析の可能性を探る．提案手法は，音声表現ベクトルから依存構造を表すラベル付き系列を直接予測するTextless なアプローチを取る．直列的なアプローチを取る既存手法との比較実験の結果，Textless な依存構造解析は十分可能である一方，頻度の低い依存関係の予測においては語彙情報の寄与が大きいことが示唆された．
B5-3,SlideAVSR: 視聴覚音声認識のための論文解説動画データセット,王昊|栗田修平|清水周一郎|河原大輔,,B5:マルチモーダル(2),視聴覚音声認識(AVSR)は音声認識(ASR)をマルチモーダルに拡張したもので，音声の代わりに動画を入力として与えるタスクである．多くの研究で使用されている読唇データセットは顔追跡動画のみから構成されるため，AVSR モデルの画像理解能力を評価するには不十分だと考える．本研究では，論文解説動画を用いて，視聴覚音声認識データセットSlideAVSR を構築する．多くの専門用語が含まれ，スライドを参照しないと正確な文字起こしは困難であるため，モデルの画像理解能力をより多くの側面で評価できると考える．そして，テキスト情報を参照可能な AVSR モデル DocWhisper を提案し，SlideAVSR においてその有効性を確認した．
B5-4,Creating Heterogenous Transcription of English and Japanese on a Multilingual Audio File,◊YuikaSun,,B5:マルチモーダル(2),"Code-switching (CS) is  the  switching  betweenmultiple  languages  in  speech. Current  literature  on code-switching  transcription  technology  has  been successful  in  translating  the  CS  transcripts  into  one language but there yet to exist satisfactory technology to accurately transcribe one single speaker’s CS audio into CS transcripts. Current speech-to-text (STT) technology, although  produces  accurate  transcriptions, is  limited  to monolingual sentences. In this paper, the focus is on an unexplored area: expanding STT to English and Japanese CS  language  transcription  without  utilizing  translation software."
B5-5,環境音に対する日本語自由記述文コーパスとベンチマーク分析,岡本悠希|高道慎之介|森松亜衣|渡邊亞椰|井本桂右|山下洋一,,B5:マルチモーダル(2),音の認識合成を大規模言語モデルと接続するためのデータセットの作成が急務である．本研究では，環境音データと，その内容を日本語で自由記述した文から成るオープンコーパスを構築する．本コーパスは環境音と英語自由記述文から成る既存コーパスの日本語訳であるため，英語と日本語を対比させた評価と分析が可能である．本論文は，コーパスの設計指針を述べるとともに，そのベンチマーク結果を分析する．
C5-1,DDSTM:Spike and Slab 事前分布を用いた動的スパース・トピックモデル,増田樹|中川慧|星野崇宏,,C5:テーマセッション２：金融・経済ドメインのための言語処理(2),トピックモデルは文書生成をモデル化する自然言語処理手法の一つで，トピックと単語の分布に基づいて単語を生成する．既存の推定手法には plSAや LDA などがあるが，これらは時系列性を考慮しない．本研究では，時系列変化と分布のスパース性を同時に扱う新しいモデル，動的スパース・トピックモデル(DDSTM)を提案する．DDSTM は動的トピックモデル(DTM)を基にし，Spike and Slab Priorを事前分布として使用し，スパース性を保ちながら時系列変化をモデル化する．この手法により，トピックと単語の分布のスパース性と時系列変化を統合し，解釈性を高めることができる．実証分析では，実データを用いて提案モデルの特徴を確認する．
C5-2,ゼロショットテキスト分類によるTCFD推奨開示項目の自動判定,土井惟成|小田悠介|中久保菜穂|杉本淳,,C5:テーマセッション２：金融・経済ドメインのための言語処理(2),サステナビリティ情報開示への要請は世界的な潮流として高まっている．この動向を受け，TCFDは，気候変動に関する 11 の推奨開示項目を設定し，実際の開示に対する規範としての活用を求めている．開示情報は多様な形式で記載されるため，推奨開示項目の充足状況の調査には膨大な資料の分析が必要となり，多大なコストを要する．機械的に開示箇所の判定を行う手法により，このコストを一定程度削減できると考えられる．本稿では，TCFD 推奨開示項目の開示箇所判定のために実施した一連の施策を報告する．具体的には，各項目の自動判定のためのより基本的な単位(TCFD 推奨開示項目クライテリア)への分解と，各クライテリアに対するゼロショットテキスト分類の性能を検証した．
C5-3,有価証券報告書の活用による事業セグメント関連語の拡張,伊藤友貴|平松賢士,,C5:テーマセッション２：金融・経済ドメインのための言語処理(2),各企業は IR（Investor Relations）活動として，決算短信や有価証券報告書等を通し，機関投資家や個人投資家等へ企業の情報を開示する．IR 活動において，自社の発信内容に対する外部からの評価の把握は重要な事項である．特に事業セグメント単位での評価の把握は有用だと考えられる．このような背景のもと，本研究では，金融文書からの「事業セグメント言及文抽出手法」の開発を目指す．セグメント情報の抽出に関する既存アプローチとして，事業セグメント名の検索をベースとするアプローチがある．一方，本アプローチでは関係会社の記載やサービス名・取扱商品のみが書かれた文の抽出には対応できないという課題がある．そこで，本研究では大規模言語モデル及び有価証券報告書内の事業セグメント説明記載を利用することで検索単語を拡張し，既存アプローチを改善することを提案する．さらに，本取組みの発展として，アナリストレポートのセグメント別センチメント分析や決算短信へのアナリスト反応の生成を試みる1）．
C5-4,重要技術語を対象とした特許技術の時系列トレンド分析手法 Patent-GLIPICA の開発,井畑匠越|邊士名朝飛|河野誠也|原川良介|岩橋政宏|野中尋史,,C5:テーマセッション２：金融・経済ドメインのための言語処理(2),本研究では，特許情報に基づく技術トレン ド分析手法として，特許文書中 の重要技 術要素を抽出し，それらの時系列連動 性を分析 する手法「Patent-GLIPCA」を提案する．「Patent-GLIPCA」は特許文書構造を考慮したグラフベース手法を使用し，精度よく重要技術要素を抽出したうえで時系列連動性を分析する手法である．評価実験においては，特許文書からの重要技術語抽出およびトレンドのクラスタリング性能が比較手法よりも優れていることを示した．また，携帯電話に関する技術分野に適用したところ，ベース技術およびベース技術と異なるトレンドを持つ技術群を特定できることを確認した．
C5-5,大規模言語モデルを用いた金融テキストに対する推論ベースの極性付与,高野海斗|中川慧,,C5:テーマセッション２：金融・経済ドメインのための言語処理(2),金融テキストマイニングでは，極性付与は重要なタスクであり，大規模言語モデル(LLM)の進歩により，適用が広がっている．一方，従来の分析対象は決算短信やニュースが中心であり，極性がテキストに直接記載されている，推論が不要なタスクである．しかし，実務上の投資判断を鑑みると，直接的に極性が記載されていないテキスト情報に対して，バックグラウンドを踏まえつつ極性を推論することが求められる．そこで本研究では，LLM の推論能力を活用し，業種に関する情報を入力し，ある特定の重大イベントが当該業種に与える影響を推論させる極性付与タスクに取り組む．そして，その出力が実務的にどの程度有用であるか検証する．
D5-1,語形の分布状況のベクトル化による言語地図の分類方法,近藤泰弘|持橋大地,,D5:テーマセッション５：ことばと地理空間の情報処理(2),"本研究では,異なる語に対する「言語地図」を機械学習によって自動分類する手法を提案した.従来「言語地図」をコンピュータで自動作成する方法としては,発表者の考案した単語語形音素の単語集合表現（BoW）による方法があったが,今回の研究では,新たに,語形の地域による共起情報を FastText でベクトル化し,語形情報と地理情報を埋め込んだ言語地図を様々な語について作成した.そして,その言語地図の持つベクトル情報を階層的クラスタに分類することで,言語地図そのものを分類することを行った.これによって,基本語・漢語などの分布と,文法要素の分布とでは,異なった分布の様相を示すことが明らかになった."
D5-2,地理的エンティティ情報が与えられた文書ジオロケーションモデルの有効性検証,山本祐耶|乾孝司,,D5:テーマセッション５：ことばと地理空間の情報処理(2),SNS 投稿文書などの投稿位置を推定する文書ジオロケーション課題では、文書内に含まれる地名（「茨城」）やランドマーク（「ディズニーランド」）への言及が有力な手がかりになることが多いが、これら言及のみから常に十分な情報が得られるとは限らない。本研究では、これらの言及情報をより効果的に活用するため、各言及からそれらが指し示す実世界上の実体（エンティティ）を同定し、同定されたエンティティに関する情報を利用することを考える。評価実験を通して、エンティティ情報のうち、エンティティの所在情報に注目して文書ジオロケーションモデルに情報を取り込むことで、文書ジオロケーションの性能が改善することが確認できた。
D5-3,衛星画像の時系列変化説明に向けたLVLMの比較,辻本陵|大内啓樹|上垣外英剛|渡辺太郎,,D5:テーマセッション５：ことばと地理空間の情報処理(2),衛星画像から時系列変化を説明することは，都市計画や環境モニタリングなどにおいて重要である．しかし，データセットの人手構築には高いコストがかかる．この課題に対処するため，本研究では，衛星画像を用いた時系列変化の説明生成に焦点を当て，Large-scale Vision-Language Models (LVLMs)によって生成された時系列変化説明を比較する．実験では，複数のモデルと Prompting を検証し，生成された説明における正解センテンス中の単語網羅率，説明の忠実性と情報性などを評価した．その結果，網羅性においては LLaVA-1.5，忠実性と情報性においては GPT-4-vision-preview に衛星画像を直接入力する手法が最も有効であることを確認した．
D5-4,Text2Traj2Text: 大規模言語モデルを活用した段階的データ生成に基づく人物移動軌跡の言語化,浅野輝|米谷竜|関井大気|大内啓樹,,D5:テーマセッション５：ことばと地理空間の情報処理(2),本論文では，実世界における人物の移 動の 背後にある目的や 意図を理 解し，その説 明文を生成す る言 語モ デル を学 習す るフ レー ムワ ークText2Traj2Text を提案する．計測・アノテーションコストの高い説明文付き移動データの大規模収集を回避するため，提案フレームワークでは既存の学習済み大規模言語モデルを活用し，演繹的・段階的に人物の多様な行動パターンと説明文を生成する．また，生成した説明文をパラフレーズすることでデータを大規模化する．このように構築された学習データを用いて新たに言語モデルをファインチューニングすることで，移動軌跡の説明文生成モデルを獲得する．スーパーマーケットでの買い物を題材に評価実験をおこない，ROUGE，BERT Score などの指標を用いて提案モデルの有効性を確認した．
E5-1,民事第一審判決書のXMLデータ化,前田郁勝|外山勝彦|小川泰弘,,E5:テーマセッション３：法ドメインにおける言語処理(2),現時点において，民事判決書の公開状況は，最高裁判所ないし各省庁が言い渡された判決のごく一部をｐｄｆデータないしｈｔｍｌデータで公開されているにとどまり，裁判書の検索，内容の分析を行うのに適したデータ形式となっていない．また，法務省において民事判決の全件データベース化に向けて検討が進められており，情報工学的な観点から，どのようなデータ形式が望ましいかを検討する必要があると考えられる．そこで，民事判決の構造を踏まえて，民事判決書のＸＭＬデータ化を検討するとともに，最高裁判所ホームページ（以下「最高裁ＨＰ」という．）iから取得した民事第一審判決書のＸＭＬデータ化を試みた．
E5-2,Applying mutual information to extract legal domain-specific collocation nouns in Mandarin,Po-HsuanHuang|Sieh-ChuenHuang|HsuanleiShao,,E5:テーマセッション３：法ドメインにおける言語処理(2),"Segmentation  constitutes  a  fundamental  processwithin  of  Natural  Language  Processing (NLP) for  the Chinese  language. However, when  we  apply  it  into domain-specific  field, it  can  be  limited  with  the“domain-specific” words. especially  in  Chinesecharacters. The  researchers  often  used  the  personal dictionary by human-hand before, we present a general solution of novel collocation extraction technique aimed at  domain-specific  texts  through  iterated  segmentation based  on  mutual  information  measure  and  averaged mutual  information. It  has  been  found  that  while mutual-information-based collocation extractions did not benefit  from  iterated  segmentation, collocation extractions  based  on  averaged  mutual  information performed  better  after  several  times  of  iterated segmentation. Also, while segmentation based on mutual information  reached  generally  higher  precision, non-collocations extracted with mutual information had generally larger edit distances than those extracted with averaged mutual information."
E5-3,法律間の類似条文の対応付けにおけるBERTの法令ドメイン適応,山田大地|中村誠,,E5:テーマセッション３：法ドメインにおける言語処理(2),比較法研究では日本法と外国法の類似する条文を対応付けることがある．既に BERT [1]を用いて条文を対応付ける研究がなされているが，モデルは事前学習のみで使われていた．本研究では，BERT のfine-tuning を行い，条文を対応付けてその有効性を検証することを目的とする．fine-tuning には教師なし学習と教師有り学習を用いて性能の比較を行った．また，試験的に多言語モデルを用いた対応付け結果を示す．実験より，法令テキストを用いて fine-tuningを行ったモデルは従来の手法を上回り，特に教師あり学習が類似条文の対応付けにおいて最も高い性能を発揮した．
E5-4,変更極小性を考慮した改正後法令文の機械翻訳,山腰貴大|小川泰弘|外山勝彦,,E5:テーマセッション３：法ドメインにおける言語処理(2),一部改正に伴い既存の法令文を翻訳し直す際には，改正前の訳文の表現を維持し，改正により変化した部分のみを翻訳対象にすることが望ましい．この要件を変更極小性と呼び，改正後法令文の翻訳においては，流暢性，妥当性に並ぶ要件である．本研究では，変更極小性を考慮した機械翻訳の実現を目指し，改正前後の法令文のコーパスの構築，Transformer ベースの機械翻訳手法の開発，変更極小性の評価指標の開発を行った．また，改正後法令文の翻訳実験により，提案手法の有効性を検証した．
P5-1,地図を刺激に用いた経路情報参照表現の収集,川端良子|大村舞|小西光|浅原正幸|竹内誉羽,,P5:ポスター,我々は、経路情報を参照する表現のデータベースを構築した。20 の地図を刺激とし、1 地図あたり 2経路、1 経路あたり 40 人に地図上の二地点の経路情報の記述を依頼し、1600 の経路情報参照表現を収集した。経路情報参照表現は、地図上のランドマークに基づく相対参照表現のみであるかを判定したうえで、相対参照表現のみの場合には、始点・通過地点・終点の情報の有無をラベル付けした。さらに各表現のわかりやすさをアンケート調査により収集した。
P5-2,前提知識を考慮した数学の確率問題自動解答の精度向上,谷村華梨|平博順,,P5:ポスター,大規模言語モデルによる文章生成の品質が大幅に向上し，さまざまな分野への応用が期待されている．しかし，数学などの教科における個別学習での使用には，各教科の問題に対する解答精度が低いなどの課題がある．本研究では，大規模言語モデルの一つである GPT-4 を用いて高校数学における確率分野の問題に対して自動解答を行い，不正解となる場合の原因の分析を行った．分析の結果，GPT-4 に不足していると考えられる分野の前提知識を追加して解答生成を行い，解答精度が向上するケースがあることが分かった．題材として，従来研究で高い精度を出すことが難しいとされている確率分野の問題を取り扱うこととした．その結果，前提知識を考慮することで，解答精度の向上が見られる事例があった．
P5-3,早押しクイズの名数問題における解の妥当性を考慮した解答をするための CoT プロンプトの構築,杉山宏輝|角康之,,P5:ポスター,"本研究では,早押しクイズの名数問題における解の妥当性を考慮した解答を言語モデルに出力させる方法を提案する.通常の早押しクイズでは解の妥当性を考慮することで,一見答えが確定していない段階での解答の正答率を高めることができ,言語モデルにおいても同様のことが期待できる.具体的な手法として, Chain-of-Thought(CoT)プロンプト[1]を用いて,妥当性を考慮した思考過程とそこから得られる解答を出力する.妥当性には,仲間はずれ,文字列の類似,難易度,順序の 4 種類あり[2],それぞれ問題と思考過程を含めた解答をプロンプトとして与える."
P5-4,RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented Large Language Models,星康人|宮下大輔|YouyangNg|立野賢登|森岡靖太|鳥井修|出口淳,,P5:ポスター,Large Language Model (LLM)と 検索 を組 み合 わせた retrieval-augmented large language model (R-LLM)の効 率的 な開 発と 定量 的な 評価 を可 能と するフレームワーク，RaLLe (Retrieval-Augmented LLMDevelopment and Evaluation)を 提案 する1）．既存 のR-LLM 開発用フレームワークとは異なり，RaLLeは検索や生成などの個々の推論過程を動作させながら行うプロンプト開発や，構築した R-LLM に対して任意のベンチマークデータセットを用いた定量的な評価を実現する．
P5-5,RAGにおけるLLMの学習と評価：FAQタスクへの応用,長澤春希|戸田隆道,,P5:ポスター,大規模言語モデル(Large Language Model: LLM)はその汎用性の高さから，実応用を含めた様々な利活用が進んでいる．昨今では文書などを追加入力として与えることで，外部知識を参照させながら LLM を運用する Retrieval-Augmented Generation(RAG)などの手法の有用性が改めて認識されている．一方で，Low-Rank Adaptation (LoRA)などの軽量なﬁne-tuning手法なども確立されつつある．そこで本稿では，参照知識が限定的な FAQ タスクを例に取り，RAG と比較した際の質問応答タスクにおける LLM ﬁne-tuning の有用性を検討する．並行して，実運用を踏まえた評価についても議論する．
P5-6,質問応答モデルはどのショートカットを優先して学習するか？,篠田一聡|菅原朔|相澤彰子,,P5:ポスター,読解のための質問応答モデルは，訓練セット内の擬似相関を利用した解き方であるショートカットを学習する傾向がある．この問題を緩和するために様々な手法が提案されてきたが，それらはショートカット自体の特性を十分に考慮していない．本研究ではショートカットの学習可能性（ショートカットをどれくらい学習し易いか）が緩和手法の設計に有用であるという仮説を立て，実験的に検証する．
P5-7,大規模言語モデルを用いたEmotional Support Conversation システムの構築とその評価,藤田敦也|上乃聖|李晃伸,,P5:ポスター,会話 にお いて ユー ザの 負の 感情 を緩 和す るEmotional Support 能力は，ソーシャルインタラクションやメンタルヘルス支援，顧客対応など様々な対話シナリオにおいて対話システムが今後具備すべき重要な機能である．本論文では，大規模言語モデルを用いた対話戦略の予測と，予測に基づいた対話生成を行うことで Emotional Support を実現する手法を提案する．実験では，応答文評価と実際に人とシステムを対話させる評価を行い，対話戦略による対話管理の効果や大規模言語モデルの EmotionalSupport 能力を検証する．
P5-8,エントレインメント尺度および戦略が対話システムの評価に与える影響の調査,金崎翔大|河野誠也|湯口彰重|桂井麻里衣|吉野幸一郎,,P5:ポスター,人間同士の会話では，やりとりを重ねるうちに話者のふるまいが同調するエントレインメント現象がしばしば発生する．こうした現象を扱う対話システムを構築しようとする場合，どのようなエントレインメント尺度を活用するか，どのようなタイミングでどのようなエントレインメント度合いを用いるかの 2 点を明らかにする必要がある．本研究ではニューラル雑談対話モデルをエントレインメント度合いに応じてリランキングするシステムを用い，複数の語彙的エントレインメント尺度，および複数のエントレインメント戦略を網羅的に組み合わせた主観評価実験を行った．
P5-9,Character-LLM 構築のためのキャラクター設定指示,人見雄太|木本晴久|佐藤大地|跡部優吾|福島千尋|池田愛|並松竜太郎|鈴木沙英子|岡村萌加|簑田葉月|小山正彦|片田智大|橋本圭|ジューストー沙羅|守屋貴行,,P5:ポスター,本研究では，LLM に対するキャラクター設定指示を組み込むことで，Character-LLM の性能向上を図るキャラクター設定指示を提案した. 実験結果は，提案手法が従来手法に比べて，正解率とターゲット指向正解率を大幅に向上させることを示している.提案手法により，GPT の固有の生成傾向を克服し，よりキャラクター固有の要求に適切に応答する能力を向上させることができた.
P5-10,経験情報収集および伝達を主目的とする雑談対話による関係性維持支援システム,志満津奈央|上乃聖|李晃伸,,P5:ポスター,対話システムを介して二者の経験情報を共有することで，関係構築を促進する研究が行われている．これまでのシステムでは，情報の収集と伝達の機能の分離や，テンプレートを用いた発話生成など固定的な処理が多く，対話の流れの自然さや応答の柔軟性に課題がある．本研究では，雑談対話による関係性維持システムを目指し，LLM を用いた柔軟な経験情報収集および伝達を行うシステムを提案する．システム構成として，収集と伝達を順に行うカスケード型システムと，両タスクを一度に行う混合型システムを提案する．実際のシステムで評価を行い，LLM を用いたシステム性能の検証と提案する 2種類のシステムの性能比較を行った結果を示す．
P5-11,ロボット対話によるインタラクティブ観光プランニング,佐藤京也|大萩雅也|山崎天|水本智也|吉川克正,,P5:ポスター,本稿では，対話ロボットコンペティション 2023で最優秀賞を獲得したマルチモーダル対話ロボットについて詳述し，課題や知見も共有する．本コンペティションは，実際に店舗にヒューマノイドロボットを置いて観光プランニングを行うものであり，テキスト対話ではなくマルチモーダル対話が要求される．我々は大規模言語モデルを活用するだけでなく，画像，音声，動作，地図などを総合的に用いることで観光プランニングタスクを適切に達成することを狙ったシステムを構築した．
P5-12,複数生成AI間のコミュニケーションにおける対話の多寡と思考変化の関係分析,益村優輝|坂野遼平,,P5:ポスター,近年の対話型 AI の普及に伴い AI 同士がコミュニケーションを行うソーシャルネットワーク(AI-SN)が発生する可能性がある．それらは人間より高速な意見交換を行うと考えられ，意見の偏りがすぐに肥大化してしまう危険性がある．本研究ではその傾向と制御の分析のため，出力意見をベクトル化することによるコサイン類似度と意見交換数の相関係数，各 AI が出力したスコア，人手によるスコアを用いて，複数 AI 間の意見交換による対話の多寡と思考変化の関係分析を行った．その結果，議題によって異なるがそれぞれの出力意見に変化を確認することができた．また，議題に対して肯定的な話者を多く含ませることによって意見の偏りの少ない議論が行われるよう AI-SN を制御できる可能性があるという仮説が立てられた．
P5-13,SILVER: Self Data Augmentation for Out-of-scope Detection in Dialogues,ChunpengMa|TakuyaMakino,,P5:ポスター,"Detecting out-of-scope (OOS) utterances is crucial intask-oriented dialogue systems, but obtaining enough an-notated OOS dialogues to train a binary classiﬁer directly isdiﬃcult in practice. Existing data augmentation methodsgenerate OOS dialogues automatically, but their perfor-mance usually depends on an external corpus. Herein wepropose SILVER, a self data augmentation method thatdoes not use external data. It improves the accuracy ofOOS detection (false positive rate: 90.5%→ 47.4%).Furthermore, SILVER successfully generates high-qualityin-domain (IND) OOS dialogues in terms of naturalness(percentage: 8%→ 68%) and OOS correctness (percent-age: 74%→ 88%), as evaluated by human workers."
P5-14,文脈を考慮した半教師あり学習による対話行為推定,石島孝俊|白井清昭,,P5:ポスター,本研究では発話の先行文脈を考慮して対話行為を推定する半教師あり学習の手法を提案する．一般に発話の対話行為は文脈に依存するが，教師あり学習によって文脈を考慮したモデルを構築する手法は提案されていたものの，教師なし・半教師あり学習において文脈を考慮することの有効性は十分に検証されていなかった．提案手法では，先行する発話の文脈情報を反映した発話の埋め込みを作成し，クラスタリングや k-NN 法に基づいて少数のラベル付き発話からラベルなし発話に対話行為を伝播させる．評価実験の結果，文脈を考慮することで対話行為推定の正解率が向上することを確認した．
P5-15,語り直しを目的とした大規模言語モデルを用いた Story Intention Graph の作成とその評価,吉川祐輔|井上壮志|東中竜一郎,,P5:ポスター,"人間同士の対話において，お互いの価値観や経験は物語によって表出されることが多い．対話システムにおいても，ユーザが話す物語を適切に理解することで，ユーザの価値観や経験を深く理解し，親密さを持ったやり取りを実現できるようになるとともに，より高度なやり取りも実現できるようになると考えられる．本論文では，大規模言語モデルを用い，物語文を Story Intention Graph (SIG)に変換する手法について述べる．SIG は，物語中の登場人物,および，その行動・意図・動機に焦点を当て,それらの関係性をグラフとして表したものである．今回，大規模言語モデルとして GPT-4 を用い，所定の物語文からの SIG の自動作成に取り組んだ．また，作成された SIG の妥当性を評価するとともに，SIG を用いた物語の語り直しを行い，その結果を確認した．"
P5-16,対話状態追跡における言語モデルのスキーマに基づくHallucinationの抑制,佐藤明智|南泰浩,,P5:ポスター,近年では，ChatGPT をはじめとした大規模言語モデルを活用した対話システムが注目されている．これらのシステムは，日常会話や要約などの幅広い用途で利用されており，多種多様なユーザーのニーズに応えることができる．また，ユーザーの意図に応じて情報を取得したりデバイスを操作したりするタスク指向の対話システムに対するニーズも高まりつつある．しかし，大規模言語モデルにはHallucination の問題が存在しており，不正確なテキストの生成によって，誤ったアクションを引き起こすリスクがある．これを解決するため，本研究ではタスク指向対話システムにおける Hallucination を抑制する新たな手法を提案する．具体的には，Schema Guided Dialogueデータセットを用いて，スキーマに基づいて生成する語彙を制約するスキーマ名制約付きデコーディング(SNCD: Schema Name Constrained Decoding)を提案する．この手法を用いることでスキーマ名を正確に生成し，エラーを防止することが期待できる．本稿では提案手法の有効性を検証し，Hallucination を抑制するための可能性について分析する．
P5-17,強化学習を用いた傾聴対話モデルの構築,松本奈々|安藤一秋,,P5:ポスター,高齢者の増加とともに認知症患者も増加している．認知症患者の感情に寄り添い，意思を汲み取るためのコミュニケーション技法として「バリデーション」がある．しかし，介護業界は慢性的な人手不足であり，介護士がすべての患者に対して十分なコミュニケーション時間を確保することが難しい．本稿では，バリデーションのうち「オープンクエスチョン」に着目し，強化学習を用いて傾聴の多い応答を生成する対話モデルの構築法について検討する．評価実験では，ファインチューニングの epoch 数と強化学習の step 数の関係に着目し，応答文の多様性や傾聴性などに関して評価・考察する．
P5-18,対話破綻修復コーパスの収集と分析 —ユーザの個人特性とシステムとの関係性を考慮した修復文生成に向けて—,坪倉和哉|岡田真依|入部百合絵|北岡教英,,P5:ポスター,現状の対話システムとの対話では，未だ対話破綻が生じているため，破綻発生時には適切に対話を修復する必要がある．しかし，これまで提案されている修復方法はどのユーザに対しても同様の発話を行う．ユーザ適応の観点から，ユーザの個人特性やシステムとの関係性によって適切な修復方法が異なるかを明らかにするため，個人特性や関係性を含む対話破綻修復コーパスを作成した．破綻後のユーザ発話を分析した結果，自己主張スキルが高い人は破綻したシステムに同意しない，初対面や上司に対しては破綻後に依頼をしない，などの傾向が確認された．このことから，これらの傾向に合わせた破綻修復方法を検討する必要があることが示された．
P5-19,語りに傾聴を示す応答タイミングの検出のためのテキストデータの利用,渡邉優|伊藤滉一朗|松原茂樹,,P5:ポスター,会話エージェントが人間に代わって語りの聴き手を担うことが期待されている．これらが聴き手として認められるには，傾聴を示す目的で語りに応答する発話である傾聴応答を適切なタイミングで生成することが効果的である．本論文では，傾聴応答タイミングの検出のためのテキストデータの利用について述べる．事前学習済み言語モデルを傾聴応答タイミング検出タスクでﬁne-tuning する前に，テキストへの句読点挿入タスクを中間タスクとして導入する．応答タイミングの検出実験の結果，中間タスクの導入により，特に，傾聴応答のデータ量が十分ではない場合に，モデルが傾聴応答タイミングの特徴を効率的に学習できることを確認した．
P5-20,ペルソナ対話システムにおけるペルソナ選択と応答生成,吉田快|吉野幸一郎|品川政太朗|須藤克仁|中村哲,,P5:ポスター,"ペルソナ対話システムでは対話が進むのに従い，対話の文脈上生成された新しいペルソナに相当する情報が現れる場合がある．この新しいペルソナを考慮しない場合，対話文脈と矛盾した応答を生成することがあり得る．そこで本研究では，こうした新しいペルソナに相当する情報をペルソナプールに保持し，その中から対話の文脈に合わせて必要なペルソナを選択し利用する枠組みを提案する．このため，人手によるペルソナ選択データセットの構築を行い，より良いペルソナ選択手法について分析を行った．構築したデータセットを用いたペルソナ文選択の評価では,名詞ベース選択の手法が既存の文ベース選択の手法より精度が高いことを確認した."
P5-21,知識グラフの対話システムへの記憶化：学習アプローチの探究,薛強|滝口哲也|有木康雄,,P5:ポスター,近年，対話システムの進化に伴い，生成される回答の質の向上が重要な課題となっている．本研究では，知識グラフを対話システムに記憶させることにより，回答の質を向上させると同時に，回答中の幻想問題を軽減する方法を探究する．具体的には，知識グラフを記憶するための 3 種類の学習タスクを提案し，その有効性を検証する．実験結果から，一般的な知識検索対話システムと比較して回答の生成品質は向上しなかったものの，新たな可能性を探る一歩となった．本研究は，対話システムの質的向上と知識グラフの活用における新たな方向性を示唆している．
P5-22,キャッチコピー共同作成対話コーパスにおける発話と編集および参照の分析,周旭琳|市川拓茉|東中竜一郎,,P5:ポスター,本研究では，共同作業を行う対話システムの構築に向けて，人間が共同作業を行っているデータの分析を行う．使用するデータは，人間同士が対話しながらキャッチコピーを共同で作成するタスクに取り組んだ対話データである．分析では，発話及びキャッチコピー編集の発生有無と，キャッチコピー編集欄の位置を指し示す記号による絶対参照表現の発話内での使用有無に着目した．その結果，活発に発話やキャッチコピーの編集を行う対話は作業者の自己評価が他より高くなる傾向があることや，絶対参照が多く使用されるほど評価が高い傾向があることが分かった．
P5-23,コンタクトセンターにおける人と言語モデルの協働による対話データの作成,伊藤拓海|阿部香央莉|日高雅俊|野田健一|岩浅佑一,,P5:ポスター,"コンタクトセンターにおける自然言語処理は顧客サービスの自動化と効率化において重要な役割を担っているが、個人情報や著作権等の観点から研究用として扱うことのできるデータは少ない。そこで本研究では研究用データの構築のため、仮想の家電メーカを設定し回答に必要なナレッジと対話データの作成に取り組んだ。特に、効率的なデータ作成と実用後の継続的なデータ収集を見据え、人と大規模言語モデルの協働によってデータを作成するアプローチを検討し、461 件のナレッジと 2, 308 件の対話データを作成した。"
P5-24,地図を刺激に用いた位置情報参照表現の収集,大村舞|川端良子|小西光|浅原正幸|竹内誉羽,,P5:ポスター,本研究では、位置情報を参照する表現のデータベースを構築した。20 の地図を刺激とし、1 地図あたり 40 人に地図上に示した目標点の位置情報の記述を依頼し、800 の位置情報参照表現を収集した。位置情報参照表現は、地図上のランドマークに基づく相対参照表現のみであるかを判定したうえで、相対参照表現のみの場合には、一人称視点（目標点からの見えるものの記述）・空間内視点（地図中の他の地点から目標点を参照）・空間内移動（地図中の他の地点から目標点に移動）・鳥瞰視点（地図を上から俯瞰）の 4 つに分類した。さらに各表現のわかりやすさをアンケート調査により収集した。
P5-25,実際の人々の感想を利用した雑談発話生成,成田風香|佐藤志貴|徳久良子|乾健太郎,,P5:ポスター,雑談では，感想を述べる発話が対話の盛り上がりに寄与することが知られている．我々は，文脈に対して適切な感想を生成できる発話生成システムの実現を目指し，対話の話題に対する実際の人々の感想を外部情報として入力に用いることを試みる．本稿では，我々がこれまでに構築した「感想付きニュース雑談コーパス」を拡張した上で，システムの追加学習を行うことで，人々の感想を利用して発話を生成するシステムを構築した．生成発話の評価の結果，文脈に対して自然であり，かつ感想を含む発話を多く生成できることが分かった．加えて，これらのシステムにより生成された発話は，雑談を盛り上げるような発話であることが明らかとなった．
P5-26,Dialogue Response Generation Using Personal Facts and Personality Traits,◊WeiwenSu|NaokiYoshinaga|YumaTsuta|MasashiToyoda,,P5:ポスター,"Persona-based chatbots assuming a speciﬁc persona forchatbots can generate consistent responses given the per-sona. Existing persona-based dialogue datasets such asPersonaChat and Multi-Session Chat (MSC), however,contain mainly personal facts (e.g.,“I like cats.”) butlack personality traits (“I am extraverted.”). We thusautomatically annotate the MSC dataset with personal-ity traits to train persona-based chatbots using personalfacts and personality traits. Experimental results on thepersonality-augmented MSC datasets conﬁrmed that ourchatbot improves personality consistency scores, when us-ing a personality-aware reranking."
P5-27,ディスカッションの役割分類に基づいたファシリテーション対話システム,藤後英哲|菊池英明|藤倉将平|清水健吾,,P5:ポスター,会議では，さまざまな問題が生じることが知られている．その問題を解消するアプローチとしてファシリテータの介入があるが，全ての会議にファシリテータを介入させることは困難である．そのため，本研究では会議における問題を解消するため，ファシリテーション対話システムの開発を行なった．開発した対話システムを評価した結果，ファシリテータとしての適切な発話タイミング・発話生成を行える可能性が示唆された．
P5-28,対話の齟齬と介入による解消：LLM を用いた検討,清水周一郎|YinJouHuang|村脇有吾|ChenhuiChu,,P5:ポスター,対話における齟齬は重要な現象であるが，どのような現象であるかは明確でない．本研究では，対話の齟齬について，Clark の言語使用に関する理論をもとにして整理し，また齟齬の解消には第三者による介入が役立つことを指摘する．LLM は高い対話能力と広範囲な知識を持ち，コントロールされた対話の実験を容易にする．本研究では LLM エージェントに齟齬を含む対話とそれに対する介入を行わせ，介入を行うことによる対話の変化を分析する．
A6-1,Swallowコーパス: 日本語大規模ウェブコーパス,岡崎直観|服部翔|平井翔太|飯田大貴|大井聖也|藤井一喜|中村泰士|MengsayLoem|横田理央|水木栄,,A6:LLMデータ構築,"これまで、オープンな日本語大規模言語モデルの学習には CC-100、mC4、OSCAR などのコーパスの日本語部分が用いられてきた。ところが、これらのコーパスは日本語テキストの品質を重視して作られた訳ではない。本研究では Common Crawl のアーカイブ（2020 年から 2023 年にかけて収集された 21スナップショット分、約 634 億ページ）から日本語のテキストを独自に抽出・精錬し、約 3,121 億文字（約1.73億ページ）からなる日本語ウェブコーパスを構築した。この規模は、CC-100 (約 258 億文字）、mC4（約 2,397 億文字）、OSCAR 23.10（約 740 億文字）を抜き、日本語の言語モデルの学習コーパスの中で、商用利用が可能なものとしては最大である。"
A6-2,大規模言語モデルの日本語理解能力検証のための「本音と建前」データセットの構築,子安隆人|綱川隆司|西田昌史,,A6:LLMデータ構築,"本研究では,大規模言語モデルの言語処理能力の検証を目的とし,大規模言語モデルが日本語の独特の文化的背景や言語構造を適切に理解し処理することができるかを明らかにするため，言語モデルが文中の非明示的な情報や隠された意味を理解し，それを基に推論する能力を有しているか検証するためのデータセットを構築する．本データセットを用いて,言語モデルがどの程度日本語文のニュアンスや文脈を適切に捉えることができるのかを検証した."
A6-3,ichikara-instruction LLMのための日本語インストラクションデータの作成,関根聡|安藤まや|後藤美知子|鈴木久美|河原大輔|井之上直也|乾健太郎,,A6:LLMデータ構築,GPT を始めとする対話型生成 AI は主に、事前学習、Supervised Fine Tuning(SFT)、強化 学習 を用いて構築された言語モデルで構成されている。特に SFT で利用されるインストラクションは非常に重要な役割を担っている。我々は 2024年 3 月までに、高品質な日本語インストラクションデータを1 万件作成する計画である。本論文では 2023 年 12 月 21 日に共同研究企業に向けて公開したデータの概要と、それに基づく評価結果、最終目標、データの作成手順、プロジェクトの形態と今後について紹介する[1]。
A6-4,大規模言語モデルの日本語能力の効率的な強化: 継続事前学習における語彙拡張と対訳コーパスの活用,水木栄|飯田大貴|藤井一喜|中村泰士|MengsayLoem|大井聖也|服部翔|平井翔太|横田理央|岡崎直観,,A6:LLMデータ構築,英語を主体として学習ずみの LLM を元に日本語テキストを主体として継続事前学習する方法は，高性能な日本語 LLM を構築する有望なアプローチである．本研究ではまず継続事前学習の効果を分析し，特に日本語の質問応答で効果的であることを報告する．また LLM の能力を効率的に強化する方法を明らかにするため，日本語の語彙拡張の影響および対訳コーパスの有効性を調査した．その結果，語彙拡張による効率化は要約を除き性能への悪影響はないこと，および対訳コーパスの併用が翻訳能力を強化することを明らかにした．
A6-5,Aug AnaloGPT: 大規模言語モデルを用いたアナロジー生成によるデータ拡張,李宰成|山田武士,,A6:LLMデータ構築,データ拡張(Data Augmentation)とは、新たなデータ収集なしに、訓練データの多様性を増やし、モデル性能を高める手法を指す。この手法は、自然言語処理(NLP)において、学習データ不足やデータ不均衡問題に対処する上で重要な役割を果たす[1]。しかし、ほとんどのデータ拡張手法は数百例程度のデータセットに対してのみ有効である[2]。本研究では数千例からなるデータセットにおいても学習データ不足に対処可能なデータ拡張として、大規模言語モデルを用いた文のアナロジー生成に基づく手法(Aug AnaloGPT)を提案する。文のアナロジー生成とは対象ドメインが異なるが文の論理構造や意味の関係性が類似している類比文を生成することである。提案手法を JGLUE の JNLI[3]のデータセットに適用したところ、言い換えに基づく既存のデータ拡張手法を凌ぐ性能向上を確認できた。
B6-1,日本語Winogroundデータセットの自動構築,清水博文|河原大輔,,B6:マルチモーダル画像・動画像(3),人間レベルの推論ができるマルチモーダルモデルの開発・評価のために、多くのマルチモーダルデータセットが構築されている。本研究では、その中でも視覚・言語の高度な理解を必要とする Winogroundデータセットの自動構築手法を提 案し、日本 語Winoground データセットを構築する。このデータセットにより日本語の視覚・言語モデルの評価が可能になったが、自動構築による生成データセットの質に関してはさらなる改良が必要である。
B6-2,画像ベースとテキストベースのモデルを用いた表の構造解析の性能検証,四條光|進藤裕之|渡辺太郎,,B6:マルチモーダル画像・動画像(3),"表は科学論文，web サイト，新聞など様々な媒体に現れるため，表を解析することは膨大な文書を管理するために重要である．表の構造解析を解くために，深層学習ベースの画像エンコーダとテキストデコーダから構成される画像ベースのモデルが考案され，非常に高い精度を達成している．一方，エンコーダにマルチモーダルのモデルを使用する研究が登場している．こうした背景から実際にエンコーダには画像ベースのモデルとマルチモーダルのモデルのどちらが優れているか比較することは重要である．本研究では，表の構造解析のエンコーダ・デコーダモデルを構築し，エンコーダに画像ベース，テキストベース,マルチモーダルの 3 つの異なるモデルを使用し，表の構造解析のスコアを比較することで，どのモデルが優れているのかの比較を行なった．実験の結果，画像ベースのアプローチが良いと示唆された."
B6-3,Hol-CCG構文解析と拡散モデルの統合による構文構造を陽に考慮した画像生成,山木良輔|品川政太朗|持橋大地|谷口忠大,,B6:マルチモーダル画像・動画像(3),近年，拡散モデルに基づくテキスト画像生成モデルは高度な画像生成を実現している．しかし，構文的曖昧性を有するテキストに対して，特定の構文的解釈に対応する画像を選択的に生成するという点において課題がある．そこで本研究では，テキストが有する構文構造を分散表現として計算可能な構文解析モデルである Hol-CCG [1]と，画像生成モデルである Stable Diﬀusion [2]を統合し，特定の構文的解釈に対応する画像を選択的に生成可能なモデルを提案する．
B6-4,人工画像を用いたText-to-Imageモデルの事前学習,中尾純平|磯沼大|片岡裕雄|森純一郎|坂田一郎,,B6:マルチモーダル画像・動画像(3),近年，大規模 Text-to-Image (T2I)モデルの事前学習に用いるデータセットに対して倫理面の問題が指摘されている．そこで本研究では人工画像を用いた T2I モデルの事前学習を検討する．人工画像にはキャプションが付与されていないことが事前学習に用いる際の難所となるが，本研究では CLIP を活用して人工画像に疑似的なキャプションを付与することでこの点にアプローチした．評価実験では，人工画像と実画像でそれぞれ事前学習したモデルを，複数の実画像データセットでファインチューニングした後の生成画像の精度で比較することで，人工画像を用いた事前学習が実画像を用いた事前学習に迫る有効性を示すことと共に，人工画像の色による多様性と輪郭という性質が重要であることを確認した．
B6-5,日本語特化の視覚と言語を組み合わせた事前学習モデルの開発 Developing Vision-Language Pre-Trained Models for Japanese,王直|細野健人|石塚湖太|奥田悠太|川上孝介,,B6:マルチモーダル画像・動画像(3),視覚 と言 語を 組み 合わ せた 事前 学習（Vision-Language Pre-training; VLP）は、多くのタスクに対して Fine-Tuning なしでも一定の性能を発揮する。特に、VLP モデルの一つである CLIP は、ゼロショットで教師あり ResNet-50 と同等の画像分類性能を持つとされるが、その多くは英語向けであり、日本語特化 CLIP での性能は 10–25%劣る。我々は、画像エンコーダと訓練データを 7–10 倍大にし、さらに言語エンコーダの拡大を行うことで、日本語特化CLIP の画像検索性能 R@5 を 14%改善させた。これは、OpenAI が公開する英語版 CLIP の精度を 2%上回るものである。追加実験でハイパーパラメータの影響を調査し、大きなバッチサイズが性能向上に重要であることを明らかにした。
C6-1,LLM を用いたタカハトセンチメント付与タスクの検証,川原一修,,C6:テーマセッション２：金融・経済ドメインのための言語処理(3),"中央銀行の要人発言にタカハトセンチメントを付与するタスクは,金融実務家にとって重要でありながら,商用利用可能なアノテーション付き学習データの提供はまだ行われていない.本研究では,プロンプトエンジニアリングを用いて,大規模言語モデル（LLM）を活用したセンチメント推定の精度向上を検証した.その結果,センチメント付与ガイドラインを含むプロンプトを用いることで,ファインチューニングされた小型モデルよりも高い精度を達成するケースが存在することが明らかになった."
C6-2,株価変動に対する大規模言語モデルを用いた株式用語選択,西田隼輔|宇津呂武仁,,C6:テーマセッション２：金融・経済ドメインのための言語処理(3),株価変動記事では，株価変動を表現する株式用語が用いられることが多い．そのような記事の自動生成を目的として，大規模言語モデルに数日間の株価の推移を与え，株価変動の特徴を適切に表す専門用語を自動で選択させる手法の評価を行った．本手法により，株価変動記事の記者が人手でつけた用語や，それに意味が近い用語を高い精度で選択できることが分かった．また，few-shot 学習やﬁne-tuningを行うことで，さらに性能を向上させられることが示された．
C6-3,内積注意重みを用いた統合報告書の定量評価とポートフォリオ分析,森田祐介|若村浩明|椎名唯圭|李楚翹|大島健斗|齋藤哲朗|日尾泰子,,C6:テーマセッション２：金融・経済ドメインのための言語処理(3),企業の長期的価値を評価するのに用いられる ESG開示情報には，GHG 排出量や従業員男女比率といった数値的に比較可能な情報だけではなく，ポリシーやビジネスモデルとの関連性など，文章等によって表される企業個別の情報も含まれる．本研究では，従来投資判断に活用することが難しかった統合報告書のテキストデータについて，マテリアリティウェイトと内積注意重みを用いて定量評価する手法を提案した．さらに，実際に定量化したスコアによって作成した三分位ポートフォリオのパフォーマンスを比較することで，定量化したスコアが分析期間において将来リターンに対して有効性を持つことを明らかにした．
C6-4,金融分野における言語モデル性能評価のための日本語金融ベンチマーク構築,平野正徳,,C6:テーマセッション２：金融・経済ドメインのための言語処理(3),大規模言語モデル(LLM)の発展とともに、分野や言語に特化した言語モデルの構築の必要性が議論されてきている。その中で、現在の大規模言語モデルがどの程度の性能を発揮するかを分野に特化して評価するベンチマークの必要性が高まっている。そこで、本研究では、日本語かつ金融分野に特化した複数タスクからなるベンチマークの構築を行い、主要なモデルに対するベンチマーク計測を行った。その結果、現時点では GPT-4 が突出していることと、構築したベンチマークが有効に機能していることを確認できた。
C6-5,ファイナンシャル・プランニングの自動化に向けた GPT-4 及び RAG の性能評価,西脇一尊|大沼俊輔|工藤剛|門脇一真,,C6:テーマセッション２：金融・経済ドメインのための言語処理(3),個人の家計や人生設計について資金計画を立てるファイナンシャル・プランニングは，幅広い金融知識を必要とし，一般に専門家との相談を通じて行われる．相談を促すために，大規模言語モデル（LLM）と Retrieval-Augmented Generation（RAG）を用いた自動相談サービスの実現が期待される．しかし，LLM が RAG によって抽出された金融知識を活かして応答できるかは明らかではない．本研究ではファイナンシャル・プランニング技能検定を題材に，LLM が RAG によって抽出された金融知識を活用できるかを評価した．その結果，LLM は RAG によって得た金融知識を活用できることを確認し，自動相談サービス実現に向けた課題を明らかにした．
D6-1,否定表現を伴う文における自然言語理解の性能検証,内田巧|南條浩輝,,D6:意味解析,本稿では，対偶により否定表現を伴う含意関係認識の学習・評価データセットを作成し，否定表現の自然言語理解タスクへの影響を調査した．実験の結果，含意関係認識では，前提文に否定表現が伴うことで精度が悪化することを確認した．悪化の原因として，否定表現に過剰に依存する shortcut learning が発生している可能性を示した．STS では，2 文共に否定表現が含まれるだけで，類似度を高めに予測してしまう傾向を確認した．以上より，言語モデルは否定表現による意味の変化を捉えることなく推論していることを示した．
D6-2,自然言語処理でもスコープ解釈を取り扱うべきか？－QRの棄却と主述関係を基にした分析の提案－,井上恵利佳,,D6:意味解析,近年の大規模自然言語処理モデルは著しい進展により、かつて取り扱いが難しいとされてきたスコープ解釈のような意味的に複雑な現象に対する処理能力が向上している。では、自然言語処理の分野においてスコープ解釈などは特にこれ以上扱う必要がないのだろうか。本研究では、依然として人間と同じようには処理できていない部分が存在しているため、自然言語処理でもスコープ解釈という言語現象を扱うべきであると主張する。その上で、どのように扱うべきかを考える際、従来スコープの分析として受け入れられてきたように QR を仮定することは妥当ではないと指摘し、主述関係を基にした代替案を提案する。
D6-3,Japanese Adverb Taxonomy: Modern NLP Tools and Comparative Linguistic Analysis,◊EricOdle|Yun-JuHsueh|SoufianeGhzal|Pei-ChunLin,,D6:意味解析,"This paper compares Japanese adverb taxonomies withresults from natural language processing analysis. A list of3,801 Japanese adverbs was generated using the JapaneseMultilingual Dictionary (JMDICT). Next, word embed-dings were produced from these adverbs using four chiVe(sudachi Vectors) models. Embeddings were then clus-tered using k-means and hierarchical clustering algor ithms,comparing results with the Yamada 3-category and Noda5-category linguistic taxonomies. Additionally, Silhouetteanalysis indicated optimal clustering at k=3 and k=5 clus-ters. Manual labeling of a random adverb subset showedthat the Yamada taxonomy tends to unevenly represent ad-verbs: 66.3% Status vs. 14.2% Degree and 19.5% Declar-ative. However, the Yamada taxonomy achieved a higherclassiﬁcation agreement (62.7%) with embedding clustersthan the Noda taxonomy. Overall, this research contributesinsight into Japanese adverb categorization and sets thestage for future studies."
D6-4,数学証明における帰結関係を表す接続表現の予測,太田宇宙|松崎拓也|藤原誠,,D6:意味解析,この論文は数学証明において帰結関係を表すhence / therefore / thus の間に使い分けの傾向があるか否かを調べるために、BERT を用いた単語選択の実験を行ったものである。具体的には、arXiv に掲載されている数学論文から証明テキストを抽出し、hence / therefore / thus をすべてマスクした上で BERTを用いて 3 択の穴埋め問題を解かせる訓練及び評価を行なった。結果として hence / thus の間の使い分けは Wikipediaと BookCorpus のみで事前訓練を行った BERT と比べて向上したが、therefore の正答率のみ hence / thusと比べて低いままだった。故に BERT をベースとしたモデルは少なくとも hence / thus 間の使われ方の違いをある程度まで捉えていると考えられる。
D6-5,日本語の格助詞「が」を用いた情報の授受,岡安一壽,,D6:意味解析,"日本語の主部をマークする格助詞「が」の中立叙述及び総記という働きを利用し,対話に用いられた文により情報を発信・蓄積する仕組みについて述べる．"
E6-1,言語の固有次元を測る,上田亮|横井祥,,E6:テーマセッション６：深層学習時代の言語学と自然言語処理(1),言語の複雑性に関する問題は言語学や計算機科学に属する複数のドメインで長い間探求されてきたが，近年では特に深層ニューラルネットワークモデルが獲得する自然言語文の表現の複雑性に注目が集まっている．これまでの表現学習モデルがどのような言語の複雑性を捉えてきたのか，またこれからのモデルがどのような複雑性を獲得していけばよいのかを考える契機となることを目的として，本稿では，固有次元の観点から言語の複雑性を推定する．実験の結果，最近のモデルから得られた表現であっても固有次元の推定値は数〜十数程度となり，言語の持つ本質的な次元の小ささが示唆された．
E6-2,意味変化の統計的法則は1000年成り立つ,川崎義史|高村大也|永田亮,,E6:テーマセッション６：深層学習時代の言語学と自然言語処理(1),本稿は，ラテン語とロマンス語を対象として，意味変化の統計的法則が 1000 年にわたり成り立つことを示す。単語間の意味のずれは，対応する分散表現の余弦距離で測る。分散表現は聖書をコーパスとして学習した。回帰分析の結果，頻度が高い・多義性の低いラテン語語源ほどロマンス語形との意味のずれが小さくなる傾向が見られた。これは，意味変化の統計的法則が，ラテン語とロマンス語を隔つ長期間にわたり成り立つことを示唆する。
E6-3,Exploring Metalinguistic Awareness in Pre-trained Language Models through the International Linguistics Olympiad Challenges,JunehwanSung|上垣外英剛|渡辺太郎,,E6:テーマセッション６：深層学習時代の言語学と自然言語処理(1),"Despite signiﬁcant advances in natural language pro-cessing, the degree to which these models mimic ”human-like” linguistic cognition remains uncertain. This studyexplores the metalinguistic awareness of Pre-trained Lan-guage Models (PLMs), focusing on their ability to compre-hend the structure of language. We utilise the challengingRosetta Stone problems from the International LinguisticsOlympiad (IOL), which entail translating sentences froman unknown language solely relying on limited informa-tion. ByT5 was selected as our model due to its byte-levelunbiased tokenisation and its aptness for translation tasks.Our empirical ﬁndings reveal that whilst ByT5 can learnimplicit linguistic patterns without supervision, it exhibitslimited metalinguistic awareness, particularly in zero-shotlearning scenarios. These results highlight the need forongoing research to enhance the depth and breadth of lan-guage understanding in PLMs and to br idge the gap towardshuman linguistic capabilities."
E6-4,意味の集中度に基づいた意味変化検出,永田亮|高村大也|大谷直輝|川崎義史,,E6:テーマセッション６：深層学習時代の言語学と自然言語処理(1),本稿では，二つのコーパスで意味が異なる単語を検出する手法を提案する．提案手法は，単語ベクトルの方向のばらつきから算出される「意味の集中度」という新しい指標に基づく．これにより，コーパスや単語ベクトルに対する条件が緩和され，適用範囲が広がる．また，計算量も低減され，大規模なコーパスにも適用可能である．更に，意味の差異を検出するだけでなく，意味の広狭の判定および意味が異なる事例の抽出も可能となる．
E6-5,動詞派生前置詞の文法化の定量化,永田亮|川崎義史|大谷直輝|高村大也,,E6:テーマセッション６：深層学習時代の言語学と自然言語処理(1),動詞派生前置詞とは，動詞から派生し，前置詞のように振る舞う語句（例：following）を指す．動詞派生前置詞が，動詞の性質を失い，前置詞の機能を果たすようになる文法化現象について様々な仮説が言語学で知られている．しかしながら，仮説検証の規模について改善が必要なことが指摘されている．本稿では，動詞派生前置詞の文法化度を自動的に定量化する手法を提案し，大規模なコーパスを対象にして，文法化に関する三つの仮説の検証を行った．その結果，提案手法は全ての仮説を支持する結果となった．
P6-1,日本語文埋め込みの文書検索性能と検索補助付き生成での評価,矢野千紘|塚越駿|笹野遼平|武田浩一,,P6:ポスター,LLM の実応用が加速する中，LLM を訓練なしで拡張可能な検索補助付き生成(Retrieval AugmentedGeneration: RAG)と，RAG に用いられる文埋め込みを利用した密ベクトル検索は，重要な技術として注目されている．しかし，日本語における密ベクトル検索や RAG の評価は十分とは言えない．そこで本研究では，日本語文書検索タスクにおける文埋め込み手法の性能を評価する．さらに，有望なモデルをRAG に利用した場合の性能評価も行い，日本語における密ベクトル検索と RAG の全般的な評価を行う．
P6-2,文書分類のためのクラス情報を考慮したトークン分割,平岡達也|岩倉友哉,,P6:ポスター,本稿では，クラスの情報を有効活用することで文書分類タスクに特化したトークン分割の処理を提案する．ユニグラム言語モデルベースのトークン分割器に，エントロピーに基づく重みを掛け合わせることで，あるクラスに特徴的なトークンを優先的に使用するようなトークン分割を行う．実験より，複数の文書分類のデータセットで提案手法による性能の向上が得られることが分かった．また，クラスが未知の場合であっても，疑似的なクラスによって性能の向上が得られる場合があることを報告する．
P6-3,Improving Zero-Shot Dependency Parsing by Unsupervised Learning,◊JiannanMao|ChenchenDing|HourKaing|HidekiTanaka|MasaoUtiyama|TadahiroMatsumoto,,P6:ポスター,"UDify [1] is a multilingual and multi-task parser ﬁne-tuned on mBERT. It has demonstrated notable perfor-mance, even on few-shot languages. However, its perfor-mance saturates early and decreases g radually as trainingprogresses with zero-shot languages. This work focuses onthis phenomenon, which has not yet been suﬃciently stud-ied. Data augmentation methods based on unsupervisedlearning on monolingual data were designed to transform azero-shot case into an ar tiﬁcial few-shot case. Experimentswere conducted on the Breton language as a typical casestudy. For the Breton language, the unlabeled attachmentscore was signiﬁcantly improved. The parsing accuraciesfor other languages were not noticeably aﬀected."
P6-4,日本語 Universal Dependencies の通時的転移可能性について,尾崎太亮|臼井久生|古宮嘉那子|浅原正幸|小木曽智信,,P6:ポスター,日本語の通時的な文法研究のため，近代以前の日本語に対する統語情報の付与を目指し，現代日本語Universal Dependencies (UD)解析の zero-shot 転移を検討した．UD で広く研究される言語横断的な解析手段に着目し，現代日本語 UD で学習した解析器を明治期の文書を対象とした UD コーパスで評価した結果，係り受け関係にある二語の抽出は高い精度を維持していたものの，文法的な観点では述語とその格要素の転移性能が低く，また助動詞を含めた文末表現も適切に解析できないことも明らかになった．
P6-5,Transformerとベクトルを用いたSpan-based固有表現抽出手法,宮﨑太郎|SimonClippingdale|後藤淳,,P6:ポスター,固有表現抽出は自然言語処理の基盤技術のひとつであり，自然言語処理を利用したシステムで広く応用されている．従来では CRF (Conditional RandomField)を用いた系列ラベリングを用いる手法が一般的であったが，近年では複数単語のまとまりを入力して，入力のまとまりが固有表現であるか判定するSpan-based 手法も用いられる．本稿では，Span-based手法による固有表現抽出手法について述べる．複数単語からのベクトルのまとめ上げに BERT などの事前学習モデルで用いられる特別な Token ⟨CLS⟩の考え方を用いることで，従来一般的に用いられていたLSTM (Long Short-term Memory)や Max Pooling を上回る性能が得られることを確認した．
P6-6,日本語意味役割タスクにおいて複数TokenIDが与える影響,曽和晃太郎|竹内孔一,,P6:ポスター,本研究では，Byte-Level BPE アルゴリズムを採用したトークナイザのエンコードによって，1 つのトークンから複数のトークン ID が生成される場合に日本語意味役割タスクに与える影響について調査した．その結果，二つの日本語意味役割タスクそれぞれにおいて複数のトークン ID を持つデータが各タスクの精度に与える影響を明らかにし，各タスクにおける有効なデータの形を示した．
P6-7,依存関係の大きさは意味の関連性を表す,大山百々勢|山際宏明|下平英寿,,P6:ポスター,単語ベクトルの点群を可視化して高次元空間でどのように単語の意味が表現されているのかを解釈する手段として独立成分分析(ICA)を用いることができる．ところが現実のデータに適用すると ICA によって得られる成分は互いに無相関であるが独立ではなく，成分間には依存関係がある．本稿では単語ベクトルを ICA で変換して得られる成分間の依存関係を３次以上の混合モーメントで定量化し，その依存関係が何を表しているのかを理解することを目標とする．実験を行った結果，依存関係が大きい成分同士は意味の関連が強いことがわかった．また，成分間の依存関係への寄与が大きな単語によって関連性を具体的に解釈することができた．
P6-8,自動生成したNLI データを用いた教師なし文埋め込みの改良,佐藤蒼馬|塚越駿|笹野遼平|武田浩一,,P6:ポスター,デコーダ系の大規模言語モデル(LLM)は自然言語処理の多くのタスクにおいて高い性能を示しており、文埋め込み生成においても PromptEOL [1]というデコーダ系モデルが Semantic Textual Similarity(STS)タスクにおいて最高性能を達成している。しかし、PromptEOL が高い性能を示すのは、人手で構築された自然言語推論(Natural Language Inference:NLI)データセットを用いてﬁne-tuning した場合であり、人手で構築されたデータを利用しない場合のSTS の性能は 6 ポイント程度低い値となっている。本研究では LLM を用いて NLI データセットを自動生成し、PromptEOL のﬁne-tuing に利用することで、教師なし設定における文埋め込み生成の高性能化を目指す。STS タスクで評価した結果、人手で構築された大規模なデータセットを利用しない設定において 82.21 という既存手法を上回る性能を達成した。
P6-9,言語横断類似度推定のための多言語文符号化器のドメイン適応,山内洋輝|梶原智之|桂井麻里衣|二宮崇,,P6:ポスター,本研究では，多言語文符号化器のドメイン適応に取り組む．高度な専門知識が要求される医療や学術のドメインにおいては，目的ドメインに特化した事前訓練の有効性が知られている．しかし，様々な言語においてドメイン特化の単言語事前訓練モデルの開発が進む一方，言語横断情報検索などに応用可能な多言語モデルは存在しない．また，各言語における目的ドメインのコーパスを整備し多言語の事前訓練を行うには大きなコストが必要となる．そこで我々は，既存の多言語文符号化器および 2 言語の各々における目的ドメインに特化した単言語文符号化器を用いて，効率的にドメイン特化の言語横断文符号化器を開発する．3 つのドメインおよび言語対における翻訳ランキングの評価実験の結果，ドメイン適応なしのベースラインや既存のドメイン適応手法と比べて，提案手法の有効性を確認できた．
P6-10,家族関係を対称詞として呼びかけられた際の聞き手の受け取り方 ー事象関連電位を用いた検討ー,山根初穂|汪敏|加藤志織|小泉政利|木山幸子,,P6:ポスター,親族名称の虚構的用法を用いた呼びかけは、聞き手を不快にする場合がある。本研究はこの不快感について脳波の事象関連電位を用いて検証した。参加者が「お兄/姉ちゃん」、「お兄/姉さん」、「すみません」と呼びかけられる音声刺激に応じて感情惹起を反映する成分の検出を目指した。その結果、男女ともに、親族名称の虚構的用法による呼びかけに対して感情反応と考えられる成分が増大した。特に男性参加者では、「さん」と「すみません」に比べ「ちゃん」に対して感情反応と考えられる成分を惹起した。親族名称の虚構的用法は、聞き手の感情に影響を与えていること、男性は女性よりも対称詞使用に強い拒否反応を持つことを示唆する。
P6-11,大規模言語モデルによるシフト還元修辞構造解析の模倣,前川在|平尾努|上垣外英剛|奥村学,,P6:ポスター,デコーダのみからなる大規模言語モデル(LLM)の発展は目覚ましく，様々な自然言語処理タスクにおいて良好な結果を残している．一方，修辞構造解析におけるそれらの有効性はこれまで議論されていない．本稿では，今後の修辞構造解析の研究において LLM を活用すべきかどうかを探ることを目的として，プロンプトを介してシフト還元動作を LLMで模倣する手法を提案し，その有効性を議論する．評価実験の結果，提案法は世界最高の解析性能を達成し，テキストドメインの汎化性においても優れていた．つまり，修辞構造解析においても LLM に注力すべきことが強調される結果を得た．
P6-12,モデル編集を用いたMachine Unlearningにおけるハイパーパラメータの自動調節,中屋和樹|松田源立,,P6:ポスター,深層学習の発展によりあらゆるタスクの性能が向上した一方で，特定のデータを忘れる技術の開発も求められるようになってきている。MachineUnlearning とは訓練された機械学習モデルから，一部のデータに関する影響を取り除く技術である。本研究では，タスクベクトルと呼ばれるモデル編集手法に着目し，Transforemr モデルの重みを一律ではなく個々の Attention ブロック，ないしはレイヤーごとに調節する手法を提案した。具体的には，翻訳タスクと対話システムタスクでの Unlearning を試み，Machine Unlearning における評価基準の観点から，テストデータおよび忘却データを対象とした分析を行った。
P6-13,生成 AI は含意関係認識ができるのか,荒沢康平|狩野芳伸,,P6:ポスター,含意関係認識は論理的過程の基盤であり、たとえばファクトチェックなど様々な重要タスクの下敷きとなる。ファインチューン等で表層的なパターンを学ばせれば含意関係認識の評価スコアは向上するが、必ずしも含意関係認識そのものが解けて論理的な演算一般ができることにはならない。本研究では、ファインチューンや few shot prompting 抜きにGPT-4 がどのような場合に含意関係認識に失敗するかを詳細に分析し、特に時制、数量詞・数詞の認識に課題があること、またわずかな単語や語順の違いで結果が大きく変動することを示した。現在の大規模言語モデルの限界を示すとともに、今後の言語モデル改良に向けた手がかりになると期待される。
P6-14,対話モデルに対する敵対的プロンプトの効率的な最適化,矢野一樹|綿岡晃輝|ThienQ.Tran|髙橋翼|SengPeiLiew|鈴木潤,,P6:ポスター,"言語モデルの不適切な出力を回避するためには,敵対的プロンプトを用いたストレステストにより,潜在的なリスクを洗い出すことが重要である.既存の手法では，プロンプトのトークン選択を繰り返すことで攻撃成功に近づくよう最適化を行う．そのため，一つのプロンプトの生成に時間を要し，多様なリスクを網羅するストレステストの実施には膨大な時間を要する.この課題を解決するため,プロンプト最適化におけるトークン選択の戦略を改善する手法を提案する.実験により，提案手法は既存手法より少ないステップで攻撃を成功できることを示す.加えて，トークン選択における勾配と損失を分析し，提案手法が採用する戦略の優位性を示す."
P6-15,日本語TruthfulQAの構築,中村友亮|河原大輔,,P6:ポスター,本研究では大規模言語モデル(LLM)の真実性に関するベンチマークとして，日本語 TruthfulQA（JTruthfulQA）を構築する。JTruthfulQA は非事実に関連するもの，難しい知識を問うものを含む 18 カテゴリ，604 問からなる。JTruthfulQA を用いて LLMの評価を行ったところ，GPT-3.5-Turbo および GPT-4は非事実ジャンルの問題において人間より高い正答率を示したが，知識ジャンルにおいては人間の正答率を大きく下回った。また，GPT-4 はすべてのジャンルの問題において LLM の中で最も高い正答率を示した。
P6-16,大規模言語モデルに含まれる社会集団間の感情の抽出,田中邦朋|笹野遼平|武田浩一,,P6:ポスター,大規模言語モデル(LLM)は大量のテキストからモデルを学習することで、社会常識や偏見など、人間が潜在的に持つ知識や感情をある程度、獲得しているとされる。しかし、特定の社会集団が持つ感情を各種の LLM からどのくらい抽出可能かは明らかとなっていない。本研究では、国籍、宗教、人種/民族という観点でそれぞれ規定される社会集団を対象に、ある集団から別の集団への印象に関する質問をLLM に入力し、その応答に感情分析を行うことで、集団間の感情を LLM を用いてどの程度、抽出できるかの検証に取り組む。
P6-17,複文における言い換え文の生成,駿河樹|村上仁一,,P6:ポスター,本論文は，複文における日本語の言い換え文の生成を行う．言い換え文の生成には様々な手法がある．松本[1]が行った手法では，モデルの学習・言い換え文の生成に単文対訳文を使用した．本論文では，文長が長く複雑になりがちである複文対訳文を使用して同様の実験を行った．また実験結果の比較・検討を行った．その結果，複文は単文と比べると，意味を正しく保持した質の良い言い換え文が作成されやすい事が分かった．
P6-18,任意の文における言い換え文の作成,宮本歩|村上仁一,,P6:ポスター,本稿では，任意の入力文において言い換え文を作成する手法を提案する.言い換えの作成に関する研究は数多く行われているが，松本の手法[1]では言い換え文の作成に日英対訳文の存在を前提としていた.本研究では対訳文のない文章でも正解率 90%の精度で言い換え作成を実現した.
P6-19,Exploring the Challenges of Multi-Step Logical Reasoning with Language Models: A Few-Shot Approach to Explainable Entailment Trees,◊BowenGao|ShotaroKitamura|NaoyaInoue,,P6:ポスター,"An Entailment Tree is a type of explainable entailmenttask that requires Large Language Models ( LLMs ) toproduce intermediate hypotheses and reasoning steps. Pre-vious studies have focused on using ﬁne-tuned models,including the T5 model, for this purpose. However,ﬁne-tuning typically involves high computational training costsand necessitates a comprehensive dataset to be eﬀective.This paper explores the use of a decoder-only model com-bined with few-shot learning. This technique is, facilitatedby a prompt, and is implemented to generate the intermedi-ate hypothesis. Our experiments show that it is challengingto achieve results superior to those obtained using ﬁne-tuned models, including the T5 model. We conducted ananalysis to understand why decoder-only models do not ex-cel in this area, and we hope that our ﬁndings can aid otherresearchers in investigating the potential of decoder-onlymodels for explainable entailment tasks."
P6-20,JParaCrawlからの大規模日本語言い換え辞書の構築,近藤里咲|梶原智之|二宮崇,,P6:ポスター,"本研究では，先行研究よりも 25 倍大きい 3.8 億対の日本語言い換え辞書を構築し，公開する．言い換え知識獲得は，Bilingual Pivoting と呼ばれる対訳コーパス上での単語アライメントによって行われてきた．本手法で獲得できる表現の多様性は対訳コーパスの規模に依存するが，既存の日本語言い換え辞書は 200 万文対の日英対訳コーパスから得られた1,500 万言い換え対が最大である．我々は，10 倍大きい 2,000 万文対の日英対訳コーパス JParaCrawl を用いて，より多様な言い換え知識獲得に取り組む．評価実験の結果，我々の言い換え辞書は再現率と適合率の両方で先行研究を上回り，文類似度推定の外的評価においてもより高い性能を達成した．"
P6-21,大規模言語モデルにおける幻覚緩和のための単語確率の外挿,何昀臻|高瀬侑亮|石橋陽一|下平英寿,,P6:ポスター,GPT-4 や Llama，PaLM などの大規模言語モデル（LLM）の進化は下流タスクの性能を急激に上昇させただけでなく，我々の社会に大きな影響を及ぼしている．このような技術革新が起きた一方で，尤もらしい誤情報を生成する「幻覚」が重要課題となっている．本研究では LLM の構造や学習済みパラメータを変更せず，容易に幻覚を低減する効果的な手法を提案する．この手法は Transformer の低層から高層にかけての単語確率の軌道に着目し，仮想的な追加層における単語確率を予測して外挿することで，より正確な単語生成を促進し幻覚の発生を抑制する．実験により，提案手法は既存手法と比較して幻覚生成の抑制において同等の性能を達成していることが示された．
P6-22,人材業界固有の表現を考慮した求人票のマルチラベル分類,原龍昊|林勝悟|DatP.T.Nguyen,,P6:ポスター,人材業界では，求人票や履歴書といった様々なテキストデータが存在し，その分類や予測が行われている．しかし，人材業界のテキストには専門用語などの固有の表現があるため，単純なテキスト分類モデルでは適切な分類が難しい．本研究では，求人票の職種と業種のマルチラベル分類タスクに取り組む．まず，人材業界固有の表現に対応するために，求人票データを用いてドメイン特化 BERT モデルを訓練する．次に，無関係なテキストの影響を低減するために，文単位に分割した求人票のテキストと各カテゴリの埋め込みを BERT モデルを用いて生成し，各カテゴリとの最大類似度ベクトルに基づいてマルチラベル分類を行う．求人票データセットを用いた評価を行い，提案手法は比較手法よりも優れた結果を出し，分布シフトの状況下でも有効に働くことを確認した．
P6-23,語りの傾聴における補完応答の生成のための話し手の発話の予測,海野博揮|大野誠寛|伊藤滉一朗|松原茂樹,,P6:ポスター,円滑に会話を進めるには，話し手の語りに対して聞き手が相槌などの応答をすることが重要であり，対話システムが語りを聞く際にも，傾聴態度を示す応答（傾聴応答）の生成が望まれる．傾聴応答の 1つに話し手の発話を補完する応答，すなわち，補完応答がある．補完応答を適切に生成できれば，語りを理解していることを効果的に伝えることができる．本論文では，補完応答の生成に向けた，話し手の発話の予測について述べる．まず，補完応答において話し手のどのような発話が補完対象であるかを分析する．次に，分析結果に基づき，本研究では，話し手の既発話文節と係り受け関係にある未発話文節を補完対象として予測する問題に取り組む．
P6-24,RAGにおける自己認識的不確実性の評価,二宮大空|戸田隆道,,P6:ポスター,大規模言語モデル（Large Language Model: LLM）の普及により，カスタマーサポート事業では外部知識に基づき回答する Retrieval Augmented Generation（RAG）の導入検討が積極的に行われている．しかし，ユーザーの質問に対する答えが検索で得られなかった場合，誤った情報を生成してしまう可能性が高い．このような場合，本来であれば回答不能であることを LLM が認識してユーザーに伝えることが望ましい．そこで，本研究では回答可能かに関する認識の正確さを自己認識的不確実性と定め，LLMを用いて定量的に評価する．さらに，LLM を用いた回答の修正が自己認識的不確実性の向上に有効であるかを検証する．
P6-25,自己認知は LM as KB の信頼性を高めるか,井之上直也|原口大地|田中健史朗|白井清昭|NatthawutKertkeidkachorn,,P6:ポスター,Language Models as Knowledge Bases (LM as KB)は，自然言語形式のプロンプトで知識の問い合わせを柔軟に行える一方で，信頼度の高い問い合わせ方法は未だ確立されていない．本稿では，LM as KB に自己認知機構を取り入れ，予測結果が不確実な場合に問い合わせを分解し，熟考的に検証する新しいアプローチ Back-oﬀ LMKB を検討する．評価実験では，GPT-4 及び GPT-3.5 に基づく Back-oﬀ LMKB を質問応答データセット StrategyQA [1]上で検証し，自己認知機構の有効性，及び今後の課題を示す．
P6-26,言語は等しく複雑か？: 多義語埋め込み表現による形式–意味対応の複雑性,中山拓人,,P6:ポスター,「あらゆる言語は，等しく複雑である」という言語の性質は，言語学において長く信じられてきた．実際に，この性質を支持するような事例が報告されている一方で，反証的な研究結果も同時に挙げられており，現在に至るまで，その真偽については未解決である．本研究は，言語全体の複雑性を決定する主要な要因の 1 つとして，形式−意味の対応関係に注目し，情報理論に基づく複雑性計測手法の提案，及び多言語間の複雑性比較を行った．結果として，極端に複雑な対応関係を持つ言語は無いが，他に比べて，より単純な対応関係を持つ言語が存在すること，及び言語の等複雑性はそれほど強い性質ではない，ということが示唆された．
P6-27,超伝導材料の転移温度予測における事例間の繋がりを考慮した知識グラフの有効性の調査,吉野草太|旭良司|三輪誠|佐々木裕,,P6:ポスター,近年，データ駆動で材料開発を行うマテリアルズ・インフォマティクスの発展に伴い，属人的な知見への依存を減らし，より高性能に物性値を予測するための研究が進められている．超伝導材料は高い応用可能性により開発が急がれているが，膨大な探索範囲から目的に見合った転移温度を持つ材料を発見するのは困難である．そのため，組成式や構造情報から転移温度を予測し，材料探索を加速化するアプローチが研究され，その 1 つにデータベースから作成した知識グラフを用いて転移温度予測を行う手法がある．しかし，既存手法の知識グラフは事例間の繋がりを考慮できていない．そこで，本研究では材料が組成式・構造名・論文題名の頂点を介して繋がる知識グラフを用いた転移温度予測モデルを提案する．実験により，SuperCon データセットにおいて既存手法と比較して RMSE が 0.072 減少することが明らかとなった．さらに，材料間の繋がりを考慮した知識グラフの転移温度予測に対する有効性を確認した．
A7-1,Compositional augmentation policy using different formulas for the notion of middle sentence for low resource machine translation,◊JinChen|YvesLepage,,A7:翻訳・LLM,"Middle sentence generation is a technique that, given astart sentence and an end sentence, outputs a sentence withmiddle semantics. We aim to further explore formulas formiddle sentence generation and construct a compositionalpolicy to combine these formulas into better translationmodels. We study particular and general types of formulas:particular formulas are based on speciﬁc words and gen-eral formulas are based on the IDF score of each individualword. We use these formulas as corpus augmentation op-erations and deﬁne a policy that automatically constructsa breadth-ﬁrst tree which ﬁnds the node with the least per-plexity as the best node. Results show that our policyprovides signiﬁcant improvements over our baseline."
A7-2,異言語間対話支援における誤訳警告メッセージの有効性調査,YunmengLi|鈴木潤|森下睦|阿部香央莉|乾健太郎,,A7:翻訳・LLM,現状の機械翻訳システムは，実用レベルに達したと言われるようになったが，異言語間対話支援に利用する場面では，ユーザの意図を正しく翻訳できるかという観点で，まだ実用レベルとは言い難い．誤訳を多く含む異言語間対話支援において，機械翻訳システムを利用する実用的なアプローチの一つは，誤訳に関する警告メッセージを提示し，ユーザの混乱を軽減する方法である．しかし，このような警告メッセージがユーザにどのように受け入れられ，また，どのような利益をもたらすのかについては未検証課題である．本研究では，この課題に取り組み，異言語間対話支援における誤訳警告メッセージの有効性を検証する．
A7-3,LLM の生成・翻訳による指示・応答データセット構築,加藤佑一|中田康太,,A7:翻訳・LLM,高品質な日本語の指示・応答データセットを LargeLanguage Model（LLM）よる低コストな構築を目指し、英語での対話に最適化された Llama-2-70B-chatで英語の指示・応答データセットを生成し、それをLlama-2-70B で日本語訳した。本データセットと既存データセットのそれぞれで Swallow-7b をファインチューニングし、日本語 Vicuna QA ベンチマークで GPT-4 により比較評価した。その結果、前者のモデルが約 75%の勝率を達成した。さらに、OpenAIの text-davinci-003 との比較でも 60%以上の勝率に達した。以上から、LLM による生成・翻訳による指示・応答データセット生成の有効性が示された。
A7-4,同一の原文書に対する複数の翻訳文書間で対応する言語単位対の自動抽出,本田友乃|藤田篤,,A7:翻訳・LLM,機械翻訳の研究や産業翻訳において、誤りのない翻訳間の品質における差異を分析的に記述することは重要である。同一の原文書に対する異なる翻訳間に観察される差異を言語表現に基づいて記述するための枠組みは、翻訳文書対の分割と分割された単位対の分類という 2 つの工程からなるスキームとして整理されている[1]ものの、差異を効率的に分析するためには、分割・分類の自動化が課題である。そこで我々は、同一の原文書に対する複数の翻訳文書間で対応する言語単位対の自動抽出に取り組んだ。
A7-5,プロンプトの丁寧さと大規模言語モデルの性能の関係検証,尹子旗|王昊|堀尾海斗|河原大輔|関根聡,,A7:翻訳・LLM,人間は社会的インタラクションにおいて、敬意やその表現である丁寧さに敏感である。例えば、丁寧な要求は、より高い協力意欲と目的の達成を促す傾向がある。一方で、無礼な言葉遣いは反感や敵意を引き起こし、それに対する応答や対応の質を低下させる可能性がある。本研究では、プロンプトの丁寧さが大規模言語モデルの性能に及ぼす影響を調査する。英語、中国語、日本語における言語理解ベンチマークで評価を行う。評価結果から、無礼なプロンプトを使用すると性能が低下する可能性が高い一方で、極端に礼儀正しく遠慮深い言葉遣いが必ずしもより良い結果をもたらすわけではないことがわかった。これらの結果は、大規模言語モデルが人間の行動をある程度反映していることを示唆している。
A7-6,自然言語生成のための指示テキストの曖昧性解消,丹羽彩奈|磯颯,,A7:翻訳・LLM,大規模言語モデル（Large Language Models; LLMs）の台頭により、自然言語を用いた指示で多岐にわたる言語処理タスクが実行可能になった。しかし、与えられた指示が曖昧性であるためにユーザーの意図と異なるテキストが生成されることがある。特に自然言語生成（Natural Language Generation; NLG）に見られる曖昧性は広範で、人間が曖昧でない指示を書くことは難しい。そこで本研究では、曖昧性解消ベンチマークデータセット AmbiNLG の導入および自動的かつ網羅的な曖昧性解消を行う。実験より、提案手法による複数の曖昧性の明示的・網羅的な曖昧性解消の有効性を示した。
B7-1,自然言語処理における属性単位での反学習,沖村樹|小島武|岩澤有祐|松尾豊,,B7:機械学習,機械反学習（Machine Unlearning）は有害なデータセットからの影響を軽減できる注目すべき手法である．特に自然言語処理領域では利用者の視点から，特定の個別情報を削除できるかに主に焦点が当てられている．しかし，モデル提供者の視点からは，反学習が要求に対して特定の個別情報にのみ適用される限りでは，モデルがリスクとなる情報を出力する可能性は排除できない．この問題に対処するため，本研究ではモデル提供者がリスクのある属性に関する情報を抑制するため，属性単位での反学習が汎化しているかを評価する新しいデータセットと問題設定を提案する．提案したデータセットを用いて，既存の手法が属性単位での反学習にどれだけ適応できるかを調査し，また，提案手法であるラビング（Rubbing）が代表的な手法と比較して安定して性能を発揮できることを示す．
B7-2,文法誤り検出BERTのためのマルチタスク追加事前学習,岡本昇也|南條浩輝|馬青,,B7:機械学習,本研究では，文法誤り検出システムを実装し，文法誤りの検出性能の向上を目的として取り組んだ．我々は，追加の事前学習として対照学習と MLM のマルチタスク学習を提案した．実験の結果，追加の事前学習を行うモデルは追加の事前学習を行わないモデルに比べて性能が向上した．この追加の事前学習により，各単語の意味表現，文の意味表現を維持しつつ，文が誤りを含むか含まないか区別させる学習ができたと考えられる．
B7-3,Integrated Gradientsにおける理想の積分ステップ数はインスタンス毎に異なる,牧野雅紘|浅妻佑弥|佐々木翔大|鈴木潤,,B7:機械学習,Integrated Gradints (IG)は、機械学習モデルの挙動を説明する手法である。IG は公理により値の加法性が保証される利点を持つが、実際は数値積分の誤差から公理が保証されない可能性がある。一方で、IG の数値積分に関する分析の報告はなく、最適な積分ステップ数を導出する指針もない。そこで本研究では、積分誤差に関する分析を実施する。実験により、既存研究で広く用いられているステップ数の設定方法では、半数以上のインスタンスで過剰なステップ数となり、一部のインスタンスではステップ数が不足することを示す。本稿は IG のステップ数を分析した初めての研究報告であり、ステップ数を固定する既存の積分方法の問題点を明らかにする。
B7-4,文脈構造を利用した埋め込み表現学習の提案,原田慎太朗,,B7:機械学習,文や画像などの埋め込み表現は、検索をはじめとしたアプリケーションに利用されており、関連研究が盛んに進んでいる。先行研究では、文脈構造を明示的に利用せずに同一の文および画像を正例としてそれ以外を負例とする対照学習が主流である。しかし、埋め込み表現を構築する上で文脈構造を利用することは重要である。本稿では、文脈構造を考慮することで表現能力を向上させるための最適輸送を用いた教師なし埋め込み学習手法を提案する。結果として、STS-B および SICK-R における定量評価では、最高性能と同等以上の性能を達成し、定性評価では、文脈構造の利用により頑健かつ質の良い埋め込み表現が得られた。
B7-5,Inductive-bias Learning: 大規模言語モデルによる予測モデルの生成,田中冬馬|江本直史|弓林司,,B7:機械学習,大規模言語モデル(LLM)はパラメータを更新することなくプロンプトに入力されたデータをもとに推論を行うIn-context Learning(ICL)と呼ばれる能力が注目されている．また、コード生成も LLM の重要な応用先である．本論文では、ICL とコード生成を応用した”Inductive-bias Learning(IBL)”と呼ばれる新しい学習手法を提案する。IBL では ICL と同様に、学習データをプロンプトに入力し、推論を行うために必要な関係性を持つコード（Code Model と呼ぶ）を生成する。シンプルなアプローチであるが、IBL は学習データがどのような関係性を持つか捉えることができ，さらにコードを生成するため解釈性も兼ね備えている．また驚くべきことに、生成された Code Model は代表的な機械学習モデルに匹敵する予測精度を達成する．IBL のコードはオープンソースです．1）
B7-6,量子計算を用いた文字言語モデル,三輪拓真|河野誠也|吉野幸一郎,,B7:機械学習,大規模言語モデルの登場により，言語モデルは近年多くの注目を浴びている．また言語モデルは機械翻訳や要約など，幅広いタスクに応用されている．一方で大規模言語モデルは未だ計算量に課題があるため，計算効率の改善は重要である．本研究では，限定されたタスクで量子計算の計算効率が古典コンピュータを上回る点に注目した．具体的には，量子計算を用いて文字言語モデルを構築し，その性能の分析を行った．結果として構築したすべてのモデルにおいて，同規模のマルコフモデルよりパープレキシティを減少させることが可能とわかった．
C7-1,音声認識を用いた青空文庫振り仮名注釈付き音声コーパスの構築の試み,佐藤文一|吉永直樹|豊田正史|喜連川優,,C7:言語資源・アノテーション(1),読書バリアフリー法が制定され，読みの困難な人のためのアクセシビリティへの要求が高まっている．本研究では，OpenAI が公開している Whisper による音声認識を用いて多種多様な読みを推定するためのコーパスの大規模化が可能かを検討する．コーパスの作成にあたっては正解テキストデータとして青空文庫のテキストと，音声データとして「サピエ」の音声デイジーをそれぞれ使用し，両者を文レベルで対応させ，音声認識で複数の認識候補を取得し，読みの推定をおこなっている．合計 5545 万文字，3520時間の振り仮名注釈付き音声コーパスを構築した．この過程で明らかとなった課題についても説明する．本研究によって得られたコーパスについては公開を予定している．
C7-2,科学論文中の同じ貢献を説明しているイントロダクションの文と本文のパラグラフを判定するためのデータセット,田中翔平|牛久祥孝,,C7:言語資源・アノテーション(1),本研究では論文中の同じ貢献を説明しているイントロダクションの文と本文のパラグラフを判定するという新しいタスクを提案する．よく書かれた科学論文はイントロダクション中で示された貢献について，以降の本文において詳細に説明している．しかし初学者や専門外の論文を読む研究者にとって，イントロダクション中で示された貢献と本文の対応を把握することは難しい．機械学習モデルがこうしたイントロダクションと本文の対応をハイライトすることで，人間の論文読解の助けになることが期待される．提案するタスクのために，本研究では自動アノテーションと人手アノテーションを組み合わせてデータセットを収集した．収集したデータセットを用いて構築したエンコーダーモデルをパラグラフ検索タスクにおいて評価したところ，科学ドメインデータで事前学習されたモデルが最も性能が高く，38%の精度でイントロダクション中の貢献を説明する文に対応する本文のパラグラフを選択できることがわかった．
C7-3,ヘイトスピーチ検出における GPT-4 による擬似ラベル付与の手法と評価,倉嶋将矢|鍛原大成|櫻井義尚,,C7:言語資源・アノテーション(1),本研究では，GPT-4 を利用した擬似ラベル付与手法を提案し，その有効性を実証した．初期の F1 スコアが0.51 であったが，本手法の適用により 0.68まで向上し，従来の機械学習によるラベリングを上回る精度を達成した．正解率に関しては 94.90%を達成している．これにより，GPT-4 の応用範囲が拡がり，データセットの品質向上に寄与する可能性が示唆された．
C7-4,日本語社会的バイアスQAデータセットの提案,谷中瞳|関澤瞭|竹下昌志|加藤大晴|NamgiHan|荒井ひろみ,,C7:言語資源・アノテーション(1),大規模言語モデルの発展とともに，モデルに含まれる社会的バイアスが問題となっている．英語圏では社会的バイアスに関する様々なベンチマークが構築されているが，英語以外のベンチマークは発展途上であり，日本語の大規模言語モデルにどの程度社会的バイアスが含まれているかについては十分に調査されていない．本研究では，英語の社会的バイアス QA データセット BBQ をもとに日本語社会的バイアス QA データセット JBBQ を構築し，日本語の大規模言語モデルの分析を行う．その結果，日本語の大規模言語モデルは JBBQ に対して正答率が低く，正答率が高いモデルも社会的バイアスに従って答えている場合が多いということが分かった．注意：本論文には不快な表現が一部含まれます．
C7-5,J-UniMorph: 日本語の形態論における意味分類の体系化,松﨑孝介|谷口雅弥|乾健太郎|坂口慶祐,,C7:言語資源・アノテーション(1),"我々は日本語の動詞における語形変化とその意味をまとめたデータセットを作成した．本データセット（J-UniMorph）は，世界中のあらゆる言語の語形に共通の基準で特徴ラベルを付与する UniMorph スキーマに準拠しており，107 種類の動詞に対して合計 12,533 組の語形と特徴ラベルを掲載している．UniMorph ラベルを付与した日本語のデータセットにより，他言語との比較・分析や言語横断的なデータの解析が見込めるほか，語形変化を意味から捉えられるようになるため，日本語学習者への支援など言語教育等のアプリケーション開発が期待できる．github.com/cl-tohoku/J-UniMorph"
C7-6,ホープスピーチ研究のための日本語データセット,和泉悠|谷中瞳|永守伸年|荒井ひろみ,,C7:言語資源・アノテーション(1),ヘイトスピーチをはじめ有害コンテンツの自動検出技術の重要性は言をまたないが，表現規制のハードルの高さが技術運用における課題となってきた．そのため，ヘイトスピーチを間接的に抑制する方法として，ホープスピーチの重要性が認識され始めた．本研究では，YouTube ニュース動画へのコメント約 1 万件によって構成されている，日本語ホープスピーチのデータセットを作成し，ラベルづけされたテキストの内容分析とGPT-4を用いた評価実験を行った．
D7-1,カタカナ語の視覚的処理における迅速な音韻活性: 閾下プライミングを用いた語彙性判断課題による検証,加藤志織|熊可欣|木山幸子,,D7:心理言語学・認知モデリング,本研究は，日本語の音節文字であるカタカナの視覚的語彙処理において，書字情報の活性と，書字からモダリティの違いを越えて起こる音韻情報の活性の速度を比較することを目指す．閾下プライミングを用い，ターゲットに対し書字音韻プライム，音韻プライムを提示したときに，無関連プライムを提示したときと比較してターゲットの処理がどれだけ促進されるかについて，3 段階のプライム持続時間で検討した．語彙性判断課題の反応時間を分析して検討した結果，カタカナの視覚的処理において，音韻情報が迅速に活性化し，書字情報の活性との時間差はアルファベット等の音素文字よりも小さいことを示唆した．
D7-2,認知フィードバック：眼球運動・脳波による大規模言語モデルの強化学習,原田宥都|大関洋平,,D7:心理言語学・認知モデリング,人間のフィードバックを用いて、大規模言語モデルにより好ましい出力を教示する方法が成功しているが、脳波や視線などの認知的なフィードバックの有用性は未だ調査されていない。本研究では、人間のフィードバックにおける問題点を克服するための方法として、認知フィードバックを用いて大規模言語モデルを調整するための手法を提案し、その手法の有効性を調査する。実験の結果、規模の小さなデータセットにおいてもある程度人間のフィードバックを代替、あるいは改善できる可能性を示した。
D7-3,早押しクイズにおける超次単語予測の認知モデリング,山下陽一郎|原田宥都|大関洋平,,D7:心理言語学・認知モデリング,人間は続きの単語を予測しながら文を理解していると考えられているが、特殊な状況下では、より長いまとまりを持った単語列を予測することができる。本研究では、人間が文処理の際に見せるそのような「超次単語予測」を言語モデルがモデリングできるかどうかを検証する。早押しクイズの問題文を読んでその続きを予測する際の視線を計測し、言語モデルによって、その読み時間をモデリングした。その結果、言語モデルは人間の「超次単語予測」をある程度モデリングでき、さらに特定のデータで言語モデルをファインチューニングすると、よりよくモデリングできることが示された。
D7-4,選択性を考慮した語彙エントレインメント尺度,守屋彰二|佐藤志貴|徳久良子|赤間怜奈|横井祥|乾健太郎,,D7:心理言語学・認知モデリング,語彙エントレインメントとは，対話の参加者の語彙選択が徐々に同調してくる現象である．先行研究では，語彙項目の一致頻度に基づいてこの現象が定量化されてきたが，このやり方では，単に他に適切な表現が無いから相手と同じ表現を使用しているのか，それとも相手に同調して「あえて」その表現を使用しているのかを区別できない．そこで本研究では，選択性，つまり「あえて」の度合いを明に考慮した尺度を提案する．まず，他に自然な選択肢が存在するかどうかを言語モデルと言語資源を用いて計算し，次に，当該の表現を選択する必然性が小さい場合に大きなスコアを与える．また実際の対話データを用いた実験により，提案尺度によってはじめて捕捉できるエントレインメント現象を明らかにし，対話システムへの応用可能性について議論する．
D7-5,認知ファインチューニング：眼球運動による大規模言語モデルのファインチューニング,染谷大河|大関洋平,,D7:心理言語学・認知モデリング,近年、眼球運動データや脳波データなどの人間の生理指標データを用いて、人間の言語処理における特徴を反映し、より精度よく下流タスクを解くことができる言語モデルを構築しようとする試みがある。しかし、既存手法は特定の下流タスクでの性能向上に特化している、もしくはモデルのアーキテクチャ自体に変更が必要な手法となっており、既存の大規模言語モデルに適用して幅広い下流タスクにおける性能を向上しうる汎用的な手法となっていない。そこで本研究では、既存の大規模言語モデルに適用可能な新たな手法として、「認知ファインチューニング」を提案し、その方法論的妥当性を検証する。
D7-6,工学的性能と人間らしさの関係はトークン分割に依存する,三輪敬太|吉田遼|大関洋平,,D7:心理言語学・認知モデリング,言語モデルがトークンに与える情報量と人間の文の読み時間との関連が近年の研究で示されており，この観点から言語モデルの「人間らしさ」を評価できる．本研究では情報量や言語モデルの挙動が文のトークン分割単位に深く依存することに着目し，分割単位の異なる言語モデルにおいて工学的性能（パープレキシティ）に対する人間らしさの関係の違いを実験的に調査した．日本語の短単位と長単位が大きく異なる挙動を示すことを報告し，このような差異の原因を議論する．
E7-1,どのような言語モデルが不可能な言語を学習してしまうのか？---語順普遍を例に---,栗林樹生|上田亮|吉田遼|大関洋平|TedBriscoe|TimothyBaldwin,,E7:テーマセッション４：言語とコミュニケーションの創発(1),ニューラル言語モデルは，自然言語の範囲を超え，プログラムなど系列データ一般を処理するための基盤的な道具立てとなった．一方言語学では，自然言語のみを受理（学習）し，可能言語と不可能言語を区別する計算モデル（形式言語など）が探求されており，両分野の向かう方向は異なる．そこで本研究では，両視点から，自然言語らしくないデータをモデリングできない言語モデルを探求することで，自然言語の性質に迫る．今回は特に語順に焦点を当て，どのような言語モデルが，自然言語における語順普遍から逸脱した不可能語順をもつデータを学習してしまうのか調査する．認知的に動機づけられた言語モデルが相対的に可能語順のみを学習しやすい傾向にあることなどがわかった．
E7-2,共通基盤の構築に及ぼすイメージ生成の個体差に関するシミュレーション,由井達也|森田純哉|天谷武琉|東中竜一郎|竹内勇剛,,E7:テーマセッション４：言語とコミュニケーションの創発(1),コミュニケーションの送り手が発した記号は，受け手の有する認知的フレームを介してイメージとして解釈される．つまりコミュニケーションを効率化するためには，送り手と受け手の間で認知的フレームをすり合わせる必要がある．本稿では，そのような送り手と受け手で共有されたフレームを共通基盤と呼び，タングラム命名課題を対象とした共通基盤形成のモデルを提示する．特に，本稿ではイメージ生成における個体差を，モデルに与えるノイズパターン（シード値）によって操作した 2 つのシミュレーションを示す．
E7-3,Metropolis-Hastings Captioning Game による複数の視覚言語モデルのベイズ的統合,松井悠太|山木良輔|上田亮|品川政太朗|谷口忠大,,E7:テーマセッション４：言語とコミュニケーションの創発(1),本論文では分散的なベイズ推論に基づく記号創発のモデル化法である Metropolis-Hastings (MH) naminggame をカテゴリカルなラベルを割り当てる名付け(naming)から画像に関するキャプションの生成（captioning）へと拡張し，これが複数の視覚言語モデル（VLM）がその知識をベイズ的に統合する能力に関して基礎的な検証を行う．本稿では VLM を確率モデルとして拡張した ProbVLM を導入し，２つの ProbVLM を結合した Inter-ProbVLM を定義することで，キャプション生成結果を表す共有ノードの推論アルゴリズムとして MH captioning game (MHCG)を提案する．本実験では ProbVLM が潜在空間上の確率分布に基づき画像とキャプションの一致度を判定できること，また，異なるデータセットで学習された２つの ProbVLM が MHCG を通してより妥当なキャプションを生成し，２体のエージェントの視覚情報表現に対する尤度を高めることを示し，VLMのベイズ的に統合に関する基礎的検証を行う．
E7-4,大規模言語言語モデルを用いたエージェントベース進化モデルにおける形質表現の拡張,鈴木麗璽|浅野誉子|有田隆也,,E7:テーマセッション４：言語とコミュニケーションの創発(1),大規模言語モデル（LLM）の豊かな言語的表現力を活用し，個体間相互作用に関するエージェントベース進化モデルの形質表現を拡張することで，リアルで複雑な集団の進化ダイナミクスを明らかにすることを目的とした 2 つの研究事例を概説する．一つは協力行動に関する多様な性格特性の進化であり，自然言語で記述した高次の心理・認知特性とその行動を LLM を用いて進化モデルに盛り込む試みである．もう一つは，LLM を用いて単語に関連する話し言葉を生成することで，無限に生じる会話トピック選好性の文化進化を表現する試みである．これらを通して，LLM による言語表現に基づく多様で複雑な形質進化から示唆される社会進化ダイナミクスについて論ずる．
E7-5,指示ゲームの生成モデル的な再解釈,上田亮,,E7:テーマセッション４：言語とコミュニケーションの創発(1),言語の創発をシミュレーションすることによって，言語の進化や動態を解き明かそうとする，創発コミュニケーション(EC)という分野がある．本稿の目的は，EC において頻繁に用いられるコミュニケーションモデルであるところのシグナリングゲームや指示ゲームを，生成モデルに基づく変分推論として統一的に解釈することである．具体的には，ある種の Conditional VAE と見做すことのできる文脈付きシグナリングゲームという新たなゲームを定式化し，それが確かにシグナリングゲームや指示ゲームの一般化になっていることを確認する．
E7-6,RL-SPINNを用いた創発言語の汎化性能の評価,加藤大地|上田亮|宮尾祐介,,E7:テーマセッション４：言語とコミュニケーションの創発(1),ニューラルネットワークで構成されたエージェント同士に会話の模倣をさせ、人工的な言語を創発させて、人間の自然言語と比較・解析する言語創発という分野が、近年注目を浴びている。しかし、エージェントのアーキテクチャとして、系列の順序に沿って厳密に左から右に文を読む標準的な RNN を採用することが多く、文の中の隠れた木構造を見出しながら文意を理解する人間の理解プロセスとは大きく乖離している。そこで我々は、強化学習を用いて教師なしで文の木構造を学習できる RL-SPINN をエージェントに組み込み、言語を創発させるモデルを提唱する。実験の結果、RL-SPINN を用いた創発言語は、既存のアーキテクチャを含む複数のベースラインに勝る汎化性能を持つことが確認された。
P7-1,拡散過程を用いたキャプション生成における分類器導入の精度への影響の検証,平野理子|小林一郎,,P7:ポスター,近年，拡散過程を用いた生成モデルは連続領域において最先端の性能を達成しており，離散データ生成においても盛んに研究が行われている．本研究では，拡散言語モデルを使って自然言語処理タスクの一つであるキャプション生成に取り組み，精度向上を目的に画像による制御を言語モデルとは別の構成要素（分類器）によって行う手法と言語モデルのみで実現する手法の性能の違いについて検証を行なった．実験で測定された精度に関して提案手法は比較手法を上回ることができなかったが，提案手法によって画像の内容に応じたキャプションが一定の精度で生成できることを確認した．
P7-2,自然画像で学習された画像埋め込みにダイアグラムを特徴づける情報は含まれているか？,吉田遥音|工藤慧音|青木洋一|田中涼太|斉藤いつみ|坂口慶祐|乾健太郎,,P7:ポスター,ダイアグラムの意味やデザインを考慮して分類や検索，評価を行うための道具として，画像埋め込みがある．しかし，既存の事前学習済み画像モデルから得られる埋め込みに，ダイアグラムを特徴づける情報が十分に含まれているかは明らかでない．本研究では，エッジの向きやノードの形といった要素が異なるダイアグラムの埋め込み分布を比較し，事前学習済みモデルから得られる画像埋め込みがダイアグラムを特徴づける情報を含んでいるかを調べた．既存の事前学習済みモデルから得られる埋め込みはダイアグラムを特徴づける情報を十分には含んでいない可能性があり，ダイアグラムを扱うことができるモデルの必要性が示唆された．
P7-3,知識ベースの検索を伴うVideo QAタスクの提案,黒田佑樹|中島悠太,,P7:ポスター,ユーザの過去の発言や行動等の知識をもとに質問に答えられる質問応答システムの登場が期待され る．Knowledge-Based Video Question Answering(KBVQA)では，テレビドラマを実世界に見立ててこの問題に取り組んでいる．KBVQA では，質問に対して必要な知識が紐付けられて利用されている．本研究では質問と知識の紐付けを行わず，全体の長大な知識ベースからの知識検索を伴う VideoQA タスクである MAGQA を提案する．また，動画像字幕からの自動知識ベース作成，知識検索及び質問応答を行うベースライン手法を提案し，本タスクの難しさと提案手法の有効性を示す．
P7-4,Genre-based Character Network Analysis and Emotion Sequence Analysis for Manga,◊MeghaSharma|YoshimasaTsuruoka,,P7:ポスター,"This paper explores the relationship between emotionsequences and character network graphs from Japanesecomics to explore trends among diﬀerent genres. We pro-pose a framework to extract emotion sequences from themanga, and analyse whether signiﬁcant correlations existbetween temporal pages and emotions of the manga as wellas between emotion variables. We also detect the peaks andvalleys to ﬁnd correlations with genres. We build socialnetwork graphs from the characters in pages to analyse thestructural relationship across genres and extract featuresfrom the graphs and report on the trends across genres.Our results suggest that some preliminary trends exist inthe current scope of the study."
P7-5,環境依存情報を利用しない大規模言語モデルによるコンピュータータスク自動化手法,笹川慶人|河原大輔,,P7:ポスター,大規模言語モデル(LLM)を用いたエージェントによってさまざまなコンピュータータスクを自律的に実行する手法が提案されている。先行研究で提案された手法の多くは HTML のコードなど環境に依存した情報を用いており、それらを用いることのできない環境では使用できず、汎用性に欠ける。本研究では環境に依存した情報を用いずにタスクを実行する手法を提案する。具体的には、コンピューター画面のスクリーンショットを画面上のテキストとユーザーインターフェースの要素の位置情報に変換し、その情報からマウスやキーボード操作のコマンドを LLM に生成させる。結果としてコンピューター画面の画像の入力のみでタスクを実行できるようになり、また、高いタスク成功率を示した。
P7-6,Enhancing Economic Time Series Prediction with News Text Data and Numerical Data: A Transformer-Based Approach,◊MouShangyang|ZhangWenting|TakujiKinkyo|ShigeyukiHamori|ChenJinhui|TetsuyaTakiguchi|YasuoAriki,,P7:ポスター,"Financial time series such as stock prices can be hard topredict as it is diﬃcult to model short-term and long-termtemporal dependencies between data points. In addition,they are inﬂuenced by underlying fundamentals that areconveyed through various news feeds. Existing methodsfor predicting ﬁnancial time series typically focus on eithernumerical data or textual information. When consideringtextual data, the prevailing approach is to utilize senti-ment information extracted from news sources as features.This paper introduces a novel methodology that directlyintegrates ﬁnancial news content with corresponding timeseries data, to enhance the accuracy of ﬁnancial time seriesforecasting."
P7-7,Multimodal Large Language Model Meets New Knowledge: A Preliminary Study,◊JunwenMo|JiaxuanLi|DucMinhVo|HidekiNakayama,,P7:ポスター,"Multimodal Large Language Models (MLLMs) haveachieved impressive performance on established image un-derstanding benchmarks. However, these benchmarks typ-ically include images of objects that are already known,potentially not fully testing MLLMs’ ability to understandunfamiliar objects. To address this, we assess the perfor-mance of MLLMs on images featuring synthesized novelobjects. We use ChatGPT to create descriptions of novelobjects by merging characteristics of existing objects andthen employ a text-to-image generation model to gener-ate synthesized objects. Using this dataset, we evalu-ate MLLMs in identifying and describing the elementsof novel objects. Experiment results show that state-of-the-art MLLMs struggle to comprehensively understandimages containing novel objects, often leading to halluci-nated descriptions."
P7-8,音声想起時の脳波における想起区間の推定,鈴木大裕|入部百合絵,,P7:ポスター,音声想起時脳波から想起言語を識別する BCI 研究が始まっている．音声想起識別では想起区間を検出せず，ノイズを含む区間を想起対象データとして扱うため識別精度が低下する傾向にある．そこで想起言語の識別精度向上を目標に，本稿では音声想起時脳波における想起区間の推定について報告する．本報告では，定 Q 変換によるスペクトログラムをサンプル加算することで想起区間を得て，想起区間を基に 3DCNN で想起区間推定を行った．その結果，加算スペクトログラムで得た反応を想起区間として3DCNN に入力することで，約 80%の精度で想起区間推定に成功した．また，データを加算することで約 90%の推定精度を得た．
P7-9,一人称視点映像を用いたマルチモーダル作業支援システム,梶村恵矢|西村太一|羽路悠斗|山本航輝|崔泰毓|亀甲博貴|森信介,,P7:ポスター,実験や料理など，作業者が手順書に従って作業を行う状況において，不安のある手順や不明瞭な手順を映像として確認できることは作業の再現性向上に有効に働くと考えられる．また，映像中の作業者の視線情報や手元の細かな動作を確認できる点において，実際の作業者が確認する映像として一人称視点動画を用いることはメリットがある．本研究では広く人手で行う作業の再現性向上を目的とし，テキストと音声による入力機能を持った一人称視点動画を用いたマルチモーダル作業支援システムを提案する．また，実験では作業負荷や作業完成度にシステムが与える影響を調べ，システムが負荷の軽減や完成度の向上に寄与するかを考察する．
P7-10,視覚的文脈を利用した視覚言語モデルによる画像キャプション生成自動評価手法,前田航希|栗田修平|宮西大樹|岡崎直観,,P7:ポスター,既存の画像キャプション生成の品質自動評価は，画像に映る物体への言及を過大評価するほか，物体の特性や関係といった細かい言及の間違いを見過ごすなど，人間の判断に近い評価をするには未だ不十分である．本稿では，視覚言語モデル（VLM）を用いた画像キャプション生成の自動評価手法としてVisCE2を提案する．本手法は，VLM が持つ視覚理解能力によって，画像に写る物体の属性や関係を含めた視覚的文脈を明示的に言語化し，VLM の言語理解能力によって視覚的文脈を考慮した評価を可能にする．メタ評価実験を通じて，VisCE2は既存手法と同等以上の人手評価との相関を示し，視覚的文脈の追加が評価性能を向上させることを実証した．
P7-11,講演動画の言語横断字幕生成のための英日マルチモーダル対訳コーパスの構築,寺面杏優|近藤里咲|梶原智之|二宮崇,,P7:ポスター,本研究では、英語の講演動画とその日本語字幕からなるマルチモーダル対訳コーパスを構築し、公開する。動画からの言語横断字幕生成では、音声認識のエラーが伝播して翻訳品質が劣化してしまう。この課題に対処するために、音声認識文に加えて音声や画像を参照するマルチモーダル機械翻訳が有望である。我々は、このようなマルチモーダル機械翻訳の研究に取り組むために、既存の英日対訳コーパスに対して画像・音声・音声認識文を付与した約 10万文対のマルチモーダル対訳コーパスを構築した。英日翻訳における実験の結果、音声認識文の誤り訂正によって、翻訳品質の改善を確認できた。
P7-12,Combining Large Language Model with Speech Recognition System in Low-resource Settings,◊李勝|楊正東|周汪勁|褚晨翚|ChenChen|ChngEngSiong|河井恒,,P7:ポスター,"This paper investigates integrating automatic speechrecognition (ASR) with large language models (LLMs).The overarching goal of the paper is to validate the eﬀec-tiveness of integrating LLMs with ASR systems, with aspeciﬁc focus on low-resource settings. In our experiment,The LLM is utilized for second-pass rescoring to correcterrors in ASR outputs. We ﬁne-tune a Japanese-speciﬁcversion of the LLaMA model, named japanese-Llama-2-7b, feeding it with the Whisper-Large-v3 ASR model’sn-best output. The experiment shows that the proposedmethod eﬀectively enhances the ASR result, even in low-resource environments."
P7-13,Large Language Models as Manga Translators: A Case Study,◊ZhishenYang|ToshoHirasawa|EdisonMarrese-Taylor|NaoakiOkazaki,,P7:ポスター,"Originating in Japan, manga has gained immense popu-larity on a global scale as a distinct form of comics. How-ever, the primary language of manga, Japanese, is a barrierto its widespread access to international markets. Whilecrucial for its global expansion, manga translation is of-ten accompanied by substantial investment in time andresources. The emergence of machine translation technol-ogy presents the opportunity to automate manga translationprocesses, potentially reducing translation costs. How-ever, challenges arise due to copyright restrictions limitingtraining data access. This paper empirically explores thefeasibility of leveraging Large Language Models (LLMs)for manga translation tasks. Our study delves into inves-tigations to assess to what extent LLMs are capable ofperforming such a task and identify which contextual cueshelp enhance the quality of the output. The experimentalresults demonstrate the potential of employing the LLMin manga translation, indicating a promising trajectory forfuture research."
P7-14,EgoOops!データセット：手順書に従う作業の一人称視点映像への作業誤りアノテーション,羽路悠斗|西村太一|山本航輝|梶村恵矢|崔泰毓|亀甲博貴|森信介,,P7:ポスター,本研究の目的は，手順書に従う作業の一人称視点映像を，手順書を参照しながら解析し，作業の誤りの時間区間と種類を予測することである.まず，手順書に従う 5 つの作業，合計 50 本，6.8 時間の一人称視点の作業映像を撮影し，EgoOops!データセットを構築する．映像には，事前に定義した誤りの種類と，詳細な説明文を付与している．また，大規模な一人称視点映像と言語のペアで事前学習したモデルを用いて，手順認識と作業誤り分類を統合的に行う手法を提案する．手順認識で 36.9，作業誤り分類で22.3 の F1 スコアであった．映像のみを用いた結果との比較から，手順書の参照が作業誤り分類に有効だとわかった．
P7-15,一人称視点に基づくテキスト駆動型アフォーダンス及び軌跡の学習,吉田智哉|栗田修平|西村太一|森信介,,P7:ポスター,視覚的アフォーダンス学習は，入力画像中のインタラクションするべき領域を局限する課題である．先行研究によって，この課題がロボットの把持課題に有効であることが示されている一方で，多様な行動に対するアフォーダンスの学習が次の問題となっている．本研究では，この問題の解決のためにテキスト駆動型視覚的アフォーダンス及び軌跡の学習を提案する．この課題は，テキストで表現された様々な行動に対して，それを達成するために，画像中のどの領域に，どのようにインタラクションするべきかを学習することを目的とした課題である．この課題を解決するために，一人称視点動画データセットから自動で擬似教師データセットを構築し，それを利用したモデルを提案する．実験の結果，提案手法が先行研究のモデルと比べて優れた性能を示したことを報告する．
P7-16,PORTER:最適輸送を用いたPolygon Matchingに基づく参照表現セグメンテーション,九曜克之|飯岡雄偉|杉浦孔明,,P7:ポスター,自然言語による指示で生活支援ロボットが操作できれば便利であるが，現状，生活支援ロボットの命令文理解性能は十分ではない．そこで，本研究では，複数の参照表現を含む命令文および画像から動作対象の物体のマスクを予測するタスクを扱う．既存研究では，頂点の順番は異なるが同じ多角形を表す場合を区別して扱っているため，正解と近い多角形を予測しているにも関わらず，異なる多角形と判断してしまい，不適切な学習を促してしまうという問題がある．そこで本論文では，複雑な参照表現を含む命令文から対象物のマスクを生成するセグメンテーションモデルを提案する．本手法の新規性は，最適輸送を用いた Polygon Matching Loss の導入である．命令文，室内環境の画像，対象物のマスクで構成されるデータセットによる評価の結果，提案手法は標準的な評価尺度である mean IoU において，ベースライン手法を 10.41 ポイント上回った．
P7-17,レストラン検索・予約サイトの投稿画像分類におけるマルチモーダルモデルの適用検証,柳沢勇気,,P7:ポスター,レストラン検索・予約サイトの投稿画像を「料理」や「ドリンク」といった種別に分類することは，ユーザーが目的の写真を効率よく閲覧することに貢献する．大量の画像を人手で分類するのは多大な時間と労力を有するため，自動分類モデルを用意するのが望ましい．しかし，従来の教師あり学習モデルは学習データの作成にコストがかかる．そこで，大量の画像−テキストペアで事前学習されたマルチモーダルモデルを使うことで，学習データ作成にかかるコストを無くし，画像をゼロショットで自動分類することを試みた．その結果，複数の画像種別において実用的な分類性能を達成し，人手による作業を大幅に削減できることを確認できた．
P7-18,サッカー実況中継を付加的情報の提供という側面から見る,森雄一郎|前川在|小杉哲|船越孝太郎|高村大也|奥村学,,P7:ポスター,本稿では，スポーツ実況における付加的情報の提供という側面に焦点を当てる．これまでの実況生成に関連する研究は，主要なイベントが起こった際映像上の内容を細かく記述するタスクの解決を志向している．しかし，現実のスポーツ実況者は，主要なイベントを取り上げるだけでなく，映像に関連する付加的な情報を提供し，観客の知的好奇心を満たす．本研究では，大規模言語モデルを用いて実際のサッカーの試合中継における実況コメントを分析し，付加的情報の提供を担うコメントの割合を調査する．そして，分析により，付加的情報が現実の実況に多く含まれていることを示すとともに，今後の実況生成の研究において付加的情報を考慮する必要があることを主張する．
P7-19,日本語投機的デコーディングの検討,林崎由|能勢隆|伊藤彰則,,P7:ポスター,投機的デコーディングは，言語モデルによるテキスト生成において，出力の精度を低下させることなく推論を高速化する手法として注目を集めている．この手法ではドラフトモデルと呼ばれるより小規模な言語モデルを利用することで生成の一部並列化による推論速度の向上を実現している．一方，これまでの検討は英語が中心であり，日本語などの言語固有の性能やドメイン依存のメカニズムについては明らかになっていない．本研究では，日本語を対象として，モデルサイズの異なる複数の事前学習済み言語モデルに基づきドラフトモデルを構築し，日本語要約タスクにおける投機的デコーディングの効果検証およびトークン単位での詳細な分析を行う．
P7-20,Improving the Image Discrimination Ability for CLIP-Model via Semantic Graphs through Graph Convolutional Network,SangmyeongLee|SeitaroShinagawa|KoichiroYoshino|SatoshiNakamura,,P7:ポスター,"The Contrastive Language-Image Pre-training (CLIP)model is based on plain textual inputs, leading to a chal-lenge in handling structural ambiguity residing inside atext. This paper examines the eﬀectiveness of semanticgraphs, the graph format representation converted fromsyntax trees, using a graph convolutional network (GCN)as the CLIP model’s input to address this challenge. Addi-tionally, we leverage the integrated gradient methodologyto analyse how semantic graphs are interpreted within themodel’s architecture."
P7-21,大規模視覚言語モデルに関する指示追従能力の検証,塩野大輝|宮脇峻平|田中涼太|鈴木潤,,P7:ポスター,大規模言語モデル（LLM）の隆盛を背景に，視覚言語モデルに LLM を組み込んだ大規模視覚言語モデル（LVLM）の提案が盛んに行われている．しかし，追加学習後の LVLM は組み込まれる前の LLMが有していた指示追従能力を示さず，タスク指示に従わない事例が観測されている．そこで本研究では，追加学習後の LVLM の指示追従能力が低下することを世界で初めて定量的に示し明らかにする．さらに LVLM の指示追従能力の低下の原因となる要素を洗い出し，モデルの指示追従能力を評価した結果，追加学習時の出力形式に関する指示の有無が指示追従能力の低下に大きな影響を与えている可能性があることを示す．
P7-22,語義曖昧性解消に着目した英日マルチモーダル機械翻訳の評価セット構築と分析,佐藤郁子|平澤寅庄|金輝燦|岡照晃|小町守,,P7:ポスター,"マルチモーダル機械翻訳(MMT)は,画像を用いた文脈補完によって単語の曖昧性を解消することを目的としている.しかし,既存 MMT モデルによる品質改善は限定的で，その理由に評価ベンチマークの制限が挙げられる.既存 MMT 評価セットに含まれるほとんどの原文は明瞭であり,翻訳に画像を必要としないため,視覚情報の効果を正確に評価できない.そこで,本研究では正しい翻訳を行うために画像が必要な英日 MMT のベンチマークを提案する.既存MMT モデルを本データセットで評価した結果,翻訳品質のわずかな向上が確認された.この結果から,既存 MMT モデルは画像を必要とするシナリオにおいても画像を十分に活用できていないことがわかる."
P7-23,Evaluation of the Adversarial Robustness in LLM-based Visual Dialog System,◊YahanYu|FeiCheng|ChenhuiChu,,P7:ポスター,"Large Language Models (LLMs) are widely employed.However, their susceptibility to adversarial attacks posesa signiﬁcant security concern. In this paper, we focuson LLM-based visual dialog systems and delve into theirsensitivity in the aspect of both visual attack and textualattack. Our work aims to investigate the robustness ofthese systems, and give researchers the understanding ofthe security challenges that LLMs may face in practicalapplications."
P7-24,Out-of-distribution Shape Generation using Large Language Models and Geometry Nodes,◊YutaroYamada|MachelReid,,P7:ポスター,"Recent advancements in text-to-image models have beenimpressive. Yet, they still struggle with accurately fol-lowing prompts, especially when asked to create out-of-distribution objects like a “chair with three legs.” Inthis paper, we introduce a novel method using “GeometryNodes”–a procedural generation tool for creating shapes inBlender, which is a 3D modeling software. This tool allowsfor the generation of shapes based on general parameterslike ’radius’ and ’height.’ We use a large language model(LLM) to interpret text prompts and convert them into spe-cic instructions for these shape generators. Our methodhas proven eective in creating unconventional examplesin two categories: Chairs and Tables."
A8-1,土木分野におけるLLMを用いた言語モデル評価手法の提案,緒方陸|大久保順一|藤井純一郎|天方匡純,,A8:LLM分析評価(4),土木分野においても自然言語処理技術への期待は大きく，近年実用へ向けた検討が増加している．この技術が充分に機能するためには，文脈を考慮した土木専門用語の言語モデルによる理解が必要であり，その適切な評価が求められる．しかし，既往研究はいかに土木分野へ適応させるかに焦点を当てた研究が多く，言語モデルの文章生成能力の評価には重きが置かれていない．そこで本研究では，土木分野における言語モデルの性能評価のため，評価の際に一度 LLM で要約することで評価を行う自動評価手法を提案する．語彙数が多く回答長が長い場合には，既往手法に比較して本手法が有効に働き，より人手評価に近い結果となることを示した．
A8-2,llm-jp-eval: 日本語大規模言語モデルの自動評価ツール,NamgiHan|植田暢大|大嶽匡俊|勝又智|鎌田啓輔|清丸寛一|児玉貴志|菅原朔|BowenChen|松田寛|宮尾祐介|村脇有吾|劉弘毅,,A8:LLM分析評価(4),日本語の大規模モデルが次々と発表される中，その自動評価が重要性を増している．本稿では，日本語の大規模言語モデルに対する評価ベンチマーク llm-jp-eval を提案する．llm-jp-eval は 8 カテゴリ，計12個の日本語の自然言語処理の公開評価データを用いて，言語モデルの生成結果を自動的に評価する．評価は全て生成問題に基づくもので，既存の評価データセットにプロンプト形式を適用して自動変換した問題に対する言語モデルの回答を評価する．本稿では llm-jp-eval を用いて様々な日本語大規模言語モデルを評価した結果を報告し，既存研究の知見に照らして議論する．
A8-3,日本語小説の発話者分類における大規模言語モデルおよび規則の評価,古俣槙山|銭本友樹|宇津呂武仁,,A8:LLM分析評価(4),小説中の発話文の発話者がどの登場人物かを分類する発話者分類タスクは小説や登場人物の分析において重要なタスクである．本論文では大規模言語モデル・規則に基づく手法・BERT をこの発話者分類タスクに適用した際の性能を『現代日本語書き言葉均衡コーパス』とウェブ小説の話者情報アノテーションデータを用いて評価する．この結果，大規模言語モデルの正答率は他手法より優れた値，あるいは同等の高い値となり，発話者分類における大規模言語モデルの利用が効果的であることを示した．
A8-4,ChatGPT as a Translation Engine: A Case Study on Japanese-English,◊VincentMichaelSutanto|GiovanniGattiDeGiacomo|ToshiakiNakazawa|MasaruYamada,,A8:LLM分析評価(4),"This study investigates ChatGPT for Japanese-Englishtranslation, explor ing simple and enhanced prompts andcomparing against commercially available translation en-gines. Performing both automatic and MQM-based hu-man evaluations, we found that document-level transla-tion outperforms sentence-level translation for ChatGPT.On the other hand, we were not able to determine if en-hanced prompts per formed better than simple prompts inour experiments. We also discovered that ChatGPT-3.5was preferred by automatic evaluation, but a tradeoﬀ existsbetween accuracy (ChatGPT-3.5) and ﬂuency (ChatGPT-4). Lastly, ChatGPT yields competitive results against twowidely-known translation systems."
A8-5,継続事前学習による日本語に強い大規模言語モデルの構築,藤井一喜|中村泰士|MengsayLoem|飯田大貴|大井聖也|服部翔|平井翔太|水木栄|横田理央|岡崎直観,,A8:LLM分析評価(4),"本研究では，Llama 2 をベースに日本語の大規模ウェブコーパスで継続事前学習を行い，日本語能力を強化した大規模言語モデル Swallow を構築した．実験から，7B, 13B, 70B のいずれのモデル規模においても，継続事前学習が大規模言語モデルの日本語能力を引き上げ，高い性能を達成することが分かった．また，継続事前学習の学習データ量の増加に伴い，日本語の性能が向上すること（学習のスケール性）を確認した．構築した Swallow モデルを公開し，コミュニティでの後続研究・活用を期待している．"
A8-6,デコーダベースの事前学習済み言語モデルの多言語能力に関する分析：言語固有ニューロンの検出と制御,小島武|沖村樹|岩澤有祐|谷中瞳|松尾豊,,A8:LLM分析評価(4),近年のデコーダベースの事前学習済み言語モデル（PLM）は，多言語能力の発現に成功している．しかし，モデル内部でそれぞれの言語がどのように扱われているかは明らかではない．我々は，多言語に対応したデコーダベースの PLM 内における，言語ごとに独自に発火する言語固有のニューロンの内部挙動を解析した．具体的には，英語，ドイツ語，フランス語，スペイン語，中国語，日本語の 6 言語を分析し，言語固有のニューロンは言語間でわずかな重複（＜ 5 ％）があるものの言語固有であり，その多くはモデルの最初と最後の数層に分布していることを示した．この傾向は，言語やモデルを問わず一貫していることを確認した．また，推論時に言語固有ニューロンの発火値を改ざんすることで，テキスト生成において指定した対象の言語が生起する確率を顕著に変更できることを示した．
B8-1,都議会議事録における自動要約のための数値情報自動修正手法の提案,松井我颯|中島陽子|本間宏利|秋葉友良|石川晴基,,B8:事実性・安全性検証,自動要約技術は地方議会の議事録やネットニュースなどの情報の処理に有用だが，生成型要約において数値情報の誤りが問題となっている．本研究は，自動要約における数値情報の正確性を向上させるため，原文との比較に基づく修正手法を提案する．提案手法は，数値情報の誤りを特定し，原文に即した正確な数値への修正を可能にすることで，より信頼性の高い要約生成を目指す．
B8-2,大規模言語モデルによる時系列を考慮したフェイクニュース生成,原悠貴|YinJouHuang|FeiCheng,,B8:事実性・安全性検証,大規模言語モデルの登場により，フェイクニュース検出タスクに新たな課題が生じている．既存の検出タスクの多くは，その F1 スコアが 90%を超えている．これは 1 つのニュース記事だけに着目し，その言語的特徴等を手掛かりにした，簡易的なタスク設定が原因と考える．そこで本研究では，大規模言語モデルを用いて，既存のフェイクニュース検出器に検出されにくいフェイクニュースの生成を試みた．具体的には，時系列順に並んだ複数の記事に着目し，論理的に一貫したフェイクニュースを生成することを目標にした．
B8-3,事実正誤判定が不要な生成応答の検出に向けたデータセットの収集と分析,亀井遼平|塩野大輝|赤間怜奈|鈴木潤,,B8:事実性・安全性検証,大規模言語モデルが顕著な発展を遂げる中，出力の事実性の担保が課題となっている．しかし対話という分野では，システム応答中の全ての内容が与えられた知識に基づいていることが必ずしも良いことであるとは限らない．我々は対話としての魅力度と事実性担保の両立を目標とし，その第一歩として相槌や同意，個人的な意見/感情といった事実正誤の判定が不要である文を予測することをタスクとして設定した．本研究では，このタスクのための学習・評価データセットをクラウドソーシングを通じて収集し，複数の分類モデルを用意して実験を行った．実験の結果，最も分類精度が高いモデルで約 88 ポイントの正解率で分類できることを確認した．
B8-4,科学技術論文を対象とした根拠付き生成型要約システムの構築,笠原智仁|村田栄樹|河原大輔,,B8:事実性・安全性検証,本研究では日本語の科学技術論文を対象として、抽出型要約と生成型要約を融合した根拠付きの生成型要約システムを構築する。具体的には、論文本文から抽出型要約を作成し、それを大規模言語モデルによって言い換えることによって生成型要約を生成する。抽出型要約によって本文から抽出された文が生成された要約の根拠となり、言い換えによって自然な文章を生成することが可能となる。評価の結果、本文から直接要約を生成する生成型要約モデルと比較して、幻覚の生成が減少することを確認した。
B8-5,モデル介入を用いる Jailbreak prompt 攻撃の初期応答の選択手法,ThienQ.Tran|綿岡晃輝|髙橋翼,,B8:事実性・安全性検証,"大規模言語モデル（LLM）の広範な応用には,安全性の確保が求められる. LLM に不適切なコンテンツを生成させるための入力である jailbreak prompts攻撃は, LLM の安全な運用にとって重大な脅威である.従来の jailbreak prompts 手法は,有害な生成の継続を前提として,肯定的な初期応答を生成するようにプロンプトを最適化する.本研究は適切な初期応答の選択の重要性とそれに伴う困難に注目する.攻撃の成功へ導く初期応答を効果的に選択するために,モデル介入を用いる選択手法を提案する.実験により,この方法が適切な初期応答を正確に選択する能力を大幅に向上させ,攻撃成功率を高めることを示した."
B8-6,逆学習による言語モデルの解析,磯沼大|IvanTitov,,B8:事実性・安全性検証,大規模言語モデルの高い能力を発揮させ、かつ有害な生成を抑えるには、その原因となる学習データの特定が不可欠である。理想的には、各学習データを除いて再学習したモデルを評価することで各データの影響を測ることができるが、計算コストが膨大になり現実的ではない。本稿では学習データを除く代わりに、学習済モデルから各データを逆学習してその影響を測る手法を提案する。本手法は極めて単純で、勾配上昇法で学習データを逆学習し、逆学習後のモデルの性能が悪化するほど、その学習データの影響が大きいと推定する。本手法は既存手法に比べ膨大なメモリやチェックポイントの保存を必要とせず、かつ評価実験で高い性能を示した。
C8-1,日本語ヘイトスピーチ検出における疑似ラベルを用いた精度向上効果の検証,鍛原大成|倉嶋将矢|櫻井義尚,,C8:言語資源・アノテーション(2),本論文では，疑似ラベルを付与したデータセットを学習させることで，人間がラベリングせずに高精度のヘイトスピーチ検出モデルが構築可能であることを示す．この方法により，日本語ヘイトスピーチのラベル付きデータセットの作成にかかるコスト削減が期待できる．検証では，人間がラベリングしたデータセットと疑似ラベルを付与したデータセットを用いて学習した時の精度を比較した．その結果，人間がラベリングしたデータセットの精度よりは劣るが，LLM により疑似ラベルを付与したデータセットの F 値が 0.5，正解率が 0.9 を達成した．そのため，LLM により疑似ラベルを付与したデータセットが精度向上に有用であることが分かった．
C8-2,ELECTRA単語分散表現とLightGBMを使った固有表現抽出,徳永一輝|石田希望|川端篤|岩山幸治|南條浩輝,,C8:言語資源・アノテーション(2),専門分野における固有表現抽出は，ビジネスにおけるニーズが強いが，学習データを作成するアノテーションコストが高いことが課題である．本研究では，対象とするドメインとして自動車部品用語に着目し，少数の自動車部品用語の辞書を元にして，テキストデータから自動車部品用語を抽出し，自動車部品辞書を拡張する方法を提案する．人手でアノテーションした検証データで評価実験を行い，提案手法による固有表現の抽出と辞書の拡張の有効性を確認した．
C8-3,LLMを用いた不適切発話データの自動生成に関する研究,大賀悠平|長谷川拓|西田京介|齋藤邦子,,C8:言語資源・アノテーション(2),大規模言語モデル（LLM）の抱える問題点の一つに，暴力的な表現や性的な表現などユーザに不快感を与える不適切な発話をしてしまう問題がある．これらの不適切発話を検出・抑制するモデルの学習には不適切発話データが必要となるが，人手で全てのデータを作成すると非常に大きなコストがかかってしまう．本研究では，LLM を用いることで人手による作成コストを抑えつつ不適切発話検出・抑制モデルの学習データを作成することを目指す.公開LLM を用いて不適切発話データの作成実験を行った結果，LLM で生成されたデータの品質を高めるには人手アノテーション等の対応が必要であるが，人手コストを低減できることを明らかにした．
C8-4,固有名詞置換による共参照解析データセットの拡張,富村勇貴|上垣外英剛|渡辺太郎,,C8:言語資源・アノテーション(2),共参照解析は共参照情報のアノテーションが高コストであるため、深層学習の際に利用できるデータセットが限られているという問題がある．そこで本研究では，共参照解析において学習データ内の共参照クラスターに含まれる固有名詞を別の固有名詞に置換することでデータセットを拡張し，拡張データで学習した共参照解析モデルの性能を向上させることを目的とする．実験の結果，人物名の固有名詞を性別と特殊な例を考慮してランダムに置換する方式で拡張したデータセットで学習したモデルがベースラインモデルの性能を僅かに上回り，訓練データにおいて未知の固有名詞に対しての予測精度が向上していることがわかった．
C8-5,固有表現抽出における大規模言語モデルを用いた自動アノテーション,楢木悠士|山木良輔|池田愛和|堀江孝文|長沼大樹,,C8:言語資源・アノテーション(2),固有表現抽出（NER）は自然言語処理の重要なタスクであり，幅広く応用されている．しかし，人手によるアノテーションは，コストの高さ・倫理的問題・品質の一貫性・機密情報保護等の問題が喫緊の課題である．本研究では，大規模言語モデル（LLMs）から生成したアノテーションを人手によるものと統合することで，この課題に取り組む．また，LLMs によるアノテーションではクラス分布の不均衡が引き起こるという副次的な問題を特定し，対処策として Label Mixing を提案する．提案手法により NER タスクの性能を強化するだけでなく，コストの大幅な効率化を図る．複数のデータセットで比較した結果，提案手法は，同一のアノテーションコスト下で，人手のアノテーションに比べ高い性能を示しただけでなく，学習データセットの品質が低い場合に顕著な性能の安定性向上に寄与した．
C8-6,森羅プロジェクト,関根聡|宇佐美佑|門脇一真|三浦明波|中山功太|安藤まや,,C8:言語資源・アノテーション(2),Wikipedia に書かれている世界知識を計算機が扱えるような形に変換することを目的として，2017年より Wikipedia を構造化する「森羅」プロジェクトを推進してきた．本プロジェクトは「協働による知識構築（Resource by Collaborative Contribution）」のスキームに基づき，評価型ワークショップを開催し，参加したシステムの結果を統合してより良い知識にまとめ上げ，それを公開していくことを目指した．本稿では 2017 年から行ってきた森羅プロジェクトを総括し，プロジェクト終了時に残す成果を整理して報告する．
D8-1,テキスト平易化の品質推定のための擬似訓練,廣中勇希|梶原智之|二宮崇,,D8:テーマセッション１：人間と計算機のことばの評価(1),本研究では，テキスト平易化の品質推定の性能改善のために，事前訓練モデルのファインチューニングの前に擬似的な品質推定の訓練の実施を提案する．品質推定のラベル付きデータは構築コストが高く，テキスト平易化の品質推定のために利用可能な英語の既存データは 600 件と小規模である．この少資源問題を緩和するために，品質ラベルを持たない既存のテキスト平易化パラレルコーパスを用いて，所与の 2 文のどちらがより平易かを判定する擬似的な品質推定の訓練を大規模に実施する．3 種類の事前訓練モデルを対象とする英語のテキスト平易化の品質推定における実験の結果，提案手法は平易性だけでなく同義性に関しても性能を改善できた．
D8-2,最適輸送に基づく擬似訓練データを用いた機械翻訳の品質推定,黒田勇斗|藤田篤|梶原智之,,D8:テーマセッション１：人間と計算機のことばの評価(1),人間が作成した参照訳を用いずに機械翻訳文のどの部分に修正が必要かを推定するタスクを単語レベルの品質推定という．単語レベルの品質推定の性能を向上させるため，擬似訓練データの活用に関する研究が行われている．擬似訓練データは，機械翻訳文中の各語のラベルを参照訳との表層的な対応に基づいて定めることが多いが，この方法では表層が異なる単語が実際に翻訳品質を損なうか否かを適切に判断できない．そこで本稿では，最適輸送に基づく擬似訓練データを用いた品質推定モデルを提案する．WMT21 のデータセットを用いた実験の結果，提案モデルは，従来の擬似訓練データを用いた品質推定モデルを上回る性能を示した．
D8-3,対義関係バイアス: 事前訓練済み言語モデルと人間の意味関係間の弁別能力に関する分析,CaoZhihan|山田寛章|徳永健伸,,D8:テーマセッション１：人間と計算機のことばの評価(1),意味関係の弁別は，人間にとっても，機械にとっても，容易なタスクではない．本研究では，多様な下流タスクで卓越した性能を示した事前訓練済み言語モデルが意味関係の弁別ができているか否かという問いに，混淆度という尺度を提案し，人間との比較の上でアプローチした．結果として，事前訓練済み言語モデルは，意味関係の弁別能力は，人間に比べて下回ることと同時に，非対義関係を対義関係として誤認識するバイアスが観察された．
D8-4,同時通訳・同時翻訳のための語順同期性評価,蒔苗茉那|須藤克仁|中村哲,,D8:テーマセッション１：人間と計算機のことばの評価(1),英日のような文法が大きく異なる言語ペアにて、同時通訳者はリアルタイムで訳出を行うために、原発話の語順を可能な限り維持して遅延を最小化しつつ品質を維持しているとされている。これは原発話の語順と同期した出力が望ましいことを意味し、機械による同時通訳や同時機械翻訳もこのような訳出スタイルを模倣することが発展の鍵となる。そこで本研究では順位相関係数と多言語BERT を使用して、語順同期性に着目した同時通訳(SI)と同時翻訳(SiMT)の自動評価指標を提案する。NAIST-SIC-Aligned と JNPC コーパスを用いた実験の結果、我々の評価指標が原発話と目的発話の間の語順同期の程度を計るのに有効であることが示された。
D8-5,文法誤り訂正における参照なし評価尺度を用いた分析的評価法,五藤巧|渡辺太郎,,D8:テーマセッション１：人間と計算機のことばの評価(1),文法誤り訂正における参照なし評価尺度は様々な利点を持つにも関わらず，その評価値の向上もしくは低下がどの訂正に起因するものなのかを分析することが難しい．本研究では，協力ゲーム理論におけるシャープレイ値の方法に注目し，訂正前と訂正後の文単位の評価値の差分を，訂正単位の評価値に分配する方法を提案する．これにより，全体の評価値に対する個々の訂正の貢献度を可視化し，分析を可能にする．実験では，実際の訂正をニューラルベースの尺度で評価する時の分析例を示す．また提案法の妥当性や将来的な応用について議論する．
D8-6,評価の階層性に着目した雑談対話システム評価の分析,蔦侑磨|吉永直樹,,D8:テーマセッション１：人間と計算機のことばの評価(1),文生成タスクでは，評価の解釈性向上のために多様な側面からの評価が期待される．複数の評価軸により評価を行う際，文評価に普遍的に見られる評価の階層性に注意する必要がある．評価軸間に階層的な依存性がある場合，依存先の評価値は依存元の評価値の影響を受けるため，誤った結論を導く可能性がある．本研究では雑談対話応答生成タスクの評価観点について，対話システム間の有意差を手掛かりに，評価軸間の階層的依存性を明らかにする試みを行った．さらには階層的な依存性を解消した場合のシステム間性能比較を再分析した．多様な観点で評価された雑談対話のデータセットを利用した実験から，階層的依存性の解消により対話システム間の性能有意差の有無が変化しうることを確認した．
E8-1,分散的ベイズ推論による創発コミュニケーションに基づくマルチエージェント強化学習,江原広人|中村友昭|谷口彰|谷口忠大,,E8:テーマセッション４：言語とコミュニケーションの創発(2),人は共同タスクを遂行する中で，他者や環境とインタラクションすることによって，協調行動を学習することができる．また，互いの内部状態を表現したメッセージを伝達し合うことで，互いの状態を知ることができる．このように，コミュニケーションを通じて互いに理解できる記号が創発される過程のことを，創発コミュニケーションと呼ぶ．これまで，マルチエージェント強化学習によって協調行動を学習する研究が行われおり，これらの研究では主にエージェント同士をネットワークで接続して学習するアプローチが取られていた．しかしこれは，独立した個体同士の創発コミュニケーションの観点からすると，不自然な設定である．そこで本稿では，創発コミュニケーションとマルチエージェント強化学習を組み合わせることで，エージェント間をネットワークで接続することなく，協調行動を学習できるモデルを提案する．実験では，エージェント同士が協調し，異なるゴールに到達する移動タスクを行い，適切な協調行動を学習できることを示す．また提案手法が，エージェント同士をネットワークで接続して学習する従来手法と同等の性能を発揮できることを示す．
E8-2,ガウス過程に基づく確率的生成モデルを用いたマルチモーダル情報に基づく連続的な記号の創発,劉智優|江原広人|中村友昭|谷口彰|谷口忠大,,E8:テーマセッション４：言語とコミュニケーションの創発(2),記号システムはエージェントが他者や環境と相互作用しながら集団の中でボトムアップに創発する．この記号創発現象のメカニズムを明らかにするために，構成論的研究が進められている．その一つとして，記号創発現象を集団的な潜在変数の推論と捉えた，集合的予測符号化仮説に基づく確率的生成モデルが提案されている．このモデルでは，分散的ベイズ推論によって，2 体のエージェント間で共有された離散的な記号が創発されることを示した．ただし，このモデルでは記号を離散的な変数としてモデル化しているが，記号は必ずしも離散的なものに限定されるものではない．例えば，言語は離散的なテキスト列だと簡略化され捉えられがちであるが，人類は音声という連続的なメディアを通して言語を発達させている．この意味で連続的な記号メディアの創発の構成論を議論することは，離散的な記号の構成論を補う形でも重要である．そこで本稿では，ロボットが取得するマルチモーダルな情報から，連続的な記号の創発が可能な確率的生成モデルを提案する．観測の生成モデルにガウス過程を利用することで，マルチモーダルな観測から連続的な記号を創発することが可能である．実験では，マルチモーダルな観測から記号が創発されること，さらに創発された記号が正しくエージェント間で共有されていることを示す．
E8-3,文字列中からの単語の発見と感覚情報に基づく単語の意味づけを通じた SIR 名付けゲームによる言語の創発,堀江孝文|谷口彰|萩原良信|谷口忠大,,E8:テーマセッション４：言語とコミュニケーションの創発(2),相互分節化仮説とは，複数のエージェントによる文のやり取りを通じ，文の分節化と状況の分節化が同時に行われることで，人間の言語が誕生したとする仮説である．本研究では，相互分節化仮説に着想を得て，観測した感覚情報を表現する文字列のやり取りを通じ，エージェントが文字列中から単語を発見し，単語と分類された感覚情報の関係を推論することで，言語が創発する過程のモデル化を目指す．そこで本稿では，教師なしで文を分節化するためのモデル NPYLM と，色や形といった複数の属性を含む感覚情報と単語との結びつきを学習する交差状況学習のモデル CSL-PGM を統合してエージェントを構成し，二体のエージェントを接続したモデルInter-CSL+NPYLM を構築する．また，エージェント間における推論を，文のやり取りに基づく言語ゲームである SIR 名付けゲームにより実現する．実験では，提案手法が比較手法よりもエージェント間の発話の編集距離を小さくすることが確認された．一方で，提案手法が文の分節化誤りの影響を大きく受けたことで，エージェント間で多くの単語が共有されなかったことも明らかになった．
E8-4,統語変形はコミュニケーションから創発するのか？,梶川康平|窪田悠介|大関洋平,,E8:テーマセッション４：言語とコミュニケーションの創発(2),自然言語には合成性にもとづく統語構造が存在し、さらに統語構造を直接変形する操作（統語変形）が存在する。先行研究において、合成性はコミュニケーションと学習可能性に関する圧力のトレードオフとして創発することが示されている。しかしながら、自然言語になぜ統語変形が存在するのかは明らかではない。本研究では、統語変形を必要とする統語現象として等位接続に注目した上で、統語変形もまたコミュニケーションと学習可能性に関する圧力のトレードオフとして創発するのかを検証する。
E8-5,個別化認知モデルを用いた音韻意識推定手法評価のための音声フィルタの検討,西川純平|森田純哉,,E8:テーマセッション４：言語とコミュニケーションの創発(2),言語が発達する過程の一部は，音声言語における音素やリズムなど音韻的側面への注意に関係する音韻意識という能力に支えられるとされる．本研究は，計算機モデルを活用した音韻意識の形成を支援するシステムの開発を目指す．ユーザの音韻意識は，複数の計算機モデルを搭載したシステムにおける，モデルへの相対的選好として推定される．本稿では，成人を対象とした実験設定でこの推定手法を評価する．システム出力（単語の発声）に音声フィルタをかけることで，未成熟な言語学習者の状態を模擬する．実験では，音声フィルタ（に模擬される学習者個人の特性）がモデルの相対的選好に影響するという仮説を検証する．結果として仮説は支持されなかったが，参加者の行動のばらつきから音声フィルタ設計に関する示唆が得られた．
E8-6,共同図形配置課題を行うシステムの構築と分析,齋藤結|東中竜一郎|南泰浩,,E8:テーマセッション４：言語とコミュニケーションの創発(2),対話研究において，話者が知識や信念を共有する共通基盤の構築は重要な課題とされてきたが，その構築過程を分析した研究は多くない．我々は先行研究において，二名の作業者が共同で図形を配置する共同図形配置課題を対象に，共通基盤と考えられる図形への「名付け」に着目して様々な分析を行い多くの知見を得た．本研究では，得た知見を基に共同図形配置課題を行うシステムの構築，システムへの確率構造の導入，システム同士の対話の分析に取り組んだ．その結果，構築したシステムが共同図形配置課題を行えること，相手の認識を想定して発話を生成する確率構造の導入が基盤構築を進め，共同図形配置課題を成功に導くとの示唆を得た．
P8-1,TED 講演音声の機械翻訳のためのデータ拡張法の比較,増田健人|山本一公|中川聖一,,P8:ポスター,本稿では Transformer を用いた翻訳モデルの性能改善の為に英日・日英を対象とした単一方向翻訳モデル及び双方向翻訳モデルの比較、種々のデータ拡張法の比較を行った。拡張手法では先行研究の手法[1]に加え、翻訳モデルにオートエンコーダ部分を追加した手法、オートエンコーダによる生成文を疑似コーパスとして用いた方法、英韓のパラレルデータを併用したマルチリンガルでの翻訳モデルの学習を行い、テキスト翻訳と音声翻訳の有効性を報告する。
P8-2,過去クエリを介した関連文書検索システム,須賀幹太|宮本琳太郎|桂尚輝|梅澤慶介,,P8:ポスター,多くのサービスではユーザーが困った際に質問フォームから問い合わせをすることができる。問い合わせに対して関連するヘルプガイドを自動で検索・推薦できれば、問題解決までの時間削減に寄与できる。また、ChatGPT を始めとする LLM を用いた文章生成において、関連ガイドをコンテキストとして渡すことで正確な返答文章の生成が可能になる。そこで本研究ではユーザーからの新規クエリに対して、過去のクエリとその返信文を経由することで関連ガイドを高精度に検索する手法を提案する。提案手法と新規クエリから直接ガイド文章との類似度を計算する既存手法を比較した結果、提案手法は高精度に文章を検索できることが分かった。
P8-3,論文におけるURLによる引用を考慮した引用要否判定,和田和浩|角掛正弥|松原茂樹,,P8:ポスター,論文執筆や査読支援に向けて，ある文に引用が必要か否かを判定する引用要否判定が行われている．既存研究は文献タグによる引用のみを対象としているが，学術論文では URL による引用（以下 URL 引用）も行われる．データセットなどの引用は URL引用で実施されることが多く，それらの引用も引用要否判定の対象に含める必要がある．本論文では，文献タグによる引用に加え，URL 引用を対象とした引用要否判定を提案する．データセットを作成し1），既存手法の性能を確認した結果，URL 引用に限った再現率は低く，改善の余地があることが判明した．また，URL 引用に特有の言い回しへの対応が課題であることが分かった．
P8-4,対話型検索のためのクエリ書き換えにおける大規模言語モデルの効果分析,阿部健也|竹岡邦紘|小山田昌史,,P8:ポスター,対話型検索は，対話の最後に与えられるユーザの質問に適合する文書を検索するタスクであり，対話の文脈に依存した質問を適切に書き換えるクエリ書き換えが主要なアプローチの一つである．大規模言語モデル(LLM)によって作成したクエリ書き換えで学習する手法は提案されているが，どのような場面でどの程度有効かは十分に調べられていない．本研究では，LLM による書き換えやそのデータを学習したモデルがどのような状況において有効であり，人手のデータを使う場合に比べてどのような性質があるかを調査した．実験の結果，LLM を利用すると元の質問との重複を避ける傾向にあり，元の質問から大きく書き換える必要のない事例を苦手とすることがわかった．
P8-5,ChatGPT による日本語常識道徳データセットの拡張,大橋巧|中川翼|彌冨仁,,P8:ポスター,近年の人工知能の発展や社会への参入により，人工知能に人間の一般的な道徳観を持たせることが望まれるが，現在公開されている学習させるための日本語常識道徳データセットではカバーしている事例が少ない．本研究では ChatGPT による事例のバリエーションを補うデータ拡張手法を提案する．既存の日本語常識道徳データセットを拡張したデータセットでモデルを学習・評価することで提案手法による性能の向上を確認するとともに，GPT-4 Turboによる推定結果と比較することで，拡張データセットで学習したモデルは日本特有の文化や道徳に対する理解が求められる事例に対して，より効果的な推定が可能であることが示唆された．
P8-6,大規模言語モデル開発における日本語 Web 文書のフィルタリング手法の検証,榎本倫太郎|ArsenyTolmachev|新妻巧朗|栗田修平|河原大輔,,P8:ポスター,日本語に強い大規模言語モデルの開発が活発化しており、その事前学習のために日本語の良質な大規模コーパスが求められている。しかし、大規模コーパスの中で大きな割合を占めるにもかかわらず、日本語 Web コーパスのフィルタリング手法は確立されていない。本研究では、日本語の Web コーパスに対して適切な自動品質フィルタリング手法を検証する。検証手法は、大規模言語モデルのコーパス構築で用いることを想定し、大量なデータでも比較的高速に処理できる小規模な分類器や言語モデルを選択する。Web コーパス品質評価ベンチマークをもとにこれらフィルタリング手法を評価した結果、最も精度が良い手法は N-gram 言語モデルであったが、強いフィルタリングが必ずしも下流タスクの性能向上につながるとは限らなかった。また、フィルタリングの過程で特定のトピックの割合が大きく減少した。
P8-7,新聞記事を対象としたSentence BERTを用いた経済政策不確実性の分類,桑名祥平|佐々木稔,,P8:ポスター,"本稿では, Sentence BERT のファインチューニングを用いて,経済政策不確実性に言及のある新聞記事を分類する手法の考案を行った. BERT やRoBERTa のファインチューニングを用いた従来手法のモデルと,本稿のモデルを F 値で比較することにより,提案手法の有効性を検証する.また,経済政策不確実性の有無に関するラベル付けを行う際,従来の単語マッチングによるラベル付けを行ったデータセットと,人手でラベル付けを行ったデータセットの両方を使用し,モデルへの影響度の検証を同時に行う."
P8-8,日本語タスクにおける LLM を用いた疑似学習データ生成の検討,藤井巧朗|勝又智,,P8:ポスター,大規模言語モデル(LLM)を用いることで，学習データが少量の状況においても高い性能が期待できることが報告されている．しかし，LLM はパラメータ数が多いため，推論コストが大きいという課題が存在する．そこで，本研究では 6 個の下流タスクにおいて，LLM から疑似学習データを生成し，そのデータで小規模モデルを学習する JapaGen が LLMにどの程度迫れるかを検証した．その結果，フォーマルなテキストを入力とする分類タスクで有効であることを明らかにした．
P8-9,ニュースソースの違いによるフェイクニュース検出と問題点,岸祐輝|中川翼|彌冨仁,,P8:ポスター,フェイクニュースを見破るのは難しい問題であり，機械学習技術を用いた検出が試みられている．しかし学習モデルが未来のニュースに対して適応できず適切な検出ができない点が懸念される．本研究では，機械学習モデルが学習した記事に対し，解析対象とするニュースの配信時期の違いや，ニュースソースが既知であるか否かの違い，タイトルや本文などの解析対象が検出精度にどの程度の影響があるかの検証を 100 万以上を収録する大規模なNELA-GT データセットを用いて解析した．未知のニュースソースに対する検出精度が著しく低下すること，データセットに由来する制限はあるが，著者と本文を組み合わせるのが特に有効だと分かった．
P8-10,大規模言語モデルを用いたニュース類似度の算出,井本稔也,,P8:ポスター,意味的テキスト類似度(Semantic Text Similarity)は，予め定めた基準に沿って２文書の類似度をスコア化するものである．金融分野ではニューステキストへの応用が考えられるが，地理的情報・エンティティ・時間・トピックなど，複数基準を総合判断する必要があるため，教師データセット作成の人的コストが高くなってしまう．本稿では，大規模言語モデル（LLM）を用い，少数のアノテーション済みサンプルを利用したニュース類似度の算出を試みた．特に，Few-shot、手がかり・推論の中間生成手法，自己整合性といったプロンプトエンジニアリング手法の有効性の検証を行い，SOTA の教師あり学習手法に迫る精度を達成した．更なる精度向上を目指すべく、地理的情報など各基準の類似度から段階的に解くサブタスク推論アプローチを検証し，提案モデルは SOTA と同水準の精度を達成した．
P8-11,テキスト分析による言語処理学会年次大会 29 年分の研究動向の調査,本間夏樹|飯村翔馬,,P8:ポスター,本調査では自然言語処理分野の研究動向の定量的な把握のため、言語処理学会年次大会の 29 年分の論文に対してテキスト分析を行った。先行事例では単語の集計が主だったが、本調査では係り受け表現の抽出やカテゴリ情報の付与を行うことでより実践的な情報の獲得を試みた。機関毎の発表傾向や共起分析による共著関係の可視化、研究分野やテキスト種別毎の論文数等についての分析を行い、定量的に知見を得ることを目指した。
P8-12,Translation Suggestion based on Pseudo Data generated from Word Alignment,◊FuzhuZhu|XiaotianWang|TakehitoUtsuro|MasaakiNagata,,P8:ポスター,"In this paper, we propose a method for generating pseudodata for WMT22 Translation Suggestion task using wordalignments. Furthermore, we also adopt the method ofData Augmentation to improve the ﬁnal performance of themodels. Meanwhile, we propose to apply the pre-trainedmT5 model to WMT22 Translation Suggestion task. Forthe results, our proposed approach exceeds the baselineon the Translation Suggestion direction of En-Zh pairs.In addition, the performance of the mT5 model illustratesthe possibility of applying pre-trained seq2seq model toWMT22 Translation Suggestion task."
P8-13,翻訳文の部分構造を制約とした機械翻訳,帖佐克己|上垣外英剛|渡辺太郎,,P8:ポスター,語彙制約付き機械翻訳は，指定された語句を訳語として含む文を生成するという制約の下で機械翻訳を行うタスクである．制約として指定する単位を語句からテキストの構造へ拡張することで，機械翻訳結果への操作性が向上することが期待できるが，これまで構造を制約としたニューラル機械翻訳は取り組まれてこなかった．そこで，本論文では，従来の語彙制約付き機械翻訳手法を拡張し，目的言語側の部分構造を制約とした機械翻訳を行う手法を検討する．
P8-14,漸進的な音声分割を用いたストリーミング同時音声翻訳,福田りょう|須藤克仁|中村哲,,P8:ポスター,同時音声翻訳モデルを実用化する際には、連続音声を逐次的に処理する必要があるが、近年の研究は音声が文等の短い単位に分割されたベンチマークデータを対象に行われており、連続音声の処理については十分に検討が行われていない。そこで本稿では漸進的な音声分割モデルを作成し、同時音声翻訳モデルと組み合わせて連続音声を処理するストリーミング同時音声翻訳システムを構築した。実験では、音声分割手法がトップラインの 94%以上の翻訳精度を維持できることを確認し、また音声分割における将来と過去の音声情報の重要性を検証した。
P8-15,タグ付き混合データ学習と自己教師あり学習による同時通訳データを用いたEnd-to-End同時音声翻訳,胡尤佳|福田りょう|西川勇太|加納保昌|須藤克仁|中村哲,,P8:ポスター,同時音声翻訳は、話し手の発話終了を待たずに漸進的に翻訳を行う技術である。高品質かつ低遅延の同時音声翻訳を実現するには、適宜省略や、話し手が話した内容をできるだけ早く訳出する等の、実際の通訳者の技法を同時通訳コーパスから学習することが有効であると期待される。本研究では、同時通訳データが不足している問題を軽減するため、同時通訳データに加えて話し手の発話終了を待ってから翻訳を開始する翻訳を前提としたオフラインデータと混合し、スタイルタグを用いて出力スタイルを区別する学習法を提案する。実験結果から、文の意味的類似度を測る評価における同時通訳テストデータでの翻訳性能向上の効果が、提案手法において示された。
P8-16,JParaCrawl v4.0: クラウドソーシングを併用した大規模対訳コーパスの構築,森下睦|帖佐克己|永田昌明,,P8:ポスター,現在の機械翻訳モデルは主に対訳コーパスを用いて学習されており、その翻訳精度は対訳コーパスの質と量に大きく依存している。本稿では、新たにウェブをクロールし日英対訳文を抽出することで大規模日英対訳コーパスを構築し、翻訳精度の底上げを狙う。なおこの際クラウドソーシングを活用して対訳文が存在するウェブサイトを発見することで、効率的な対訳文収集を目指す。今回ウェブから収集した対訳文と以前作成した日英対訳コーパスJParaCrawl v3.0 を合わせることで、合計 4400 万文を超える日英最大規模の対訳コーパスを作成することに成功した。実験により、新たな対訳コーパスを用いて学習した翻訳モデルが様々な分野で高い翻訳精度を発揮することを示す。なお、今回作成した対訳コーパスを JParaCrawl v4.0 と名付け、我々のウェブサイト上で研究目的利用に限り無償公開する予定である。1）
P8-17,単語難易度を考慮した反復的な翻訳文の平易化,大鹿雅史|森下睦|平尾努|笹野遼平|武田浩一,,P8:ポスター,近年，機械翻訳の精度は大幅に向上しており，機械翻訳の利用が広まっている．しかし，利用者の年齢によっては，機械翻訳によって出力された文章の語彙の難易度が高く出力文の意味を適切に理解するのが困難な場合がある．そこで，本研究では単語の難しさを語彙の獲得年齢(Age of Acquisition)[1]と定義し，修正すべき単語を指定した翻訳文の平易化手法を提案する．実験を通して，提案手法が文章の意味を保持したまま平易化を行うことができることを示す．また，本手法を反復的に利用することでより平易化が可能であることを示す．
P8-18,文内コンテキストを利用した分割統治ニューラル機械翻訳,石川隆太|加納保昌|須藤克仁|中村哲,,P8:ポスター,長文の翻訳は、ニューラル機械翻訳（NMT）における顕著な課題の一つである。我々は、分割統治アプローチに基づいてこの課題に取り組む。提案手法では、(1)入力文を等位接続詞を基準に節単位に分割し、(2)分割された各節を、文内コンテキストを考慮できる形で、節翻訳モデルを使用して翻訳し、(3)翻訳された節を集約して、別の Seq2Seq モデルを用いて最終的な翻訳を得る。ASPEC を用いた英日翻訳の実験結果から、41 単語以上の長い入力文において、mBART をファインチューニングしたベースラインよりも優れた BLEU を実現することが示された。
P8-19,言い換え文を用いた機械翻訳の学習データの増加,松本武尊|村上仁一,,P8:ポスター,NMT において，言い換え文を利用して，学習文を増加する手法がある．本論文では，外部コーパスを利用せずに言い換え文を生成する．そして，生成された言い換え文を用いて学習データを増加させ，機械翻訳の精度向上を試みた．その結果，自動評価結果では，わずかに精度が向上した．しかし，人手評価結果では学習文に言い換え文を追加しても精度に変化が見られなかった．
P8-20,Exploring the Potential of Prompt-Based Method for Kanji-Kana Conversion in Japanese Braille Translation,MicahKitsunai|DeborahWatty|Shu-KaiHsieh,,P8:ポスター,This study focuses on the challenge of polyphone disam-biguation in the automatic translation process of Japaneseinto Japanese Braille and explores the applicability of LargeLanguage Models (LLM) to this task. We propose amethod that includes additional information obtained byemploying a morphological analysis tool when promptingthe LLM. The results indicate that this combined approachenhances accuracy beyond the predictive capabilities ofmorphological analysis tools alone and also surpasses thestandalone use of the LLM.
P8-21,対訳関係にノイズのある対訳文からの新しい翻訳知識の学習,後藤功雄|衣川和尭|美野秀弥|河合吉彦|山田一郎,,P8:ポスター,ニュースでは新しい語彙や表現が出現するため，ニュースの機械翻訳では新しい語彙や表現の翻訳知識を学習していく必要がある．英語ニュースは日本語ニュースの単純な翻訳ではないため，日英ニュース記事から抽出できる対訳文は，対訳関係にノイズがある場合が多い．対訳関係にノイズがあるデータから翻訳を学習すると，ノイズも学習してしまうという課題がある．また，新しい表現は頻度が少ない場合が多く，低頻度の表現の学習は難しいという課題もある．そこで，ノイズの学習を抑え，低頻度の表現を学習しやすくすることを目指した NMT の手法として．学習したい表現部分と後続文脈の一部のみから誤差逆伝播で学習する手法を提案する．
P8-22,GPTを用いた標準語から方言への翻訳,山崎祐|坂野遼平,,P8:ポスター,現在日本では方言は当該地域における日常会話等にとどまらず，様々な形で活用されている．その方言を支える職業として方言指導講師がある．しかし若者の方言離れなどによる問題から方言指導講師の減少が懸念されている．指導できる人が減少すると舞台の原稿作成や方言の翻訳などが困難になってしまう．そこで本研究では，GPT を利用した標準語から津軽弁へのテキスト翻訳を行う．具体的には標準語と津軽弁の対訳データを Fine-tuning し，津軽弁への翻訳を指示する prompt を与える．実験の結果，学習前よりも Fine-tuning をした後のほうが BLEU スコアが高くなることが分かった．
P8-23,JaParaPat: 大規模日英特許対訳コーパス,永田昌明|森下睦|帖佐克己|安田宜仁,,P8:ポスター,2000 年から 2021 年に日本特許庁(JPO)と米国特許商標庁(USPTO)から公開された特許出願から約 3億文対の日英対訳コーパスを作成した。欧州特許庁(EPO)が管理する書誌データベース DOCDB からパテントファミリーに基づいて対訳文書対を抽出し、機械翻訳に基づく文対応を用いて対訳文対を抽出した。Web から収集した約 2000 万文対の対訳データJParaCrawl に対して、特許出願から収集した約 3 億文対の対訳データを追加することにより、日英特許翻訳の精度が約 20BLEU ポイント向上した。
P8-24,証憑を用いた日本語OCR誤り訂正ベンチマークの構築,藤武将人,,P8:ポスター,"この 論文 では OCR(Optical Character Recognition)システムにおける日本語証憑の認識結果の誤り訂正手法検討のため,ベンチマークとベースラインの構築及びその有効性の評価を行う.請求書などの証憑において,適切な処理やその自動化に向けて記載されている文字を正しく認識し,また誤りがある場合には補正を行うことは重要である.そのため,本研究では日本語請求書における社名などの項目を対象に既存の OCR モデルによる文字認識精度を測定し,誤り訂正ベンチマークを構築した.そして,言語モデルを用いた誤り訂正手法を提案し,これらの誤りを効果的に訂正できるかを検証した.提案した誤り訂正アルゴリズムは,全体的な認識精度を著しく向上させることができることを示した."
P8-25,サーベイ論文で引用すべき論文の推薦,柴克樹|笹野遼平|武田浩一,,P8:ポスター,サーベイ論文の自動生成は新たな研究分野に取り組もうとする研究者にとって、分野全体の俯瞰を助ける重要な役割を持つ技術である。しかし、既存のサーベイ論文自動生成に関する研究では、サーベイ論文が引用する論文の情報から、サーベイ論文を生成するタスクに焦点が当てられており、引用すべき論文をどのようにして見つけるかについては十分な検討がなされてこなかった。本研究では、サーベイ論文で引用すべき論文の推薦システムの構築に取り組む。具体的には、生成したいサーベイ論文に関するキーワードが与えられたとき、キーワード検索と論文の引用関係に基づき候補論文集合を作成し、そこから引用推薦の枠組みを用いてサーベイ論文が引用すべき論文を推薦するシステムを構築する。
P8-26,診療テキストからの必要な検査項目の予測,榎原芽美|柴田大作|辻川剛範|宇野裕|北出祐|河添悦昌|大江和彦|久保雅洋,,P8:ポスター,Large Language Models（LLM）は，その高い自然言語処理能力からさまざまな領域で注目されており，医学領域においても高い関心が寄せられている．本研究では、実際の医療現場において医療従事者が行うタスクの一つである初診時の診療テキストからの検査項目の予測を行う. LLM の精度と医療従事者の精度を比較した結果，全ての訓練データでFine-tuning した Bidirectional Encoder Representationsfrom Transformers の精度が最も高いことが確認された．また，Zero-Shot や Few-Shot で学習した LLM の精度は医療従事者による精度と遜色ない値であることが明らかとなり，LLM の有効性が示唆された．
P8-27,Target-Driven Contexts in Detecting Informational Bias,◊IffatMaab|EdisonMarrese-Taylor|YutakaMatsuo,,P8:ポスター,"Media bias detection requires comprehensive integra-tion of information derived from multiple news sources.Sentence-level political bias detection in news is no ex-ception, and has proven to be a challenging task that re-quires an understanding of bias in consideration of thecontext. Inspired by the fact that humans exhibit varyingdegrees of writing styles, resulting in a diverse range ofstatements with diﬀerent local and global contexts, previ-ous work in media bias detection has proposed augmenta-tion techniques to exploit this fact. Despite their success,we observe that these techniques introduce noise by over-generalizing bias context boundaries, which hinders per-formance. To alleviate this issue, we propose techniques tomore carefully search for context using a bias-sensitive,target-aware approach for data augmentation. Our ap-proach outperforms previous methods signiﬁcantly whencombined with pre-trained models such as BERT."
A9-1,言語モデルが生成したテキストを書き換えるタスク非依存の復号手法,藤田正悟|小林尚輝|後藤啓介,,A9:言語生成,言語モデルは流暢なテキスト生成を可能とし幅広い生成タスクに使用されているが，その出力は常に正しいとは限らない．そのため，実際には言語モデルによって生成されたテキストを手作業で校正する必要があるが，これは時間のかかる作業である．本稿では指定された区間のテキストを書き換えるタスク，および書き換えのための復号手法の拡張を提案する．提案手法は書き換えたいテキストの生成に使用した言語モデルを再利用するため，追加のモデルの学習やデータセットを必要とせずテキストを書き換えることができる．実験では要約タスクと翻訳タスクにおける本手法の有効性を評価し，text inﬁllingモデルと paraphrase モデルをベースラインとして比較した．提案手法は品質と多様性の両方においてベースラインを上回り，書き換えタスクへの有効性を実証した．
A9-2,R2T: 言語モデルの確率操作による学習なし中間文生成,城戸晴輝|前川在|小杉哲|船越孝太郎|奥村学,,A9:言語生成,中間文生成は，損傷した文章の復元，記事の執筆のような多くの状況で役立つ一般的なタスクであるものの十分な研究が行われていない[1].本研究では，表面的なパターンを学習してしまうことや，近年の言語モデルのサイズの増加に伴い学習にコストがかかることなどの，教師あり学習モデルの持つ問題を回避するため，学習なしでの中間文生成に取り組む．手法としては，最後の文の埋め込みと各語彙トークンの埋め込みとのコサイン類似度を，自己回帰言語モデルが次トークンを予測する際に使用する語彙の対数確率に足し合わせるという単純なものである．これはあらゆる自己回帰言語モデル，復号化アルゴリズムに対して適用可能な Plug-and-Play な手法である．実験の結果，これまでの学習なし中間文生成手法と比較して，計算コストが十分に少なく，自動評価において大幅に上回る指標があるなど，新たな中間文生成の手法としての可能性を示した．
A9-3,Advancing Robustness and Instruction-following in LLM-Powered Multi-Style Text Rewritting,◊YanLi|GuangJunWang|GangQiao|ZhenpengZhan,,A9:言語生成,"Now people frequently aim to polish their language ormodify  their  text  while  using  a  mobile  keyboard.However, leveraging  large language  models (LLMs) formulti-style  text  rewriting  poses  challenges, includingsemantic  alteration, semantic  addition, and  taskconfusion, these  challenges  stem  from  the  model'sshortcomings in effectively following instructions and itslack  of  robustness.Particularly  evident  in  handlingnon-standard, informal  English  rewrite  requests,reflecting  weaknesses  in  the  model's  robustness. Toaddress  these  challenges, this  study  introduces  amethodology  that  enriches  training  data  with  bothpositive and negative rewrite instances, accompanied bycorresponding  rationales. This  approach  aims  tostrengthen  the  model's  discriminative  capabilities.Additionally, adding Noisy Embedding during training isemployed  to  enhance  the  model's  robustness.Experiments validate the effectiveness of our methods inimproving model directive adherence and robustness．"
A9-4,Recurrent Memory Transformer for Incremental Summarisation of extremely long text,◊KaifanLi|ShuntaroYada|EijiAramaki,,A9:言語生成,"Pupular transformer-based language models are oftenconstrained with a limited number of input length, result-ing in subpar performance on the task of long-text sum-marisation. Prior work has attempted to alter the model’sinternal architecture to accommodate longer inputs. Evenif a model supports longer input texts, limited RAMs inuniversity laboratories and edge devices prohibit us fromunleashing that input length. We, thus, explore the taskof long-text summarisation based on Recurrent MemoryTransformer (RMT) which provides an external memoryfor the transformer-based models without modifying theinternal structure, and further proposed RMT-Summ. Todemonstrate the validity of RMT-Summ, we introducean incremental summarisation task, and built a dedicateddataset from PubMed medical articles containing struc-tured abstracts. Our experimental results show that anRMT-Summ powered BART model performed better thanthe baseline original BART by 1.24 points in ROUGE-1."
A9-5,特許請求の範囲の自動書き換え生成モデルのための大規模データセットの構築,河野誠也|野中尋史|吉野幸一郎,,A9:言語生成,本研究では，特許文書における特許請求の範囲の書き換えを自動生成することを目的とした書き換え生成モデルの基礎的検討を実施する。本研究では，このようなモデルを学習・評価するためのベンチマークとして，特定の特許出願に紐づけられた公開特許公報，特許公報からの情報の差分を取り込むことで，特許請求の範囲の書き換え事例を大量に収録したデータセットを構築した。次に，構築したデータセットを用いて大規模言語モデルに基づいた特許請求の範囲の自動書き換え生成モデルを構築し，その性能と限界について議論した。
B9-1,大規模言語モデルを利用した音声対話システムのメタ制御,宿里晃太郎|石垣龍馬|鈴木順大|永沼翔翼|藤本拓真|河窪大介|酒造正樹|前田英作,,B9:対話(1),大規模言語モデル(LLM)を利用することにより，従来のルールベースによる音声対話システムでは困難であった自然な対話が可能である．しかし，LLMは明示的な出力制御が困難であり，音声対話システム設計者の意図と異なる発話が生起する危険性がある．本稿では，より安定で且つ柔軟な音声対話システムを実現するための LLM を利用したメタ制御手法を提案する．提案手法は，対話シナリオに沿った対話を実現するための対話フロー制御と，自然な対話を実現するためのターンテイキング制御とからなる．それら制御の最適化にも LLM を利用するというメタ制御を音声対話システム上に実装し，その効果を検証した．
B9-2,生成的後処理ネットワークによるタスク指向型対話システムの最適化,大橋厚元|東中竜一郎,,B9:対話(1),後処理ネットワーク(post-processing network; PPN)は，対話システム中の各モジュールの出力を事後修正することで，システム全体のタスク達成能力を改善するコンポーネントである．先行研究において，出力が固定次元のモジュールに対する PPN の有効性は示されてきたが，言語生成モジュール(NLG)の出力は後処理できないという制限があった．本研究では，NLG の後処理を実現するため，言語モデルを活用した生成的後処理ネットワーク(GenPPN)を提案する．具体的には，GenPPN をタスク達成に対して強化学習で最適化するため，各発話が全体のタスク達成に与える貢献度を定量化し，報酬関数に導入する．シミュレーション評価実験と人間評価実験を通して，GenPPN による NLG の後処理が，システムの性能改善に有効的であることを確認した1）．
B9-3,Prefix Tuning とキャラクタ属性の加減算を利用したキャラクタ風発話生成,藤原寛隆|新納浩幸,,B9:対話(1),特定のキャラクタの特徴を反映した発話を生成する技術は小説やアニメ，ゲームなどの応用において大いに需要がある．しかしながら既存手法の多くは変換規則を人手で構築する必要があり高コストである．また，対象キャラクタの言語モデルを構築する場合にも収集できる訓練データに限りがある．そこで，本研究では少ない訓練データから良質な言語モデルを構築する手法を提案する．具体的には，キャラクタの持つ属性情報をベクトル(preﬁx)として明示的に与える．その際，類似属性を持つ他キャラクタの発話から属性ベクトルを preﬁx-tuning の形式で学習させることで良質なベクトル表現を獲得する．また preﬁx 同士の加減算を利用することで属性同士の加減算を試みる．実験の結果，提案手法ではキャラクタの特徴を捉えた発話を生成することが難しいことがわかった．一方で一部の実験では発話に改善が見られ，属性情報を明示的に与えることや属性の加減算が有効に機能する可能性が示唆された．
B9-4,タスク指向型対話システムへの項目反応理論の適用によるユーザのタスク達成能力の推定,平井龍|郭傲|東中竜一郎,,B9:対話(1),タスク指向型対話システムの性能は改善しているものの，すべてのユーザが自身のタスクを完全に達成できるわけではない．システムについての知識の少ないユーザは，システムに対しての話し方が分からず，対話破綻を引き起こしたり，タスクが達成できなかったりする．この問題を解決するためには，システムはユーザのタスク達成能力を推定し，ユーザの能力に合わせて対話することが望ましい．本研究では，教育分野で受験者の能力推定によく用いられる項目反応理論をタスク指向型対話システムに適用し，ユーザのタスク達成能力を推定する手法を提案する．推定したタスク達成能力を用いてスロットの正答確率を予測する実験を行った結果，提案手法はベースラインよりも高い精度でスロットの正答確率を予測できることが分かった．
B9-5,音声対話における応答速度改善に向けた先読み技術の検討,大萩雅也|水本智也|吉川克正,,B9:対話(1),本研究では大規模言語モデルを用いた音声対話システムにおける応答速度を改善するための新たな手法を提案する。既存のシステムではユーザー発話の終了後に音声チャットボットの応答を生成するため生成時間の分、応答開始が遅れていた。これに対し我々のシステムではユーザー発話が終了する前にそれまでの対話履歴から次にどのようなユーザー発話が来るかを先読み予測し、それに対する応答を事前生成する。これにより生成時間を省略し予測ユーザー発話と実際のユーザー発話のマッチング時間のみで応答を返すことができるようになる。評価の結果、ユーザーの発話候補が限定される文脈のもとで我々の手法は高い先読み精度を発揮し応答速度の改善に寄与しうるという結果が得られた。
C9-1,文書分類のための要約に基づくデータ拡張,王悦綸|吉永直樹,,C9:検索・文書分類(2),文書などの長文を対象とした自然言語理解タスクは，事前学習済みモデルを用いたとしてもデータの過疎性の問題から解くことが依然難しい．そこで，本稿では人間が文書読解能力を身につける過程に着想を得て，文書分類のための要約に基づくデータ拡張手法 SUMMaug1）を提案する．提案手法では，元の学習データの入力を要約し，必要に応じ要約された入力に合わせるように元のラベルを縮退することで，学習容易な事例を生成し，中間学習に用いる．2 つの文書分類データセットでの実験結果により，提案手法が分類精度及び学習の安定性の観点で既存手法より優れていることを確認した．
C9-2,文書のチャンクに基づく知識グラフを活用したRAG,江上周作|福田賢一郎,,C9:検索・文書分類(2),大規模言語モデルで外部知識を活用する上でRetrieval-Augmented Generation (RAG)が注目を集めており，RAG の各モジュールごとに拡張手法が開発されている．検索モジュールでは埋め込みベクトルに基づく類似度検索手法の開発が主流となっているが，ユーザの質問に答える上で必要な情報は必ずしも質問に類似しない．本研究では，外部文書のチャンクのメタデータやチャンク間の意味的関係を抽出することで知識グラフを構築し，ベクトル類似度検索と組み合わせたハイブリッドな RAG 手法を提案する．実験の結果，ベースラインと比較して回答の忠実性とコンテキストの関連性の向上を確認した．
C9-3,大規模言語モデルによる cross-lingual transfer の性能評価,田代雄介|山口流星|鈴木彰人|辻晶弘,,C9:検索・文書分類(2),近年、大規模言語モデルの発展が著しく、自然言語生成の様々な研究が進展している。一方、識別タスクなどの自然言語理解への大規模言語モデルの応用はあまり研究が活発ではない。本研究では、言語識別タスクの中でもモデルの多言語性能が重要である cross-lingual transfer について、サイズや学習データが異なる複数のモデル・設定を用いて、大規模言語モデルの性能を評価する。実験の結果、ターゲット言語のデータがない zero-shot 設定でもモデルの大規模化により転移される知識が増加すること、F1-score の上昇には大規模言語モデルでも few-shotによる少量のターゲット言語を必要とすることなどが分かった。
C9-4,様々な災害ドメインのクロノロジーに対する優先度推定,孝壽真治|竹内孔一|渡邉暁洋|平山隆浩|中尾博之,,C9:検索・文書分類(2),災害対策本部では連携機関からの報告や要請をもとに，その優先度に応じて医療リソースの分配を決定している．これらの要請などは時系列形式の文書としてまとめたクロノロジーと呼ばれる形式で記録される．本研究では，クロノロジーの優先度を推定する機械学習モデルを構築し，学習データとは異なる災害で作成されたクロノロジーにおける優先度の推定精度を検証する．実験の結果，GPTNeoX-3.6bを利用したモデルが，学習データとは異なる災害のクロノロジーの優先度推定において，特に有効であることが明らかとなった．
C9-5,Ada or Bert:検索における文埋め込み計算手法の比較研究,馬春鵬|松田寛,,C9:検索・文書分類(2),自然言語処理技術が使われている様々なサービスに、検索が中心的役割を果たしているものが多いが、近年の大規模言語モデルは検索に与えた影響が不明だ。本調査報告書は宿検索に対する文埋め込み計算手法を比較した。文の埋め込みの計算において、従来の BERT モデルと OpenAI 社の新しいモデルのそれぞれの強みと弱みを分析した。
D9-1,敵対的不変表現学習を用いたアスペクトベース感情分析,水谷宏太|南條浩輝,,D9:評判・感情分析,文書や文よりも細かいアスペクトを単位とするアスペクトベース感情分析（ABSA）の研究を行う．既存の ABSA データセットは作成のコストの大きさからサイズは大きくなく，収録されているテキストドメインが限られている．このため，実際の ABSAの分析対象のテキストと同じドメインのデータが得られず，高い精度を得にくいという問題がある．本研究では，ABSA モデルの学習時に敵対的学習を行いことでドメイン不変な表現を獲得し，学習データと異なるドメインでの ABSA の精度の高精度化を目指す．BERT を用いた感情極性分類モデルの学習において，敵対的不変表現学習を導入し，学習時と異なるドメインのデータセットに対する ABSA における敵対的不変表現学習が有効性を示した．
D9-2,テレビ番組の放送内容テキストを用いた視聴者属性別の視聴量変動の予測,山田祐也|南條浩輝,,D9:評判・感情分析,近年，テレビ視聴データの利活用が進められており，番組の視聴分析や CM 効果測定などの取り組みが行われている．本稿ではテレビ番組のコーナーごとに視聴量が増加するのか，そうでないのかの予測に取り組んだ．予測には番組内容に関するテキストを用い，BERT モデルを基準に 2 つの精度改善アプローチに取り組んだ．予測精度は視聴者属性によるばらつきがあったものの高い精度で予測できる視聴者属性があった．予測モデルの方法と結果を紹介する．
D9-3,国会議事録を使用した政党ごとのスタンス変遷の分析,尾崎慎太郎|横山大作,,D9:評判・感情分析,"昨今,若者の政治に対する参加意欲の低下が日本では深刻化している.その原因には,様々な理由があるが実際に実現されようとしているのかがわからないで似たような発言をしているなどの声が多い.本研究では,大量の国会議事録から政党ごとの政策に対するスタンスの変遷を分析し,一貫性があるかどうかを確認できることを目指した.そのため,国会での発言から政党のスタンスを分類,また発言を要約することで議案を特定し,マニフェストに掲載された 5 つの代表的な政策について分析した.その結果,一貫性が見られた政党を確認できた一方で,選挙公約で話していたことを実現していないように思われる政党も確認した."
D9-4,大規模言語モデルを用いたマイクロブログに対する絵文字予測,花一傑|宇津呂武仁|陳嘉敏|鈴木良弥,,D9:評判・感情分析,昨今の SNS では，ユーザーが絵文字を自分の文章に付与することにより，文章の表す感情を増幅，補完することが多く，その絵文字付き日本語文章を利用した感情分析に関する研究も増えている．しかし，英語文章そのものの意味を理解し，その文章に相応しい絵文字を複数のクラスの中から予測し，正しいクラスに分類する絵文字予測タスク[1][2][3]は存在するが，日本語文章に対する絵文字予測を目的とした研究は存在しない．そこで本研究では，大規模言語モデル ChatGPT1）を利用し，マイクロブログ(X)の日本語ポスト文に対する絵文字予測を行い，ChatGPT のﬁne-tuning で高い精度を達成した．
D9-5,大規模言語モデルにより生成した疑似データを用いた自由記述アンケートの自動集約,銭本友樹|長谷川遼|宇津呂武仁,,D9:評判・感情分析,自由記述回答を用いたアンケート調査は，調査対象における新たな価値や意見の発見に貢献する重要な手法である．この自由記述回答の分析作業は，回答中の意見抽出や類似意見のクラスタリングなどの複数の人手作業が必要であり，一般に大規模な回答データを対象とした分析には大きなコストがかかる．そこで本研究では，大規模言語モデルを用いた自由記述回答中の意見抽出と類似意見のクラスタリングの自動化手法を提案する．「新型コロナ不満アンケートデータ」の自由記述回答を利用した実験により，提案手法が人手による分析に匹敵する精度の分析を低コストかつ短時間で行えることを明らかにした．
E9-1,小規模言語モデルによる子供の過剰一般化のモデリング,芳賀あかり|菅原朔|深津聡世|大羽未悠|大内啓樹|渡辺太郎|大関洋平,,E9:テーマセッション６：深層学習時代の言語学と自然言語処理(2),近年，言語モデルの学習データを子供の入力に近づけることで学習効率向上が示されるなど，人間の言語獲得過程を模倣することの有効性が示唆されている．一方で子供の一般化の特徴を機械で説明しようという研究は長らくされているが，その多くは語の屈折を直接学習するなど子供の学習環境とは異なるものである．本研究は，子供が言語獲得過程で起こす誤りを模倣することで言語モデル(LM)が人間らしい学習過程を得られるという仮説のもと，子供の入力に近いデータで学習した LM の誤りの選好を分析した．その結果，子供の入力に近い学習データを用いるのみでは人間の学習過程の誤りの特徴は十分に捉えられない可能性が示唆された．
E9-2,意味変化分析に向けた単語埋め込みの時系列パターン分析,木山朔|相田太一|小町守|小木曽智信|高村大也|松井秀俊|持橋大地,,E9:テーマセッション６：深層学習時代の言語学と自然言語処理(2),意味変化とは書かれた時代により単語の意味が変化する，という言語学的事象である．単語の意味がどのようにして変化するのか，という意味変化パターンの理解は将来的に意味変化する単語のモデル化に対し重要な示唆を与える．本研究では，意味変化のパターンを分析するための前段階として，単語埋め込みの時系列分析手法を提案する．時期ごとに単語埋め込みを学習し，対象単語の埋め込みを時系列に並べることで時系列のパターン分析を可能にした．分析の結果より，特殊な振る舞いをするパターンが存在することを示し，時系列の分析に本手法が有効なことを示す．
E9-3,節埋め込みの意味論に動機づけられたプロービング,船蔵颯|櫻川貴司|峯島宏次,,E9:テーマセッション６：深層学習時代の言語学と自然言語処理(2),本稿では、「Transformer に基づく事前学習済み言語モデルは節埋め込みの意味論において重要な情報をエンコードしているか？」という問いに答えるために、節選択性に応じた述語分類と意味タグ付与という 2 つのタスクを設計し、事前学習済みBERT に対するプロービングを実施した。実験の結果、BERT の出力する埋め込みベクトルを用いた節選択性の予測が一定程度可能であることが明らかになったが、よりミクロな視点からの調査が課題として残っている。
E9-4,逆強化学習による文章における人間らしさの推定,岸川大航|大関洋平,,E9:テーマセッション６：深層学習時代の言語学と自然言語処理(2),文章からの作者の個性の推定は、言語モデルにおける人間らしい文章生成、あるいは文章の定量的分析などに応用可能であるため、重要な研究課題であると考えられる。本研究では、言語生成過程をマルコフ決定過程によってモデル化し、報酬を推定する逆強化学習を用いることによって、報酬の形で文章の個性を推定することを提案する。計算機実験として、夏目漱石の文章とそれ以外の作家の文章を提案手法によって学習させ、文章が識別可能であること、推定報酬を用いた文章表現に対する定量的な評価が可能になることを示す。
E9-5,Annotation of modal expressions in Indonesian,野元裕樹|JozinaVanderKlok|DavidMoeljadi,,E9:テーマセッション６：深層学習時代の言語学と自然言語処理(2),"We developed an annotated dataset to investigate six modalexpressions in Indonesian, i.e. harus ‘must’, harusnya,seharusnya ‘should’, mesti ‘must’, mestinya, semestinya‘should’. The data consists of 600 sentences. Three nativespeaker annotators annotated them with tags concerningmodal force, modal ﬂavour, mood, etc. The annotationresults provide quantitative information about the relevantmodal forms, which have been missing in the literature.Moreover, they validate some previous qualitative descrip-tions, but invalidate others."
P9-1,大規模言語モデルを用いた病名予測の検討,宇都宮和希|坂野遼平,,P9:ポスター,近年，自然言語処理技術を活用した医療支援や大規模言語モデルを用いた研究が盛んに行われており，少子高齢化による医者や病院の不足などから AIの遠隔診療への応用も挙げられている．診療の重要なプロセスとして，診断，すなわち患者の診察により病気の種類や名称を判断する行為がある．患者の曖昧な症状表現から病名を診断することは現状では医師が担っており，AI の活用，特に大規模言語モデルによる病名診断の可否や精度は明らかではない．本研究では，大規模言語モデルによる医療支援の一環として，GPT を用いた患者表現からの病名予測の精度を検証する．また，GPT のバージョンおよびファインチューニングの有無による影響を分析する．患者表現辞書を用いた実験の結果，ファ インチューニングを行うことで予測精度が向上すること等を確認できた．
P9-2,自動プロンプト最適化のソフトウェア設計,水野尚人|柳瀬利彦|佐野正太郎,,P9:ポスター,大規模言語モデルの発展に伴い，モデルへの指示に用いられるプロンプトの最適化技術が活発に開発されている．また，プロンプトを自動で最適化し大規模言語モデルの能力を引き出す手法も提案されるようになり，性能指標が大きく改善できることが明らかとなってきている．本研究では，プロンプト自動最適化技術の適用を行うソフトウェアに必要な機能を整理し，アーキテクチャを提案する．ユーザの記述する目的関数とプロンプト最適化アルゴリズムを分離して記述できるようにすることで，最適化の対象とアルゴリズムが明確になりプロンプトの改善による性能向上が容易に行えるようになる．
P9-3,多肢選択問題における言語モデルの頑健性の評価,滝沢広央|菅原朔|相澤彰子,,P9:ポスター,大規模言語モデルの一般常識や推論能力，医療など特定ドメインの知識等の計測には，多肢選択問題からなる評価データセットが利用されることが多い．しかし，言語モデルが多肢選択問題に回答する際の頑健性はそれほど評価されてない．そこで本研究では，多肢選択問題で構成された既存の評価データセットを変換することで頑健性を検証するための新たな評価データセットを提案し，既存の言語モデルを評価する．結果として否定を含む問題に対する頑健性の低さが明らかになった．
P9-4,JMedLoRA：Instruction-tuningによる日本語大規模モデルの医療ドメイン適用,助田一晟|鈴木雅弘|坂地泰紀|小寺聡,,P9:ポスター,大規模言語モデル（LLM）の波及効果が続く中，その医療ドメイン適応は重要な研究課題となっている．近年 LLM の調整には Instruction-tuning が多用されるが，ドメイン適応におけるその具体的な効能は明らかにされていない．本研究では，日本語での LoRA ベースの Instruction-tuning を実施し，その性能を医療質問応答タスクを通じて多面的に評価した．本実験により，英語の LLM を出発点としたInstruction-tuning によってドメイン固有の知識を一部 LLM に組み込むことができ，大きなモデルほど効果が顕著であることが示唆された．この取り組みは，医療機関が外部サービスに頼らずに LLM 構築する先駆的な試みとして位置付けられる．
P9-5,ビジネスのドメインに対応した日本語大規模言語モデルの開発,近江崇宏|高橋洸丞|有馬幸介|石垣達也,,P9:ポスター,この一年ほどで日本語に対応した大規模言語モデルが活発に開発されている。今回、我々はビジネスのドメインに対応した 130 億パラメータの日本語の大規模言語モデルの開発を行い、事前学習済みモデル及び指示学習済みモデルの公開をおこなった。本論文では、事前学習や指示学習の詳細や、モデルの評価、特にビジネスのドメインでの優れた質問回答性能について報告する。また、最新の情報の継続的学習に関する初期的な検証結果についても簡単に報告する。
P9-6,社会的状況を踏まえた大規模言語モデルによる日本語メール生成,MuxuanLiu|石垣達也|宮尾祐介|高村大也|小林一郎,,P9:ポスター,本稿では，LlaMa-2 モデルを用いて，LLM が日本語ビジネスメールの社会的状況を反映している文脈を理解する能力を探求した．異なる社会的立場や身分を示すアノテーションラベルを学習させることで，モデルにどのような情報を入力することが社会的な文脈を反映させるのに効果的かを検証した．アブレーション実験を通じて，各種アノテーションラベルの組み合わせがモデルのテキスト生成に与える影響を分析した．これにより，社会的状況を反映したテキスト生成の精度を高めるために必要なアノテーションラベルを特定できた．
P9-7,大規模言語モデル houou (鳳凰): 理研 ichikara-instruction データセットを用いた学習と評価,小島淳嗣|北岸郁雄,,P9:ポスター,supervised ﬁne-tuning (sft)によって大規模言語モデル の指 示追 従性 を向 上さ せる には、prompt とcompletion のペアで構成されるインストラクションデータが必要となる。このようなインストラクションデータの作成は、GPT-4 などの学習済みモデルからの出力を利用する方法を除くと、人手で promptと completion を記述する必要があり、アノテーションコストが高い。それゆえ、日本語のインストラクションデータは、英語で作成されたインストラクションデータを日本語に翻訳することで得るアプローチが大半であった。本稿では、日本語によってフルスクラッチから作成されたインストラクションデータセットである ichikara-instruction を用いてモデルを学習することで、自動翻訳で作成されたデータによって学習されたモデルに比べて高い日本語生成能力が獲得できることを示す。実験では、RakudaBenchmark を用いて、翻訳データによって学習されたモデルと日本語インストラクションデータで学習されたモデルの性能を GPT-4 によって比較した。その結果、gpt-3.5-turbo-1106 、日本語に自動翻訳した dolly と OpenAssistant Conversations によってそれぞれ学習された sft モデルに対する勝率はそれぞれ67.5%、82.5%、70%となり、日本語による高品質なインストラクションデータが LLM の日本語生成能力向上に重要であることが示された。
P9-8,ヒューリスティックと遺伝的アルゴリズムを用いた自動プロンプトチューニング手法,進藤稜真|ジェプカラファウ|竹下昌志|荒木健治,,P9:ポスター,良質なプロンプトを作成することは大規模言語モデルの性能を引き出すために重要であるが，プロンプト作成には人間の手間と時間的コストを必要とする．そこで本研究では，一般に広く用いられているプロンプトに関するヒューリスティックと遺伝的アルゴリズムを用いて，タスクに特化したプロンプトを自動でチューニングする手法を提案する．評価実験により，提案手法でチューニングしたプロンプトは人手で作成したプロンプトと同水準かそれ以上の性能を持つことを確認した．
P9-9,日本の司法試験を題材としたGPTモデルの評価,チェジョンミン|笠井淳吾|坂口慶祐,,P9:ポスター,"ChatGPT などの大規模言語モデルが，多岐にわたるタスクにおいて人間の専門家の精度を上回ると報告されている．とくに日本の医師国家試験にChatGPT が合格したという最近の研究報告からも，日本語についての高い性能が確認されている．本研究では，日本の司法試験（短答式）の憲法，民法，刑法それぞれ過去 5 年分を対象に，GPT-3, GPT-4 および ChatGPT の精度を評価した．結果として，現段階では日本の司法試験に対する正答率が 3〜4 割と，合格水準を大幅に下回ることが明らかになった．本研究では，単なる正解率にとどまらず，回答に必要な知識，能力を分解し，それぞれの観点での大規模言語モデルの性能を検証した．その結果，1)大規模言語モデルは多くの条文の知識を有していること，2)特定の条文や判例の知識を必要としないが学説の理解を必要とする問題に関しては正解率が高いこと，3)判例の知識を必要とする問題に関しては正解率が低いこと，が示された．米国の司法試験と比較して性能が低い原因の大部分は，日本法の知識，とくに判例の知識の乏しさにあると考えられる．"
P9-10,Chain-of-Thought過程の誘導によるLLMの性能改善と推論過程および性能の説明性向上,藤田真伎|狩野芳伸,,P9:ポスター,近年，大規模言語モデルの性能上は著しいものがあるが，その大規模さゆえにモデル構造や推論過程がブラックボックス化している問題がある．そこで，Chain-of-Thought の過程を誘導するフォーマットを提案し，推論過程のどの部分が特に推論結果に影響を与えているかを特定できるようにした．また，Fine Tuning により任意のモデルで同様のフォーマットでの出力ができること，この手法を用いることで複数モデル間で推論能力の差がある部分を明確にできることも示した．司法試験の民法分野の含意関係推論タスクを題材として，大規模言語モデルを用いたタスク性能の向上を達成した．
P9-11,RAGの連結方式および自動評価指標の定量評価,徳永匡臣|岡田智靖,,P9:ポスター,"大規模言語モデル(LLMs, Large Language Models)に外部知識を付与する手法として，Retrieval Aug-mented Generation（RAG）が高い注目を集めている．本研究では，RAG の実装で必要不可欠な「連結方式」に着目し，9 つの LLMs に対して定量評価をおこなう．その後，18 個の RAG システムを用いて自動評価指標と人手評価との相関を評価する．新たに構築した日本語評価用データセットによる定量評価の結果，RAG の回答精度を重視する場合は直列方式，回答速度を重視する場合は並列方式による連結が適していることを示した．また自動評価指標と人手評価との相関を評価した結果，ROUGE や BERTScoreなどの従来の自動評価指標と比べて，GPT-4 を用いた自動評価が人手評価との高い相関を示すことが分かった．"
P9-12,マルチホップQAの根拠情報を用いたLLMの``偽''正解の分析,石井愛|井之上直也|鈴木久美|関根聡,,P9:ポスター,LLM がどのような知識に基づいて推論しているのか，そのきめ細かい調査の一つとして，回答の根拠となる導出情報が付与されたマルチホップ QAデータセットを用いて GPT-4 の出力を分析する．分析の結果，回答が正解しているにも関わらず，根拠となる導出に誤りが含まれる“偽”正解といえる現象が発生し，“偽”正解を除くと，正解率は 60%から40%に低下することを示す．さらに，外部知識を組み合わせた場合のカバー率の調査結果から，LLMを既存の外部知識と適切に組み合わせることによる改善の可能性を示す．
P9-13,Minimal-pair Paradigmデータセットにおけるトークン長バイアスの分析と改善,上田直生也|三田雅人|小町守,,P9:ポスター,教師なし手法で言語モデルの言語能力を測るために，Minimal-pair paradigm（MPP）データセットがベンチマークとして用いられる．MPP では，容認可能な文に対して容認不可能な文より高い対数尤度を予測したミニマルペアの割合によって，言語能力を評価する．この対数尤度は文長に影響されるため，容認可能な文と容認不可能な文の単語数を揃えることが通例である．しかしながら，近年の言語モデルは文をトークン化するため，単語数を揃えるだけでは不十分である可能性がある．本研究は，容認可能な文と容認不可能な文の間でトークン長が異なることで起きるバイアスが言語・データセット横断的に存在しており，トークン長を揃えることでバイアスが改善できることを示す．
P9-14,In-Context Learning においてLLMはフォーマットを学べるか,坂井吉弘|趙羽風|井之上直也,,P9:ポスター,In-Context Learning (文脈内学習；ICL)は，プロンプト中に与えられた少数のデモなどからパラメータを更新することなくタスクを学習する LLM の能力であるが，そのメカニズムは十分に明らかにされていない．先行研究の実験は，「タスクの入力の後にラベルを出力する」というフォーマットを LLM に示すことが特に重要である可能性を示唆する．そこで本研究では，LLM が与えられたデモから答え方のフォーマットを学習する様子を直接的に可視化した．結果として，(1)確かに LLM はデモから答え方のフォーマットを学んでいること，(2)フォーマットの学習は意味の無いラベルについても可能であること，(3)最悪のラベルが ICL の Macro-F1 を大きく向上させることを発見した．
P9-15,文脈内学習における文脈内事例の寄与度推定,葉夢宇|栗林樹生|小林悟郎|鈴木潤,,P9:ポスター,モデルの出力を説明する一つの方針として，出力に寄与した訓練事例の提示が考えられる．近年成功を収めている文脈内学習では，通常の学習と異なり訓練事例が入力に含まれるため，入力に対する寄与度推定法をこの目的で適用できる可能性がある．本研究では，重要な事例が明らかになるよう設計した人工タスクを用いて，6 種類の代表的な解釈手法の適用可能性を検証する．実験により，Gradient Norm以外の解釈手法は，文脈内学習における寄与事例推定に向いていないことが経験的に明らかになった．
P9-16,シングルGPUによる日本語コードLLMの構築,相馬菜生|小原百々雅|小原有以|高橋舞衣|佐藤美唯|倉光君郎,,P9:ポスター,昨今，大規模言語モデル（LLM）の研究と開発は顕著な進歩を遂げている．LLM は自然言語処理分野において優れた成果を上げると同時に，プログラミングを含む多岐にわたるタスクで高いパフォーマンスを示している．しかし，大学や個人研究者などリソースが限られた環境下では，これらのモデルの扱いが容易ではない．本研究では，日本語コード LLM と HumanEval データセットを対象としたスケールアップ基盤の確立を目指す．この取り組みにより，限られたリソースを有する研究者たちも LLMの研究開発に参加し，新たなアイディアや手法を容易かつ効果的に検証する機会を得ることが期待される．
P9-17,文脈内学習に基づく大規模言語モデルの性別バイアス抑制,大葉大輔|金子正弘|DanushkaBollegala,,P9:ポスター,大規模言語モデル(LLM)は懸念されるレベルの性別バイアスを内包している。先行研究では LLMの追加学習や復号化器の改変に基づくバイアス除去手法が提案されているが、GPT-4 のような非公開のLLM の場合、内部のパラメータやモジュールを利用できない。本稿では、テンプレートと実世界の統計情報を用いて構築したプリアンブルを LLM の入力に追加するだけで、性別的に偏見のある生成を防ぐ手法を提案する。提案プリアンブルは、統計において特定の性別に偏りがある対象を反実仮想的または中立的に記述する。英語 LLM を用いた評価では、下流タスクの性能への悪影響を抑えながら、性別バイアスを含んだ生成を抑制できることを示した。
P9-18,Constitutional AIにおけるセーフティアラインメントの改善,綿岡晃輝|ThienQ.Tran|前田若菜|髙橋翼,,P9:ポスター,大規模言語モデル(LLM)を人の倫理観に準拠させるセーフティアラインメントの多くは，人手による高コストなアノテーション作業を要する.これを緩和するため，LLM 自身に出力文の批評と改訂を繰り返させることで，アラインメント用のデータセットを作成する Constitutional AI 等の手法が提案されている.しかし，Constitutional AI による批評と改訂を繰り返す過程では，文の自然さや倫理観の遵守の度合いが劣化してしまうことがある.そこで，批評と改訂の過程を評価し，得られた改訂の中から最も高品質な改訂を選定する戦略を導入する.実験の結果，有害な回答が 22%減少することを確認した.
P9-19,検索拡張生成における指示追従性を測るベンチマークに向けて,竹岡邦紘,,P9:ポスター,既存の検索拡張生成(Retrieval-augmented genera-tion; RAG)ベンチマークでは，固定の指示に対する評価はしているものの，指示の変化に対する追従性が調査されていない．しかし，RAG では関連文書を入力するため，比較的短い指示の差異を適切に解釈し出力に反映することが重要になる．本研究では，大規模言語モデルに検索等の結果である文書群を生成に利用する設定(RAG)において，どの程度指示通りの出力ができるかを測るベンチマーク IF-RAG を提案する．このベンチマークは，短い指示の違いによる出力の違いを測ることで，大規模言語モデルごとの特性を明らかにする．
P9-20,大規模言語モデルを用いた二段階要約における hallucination の分析,榎本昌文|竹岡邦紘|定政邦彦|小山田昌史|KirilGashteovski|Chia-ChienHung|WiemBenRim|ZhaoXu|CarolinLawrence,,P9:ポスター,大規模言語モデル(LLM)は高品質な要約を生成する一方，hallucination と呼ばれる入力文書に含まれない情報を生成する傾向があるため，要約が依拠する情報を利用者が検証できる仕組みが必要である．そのため，入力文書から要約に用いるテキストを先に抽出して，それらを合成することで説明可能性の高い要約を生成する段階的な方式が提案されている．しかし，入力文書の異なる箇所から抽出されたテキストを合成するため，合成を行うモデルが元々の文脈を理解できずに，誤った情報を生成する可能性がある．本論文では二段階要約においてLLMでテキスト合成を行う際に発生する hallucination の現象分析を行う．実験結果から，対話文書・長文文書における hallucination の増減の傾向や，指示学習・周辺文脈の追加による hallucination の抑制など，既存研究では不明であった新しい知見が得られた．
P9-21,算術推論問題における自己回帰型言語モデルの内部機序,工藤慧音|青木洋一|栗林樹生|谷口雅弥|曾根周作|坂口慶祐|乾健太郎,,P9:ポスター,自己回帰型言語モデルのような逐次的に単語を生成するモデルが「複合的な問題について，いつどのような部分問題を問いているか」という内部機序についての時間方向の解析は現状不十分である．そこで本研究では，人工的な算術推論タスクを解く際の言語モデル内部機序を分析する．本論文の前半では，モデルの内部機序の予測が立つ人工的な算術タスクのみで学習されたモデルに対し分析を行い，提案法の妥当性を示した．後半では，思考の連鎖[1]を用いて推論を行う事前学習済みの言語モデルに対して提案法を適用し分析を行ない，モデルは推論過程を出力すると同時に途中の計算も行っていることが明らかとなった．
P9-22,英語中心の大規模言語モデルの言語横断汎化能力,謝素春|佐々木翔大|YunmengLi|坂田将樹|赤間怜奈|鈴木潤,,P9:ポスター,LLaMA などに代表される大規模言語モデルは，事前学習データの大半が英語で構成されているにも関わらず，英語以外の言語についても文章の生成が可能であることが観察されている．本研究では，英語を中心に学習された大規模言語モデルに対して，英語データのみを用いて微調整学習(ﬁne-tuning)を実施した場合でも，英語以外の言語におけるタスク性能が向上する言語横断汎化能力に関して分析を行う．具体的には，英語の微調整学習前後でモデルの異言語間の内部表現に対する分析の結果，英語の微調整学習は言語非依存のタスクの解き方を学習していること，また，事前学習した言語間の類似度より性能汎化を実現していること示す．
P9-23,大規模言語モデル群へのrouting タスクにおける埋め込みモデルと多数決併用の分析,田村拓也|榎本昌文|秋元康佑|小山田昌史,,P9:ポスター,専門性の異なる多様な大規模言語モデル(LLM)が利用可能な状況において，省コストで質の良い生成物を得るために，タスクに応じて適切なモデルを選択する routing 手法が提案されている．既存のrouting 手法は LLM がタスクを正しくこなす度合いを推定するために，タスクの埋め込みを用いて類似過去タスクを参照するが，埋め込みモデルの違いが性能に与える影響を十分に分析できていない．本研究では埋め込みモデルによる routing 性能の差異を分析した．その結果，埋め込みによる性能の差異はほとんど無い一方，全タスクで平均的に良い回答を行う LLM に偏ってタスクを割り当てるため，依然として routing 手法に改善の余地があることが分かった．また，複数の候補モデルを routing 手法で選択した後に，多数決で誤答を省くことで，更に性能が改善することも新たに発見した．
P9-24,多言語ゼロショット学習における推論言語に関する分析,大平颯人|金輝燦|小町守,,P9:ポスター,現在， Large Language Model (LLM)における in-context learning に関する研究が活発に行われている.in-context learning に用いるプロンプトが適切に設計されていれば， LLM は様々なタスクを実行することができる．本研究では，そのフレームワークを拡張することによって定義される Multilingual LargeLanguage Model (MLLM)の ゼロショット学習に注目する．現在，使用する言語ごとに，どの言語をプロンプトのテンプレートとバーバライザーの言語に用いるかでタスクの性能が大きく異なることが分かっている．そこで本研究では，事前学習時の各言語のデータ量や英語との言語的近さの観点から，この違いの原因を分析する．
P9-25,意味的プロービングデータセットの構築と言語モデルの評価: イタリア語の倒置を例に,今井咲良|GiovanniPasa|小田博宗|折田奈甫|河原大輔,,P9:ポスター,言語特有の現象を利用した意味的プロービングは、言語モデルにとって挑戦的な検証タスクであり、今後の言語モデルの発展のために必要不可欠である。しかし、英語以外の言語での実施が少ない状況にある。本研究では、多言語への展開を目的として、イタリア語の主語・述語の倒置に着目した意味的プロービングデータセットを作成し、事前学習済み BERT がどの程度の意味識別能力を有するかを観察する。イタリア語の容認性判断タスクを行い、文の持つ統語・意味的性質に対する容認性識別能力の変化を調査した結果、不定代名詞や再帰代名詞など意味解釈と関わりの深い性質をもつ文の容認性識別能力が大きく変動することがわかった。
P9-26,対話モデルにおけるキャラクター特性の実現法の探索,山田和志|篠崎隆志,,P9:ポスター,対話型 AI の爆発的な普及は社会にまさに変革をもたらしているが，さらなる浸透のためには個々のAI が独立したキャラクター特性を持つことが必要と考えられる．本研究では LLM への入力を適切に構成することによって，単一のモデルで複数のキャラクター特性を実現する手法を探索する．日本語特有の語尾によるキャラクター特性の実現について注目し，対話 LLM の入力の構成要素である Persona とHistory を操作することで，ファインチューニングなしでのキャラクター付けを実現，人間による感性評価によって，Personaと History についての適切な構成を明らかにした．本手法によって，ゲームにおける多数の Non-Player Character（NPC）や，ご当地キャラとの対話を実現できると考えられる．
P9-27,大規模言語モデルを用いた有効反論箇所としての前提生成,尾﨑大晟|中川智皓|井之上直也|内藤昭一|山口健史|天野祥太郎|新谷篤彦,,P9:ポスター,本研究では，大規模言語モデル(以下 LLM)が，ディベートにおいて相手の主張を弱めるための反論箇所としての前提を効果的に選択できるかを探る．過去の中高生英語ディベート競技大会から収集した議題と肯定立論を基に，LLM に複数の前提から反論すべき最適な前提を選ばせ，この選択を人間のディベートエキスパートの選択と比較することで評価を行った．結果として，LLM は強力なモデルであっても，正解率で 7 割程度であることが分かった．一方特定の議題においては 9 割近い正解率になることもあった．本研究は，LLM を用いたディベートエージェントの開発への展望を提供すると同時に，当実験タスクの LLM の性能ベンチマークとしての可能性を示唆するものである．
A10-1,前後段落を用いて生成した単語分散表現による日本語語義曖昧性解消の検証,前原太陽|竹中要一,,A10:埋め込み表現,近年、言葉の意味をベクトルで表現する分散表現を用いることで、コンピュータが言葉の意味を扱いやすくなった。しかし、多義語の語義曖昧性解消という問題が依然として存在している。語義曖昧性解消とは、多義語の文章中での語義を判定することである。これはコンピュータが言語の意味を処理するために重要な作業である。本研究では日本語の語義曖昧性解消を目指し、異なる語義のクラスタ間の分散は大きく、クラスタ内の分散は小さくなるように、分散表現を生成する方法を提案、検証する。提案するモデルは、対象段落の前後の段落のデータを用いる。既存手法と提案手法の両方で分散表現を生成し、クラスタ間分散とクラスタ内分散、総合評価を行う。
A10-2,自己注意機構のアテンション重みが特定の種類のトークンに集中する現象と外れ値次元の関係,丸田佳|松崎拓也,,A10:埋め込み表現,BERT の自己注意機構は一部の層で[CLS]・[SEP]といった特殊トークンや，カンマ・ピリオドに大きなアテンション重みを割り振るという現象が知られている．一方，BERT の各層での出力ベクトルには他の次元と値の絶対値が大きく離れている次元（外れ値次元）が存在することが知られている．本研究では，外れ値次元と特定の種類のトークンへのアテンションの集中という現象の関係を定量的に分析する．結果として，一部の層では少数の外れ値次元がアテンションの集中を決める支配的な要因になっており，その影響で特定の種類のトークンに割り振られるアテンション重みが大きくなることを数値的に示す．
A10-3,低頻度語彙埋め込みの縮約による事前学習済みモデルの圧縮,田村鴻希|吉永直樹|根石将人,,A10:埋め込み表現,既存の事前学習済みモデルの軽量化手法は中間層の圧縮を行うもので，さらなる圧縮には埋め込み層の圧縮が必要となる．本研究では，低頻度語彙の埋め込みを高頻度語彙を用いて縮約表現することで微調整後の事前学習済みモデルの埋め込み層を圧縮する手法を提案する．JNLI，JSTS，JCoLA のJGLUE の各タスクで微調整した事前学習済みモデル DistillBERT に提案手法を適用した結果，それぞれ 3 割程度のパラメタの削減を達成した．
A10-4,平均プーリングによる文埋め込みの再検討: 平均は点群の要約として十分か?,原知正|栗田宙人|横井祥|乾健太郎,,A10:埋め込み表現,文や文書のベクトル化は，検索拡張生成（RAG）をはじめとした広範な自然言語処理アプリケーションを実装するための基盤技術である．本稿では，文埋め込みの標準的な構成方法である平均プーリングが，構成要素となる単語埋め込み集合の持つ空間的な広がりの情報を潰し得る，という問題を指摘する．また実験により，上記の問題が実際のテキストと深層学習モデルで確かに生じていることと，一方でその割合は小さいことを示す．実験結果は平均プーリングの経験的な有用性を支持するものだが，同時に，文表現の構成方法を再検討する必要性を示唆するものである．
A10-5,語義の箱埋め込み学習とその応用,小田康平|白井清昭,,A10:埋め込み表現,語義曖昧性解消の先行研究では語義の埋め込みを単一のベクトルで表現していたのに対し，本研究は語義の箱埋め込みを学習する手法を提案する．箱埋め込みの学習により，語義間の上位下位関係の推定や新語義の判定が可能となる．Prototypical Networksに基づく MetricsWSD を語義の箱埋め込みを学習するように拡張し，モデル学習に必要なエピソードを作成する 2 つの戦略を提案する．評価実験を行い，語義曖昧性解消，新語義の判定，新語義の上位語義の推定という 3 つのタスクについて，提案手法の有効性を確認した．
A10-6,部分空間法に着想を得たTransformerのアテンションヘッドにおける特徴抽出,前田晃弘|鳥居拓馬|日髙昇平|大関洋平,,A10:埋め込み表現,Transformer をベースとした言語モデルは，幅広い自然言語処理タスクにおいて高い性能を示している．本研究は，文における単語分散表現の合成メカニズムを解明するため，Transformer のアテンションヘッドに注目し，その内部計算を部分空間への射影と捉え，ノルムの変化率により各ヘッドで捕捉される言語的な特徴を同定する新たな手法を提案する．事前学習済み BERT を用いた実証実験では，各アテンションヘッドが異なる特徴を抽出している可能性が示唆される．
B10-1,ただ一つのプロンプトによるタスク指向型対話システムの実現,鈴木順大|石垣龍馬|宿里晃太郎|藤本拓真|河窪大介|酒造正樹|前田英作,,B10:対話(2),タスク指向型対話システムは，システム運用者，利用者の双方に共有された明確な対話目的が存在するため，対話シナリオを具体的に設計した上で，システムを構築することが一般的である．したがって，シナリオの各フェーズ毎に大規模言語モデル（LLM）を発話生成に利用する場合であっても，フェーズ間の対話遷移にはルールベースの制御を用いることによってシステム構築をすることが多い．しかしながら，そうしたシステムは，対話フローそのものがルールによって拘束され，ルールで想定されたフローから逸脱するような発話に柔軟に対応することができない．そこで，本研究では，LLM を利用したタスク指向型対話システムをただ一つのプロンプトによって構築することを提案する．旅行代理店対話を事例とし，提案手法を用いて構築した対話システムが，対話破綻を起こすことなくタスク指向型対話が実現可能であることを明らかにした．
B10-2,日本語日常対話コーパスへの基礎解析アノテーション,赤間怜奈|浅原正幸|若狭絢|大村舞|鈴木潤,,B10:対話(2),規範的な日常対話を収録した言語資源「日本語日常対話コーパス」に対し，基礎解析情報のアノテーションをおこなっている．具体的には，形態素解析および構文解析を施し，形態論情報としてUniDic に基づく短単位・長単位形態論情報を，構文情報として文節境界と文節係り受け情報を付与した．さらに，これらの情報を用いて，多言語間で共通化された依存構造アノテーション仕様 UniversalDependencies 準拠の言語資源を構築した．本稿では，基礎解析アノテーションの手順ならびに進捗状況を報告するとともに，アノテーション済みデータの活用事例として，依存構造解析器を構築し既存解析器との比較によりその特性と有用性を紹介する．
B10-3,大規模言語モデルを用いた対話システムの語彙レベル制御,YikaiTseng|徳永健伸|横野光,,B10:対話(2),人間同士の対話では alignment が発生することが昔からよく知られており，我々の先行研究ではLexical Level Alignment (LLA)という発話で使われる単語の語彙レベルでの alignment を提案した．本論文では，対話システムで LLA を実現するために，ChatGPT を発話生成のモデルとして採用し，生成される発話の語彙レベルを制御するための指定の語彙レベルに応じた発話生成用単語リストを作成する外部モジュールを提案する．
B10-4,RealPersonaChat: 話者本人のペルソナと性格特性を含んだ雑談対話コーパス,山下紗苗|井上昂治|郭傲|望月翔太|河原達也|東中竜一郎,,B10:対話(2),"雑談対話システムを設計する際，個性は重要な要素である．人間らしく個性を表出可能な対話システムを実現するために，所与のペルソナに基づいて対話した PersonaChat コーパスが存在する．しかし，当該コーパスでは話者本人のペルソナを使用しておらず，不自然な対話が生じている可能性がある．そこで，我々は，話者本人のペルソナと性格特性を含む，14,000 件の日本語対話からなる RealPersonaChat(RPC)コーパスを構築した．我々は，RPC と既存のコーパスを比較し，RPC の対話はペルソナの情報を過剰に含まないこと，第三者による対話満足度が高いことを明らかにした．また，RPC を用いて個性を反映した対話システムが構築できることを示した．本コーパスは GitHub1）で公開している．"
B10-5,JMultiWOZに対する対話状態アノテーションの付与と対話システムの実装評価,大橋厚元|平井龍|飯塚慎也|東中竜一郎,,B10:対話(2),日本語のマルチドメインタスク指向型対話データセットとして JMultiWOZ が構築されている．しかし，対話状態のアノテーションが付与されていないため，対話モデルの構築には利用できない．本研究では新たに，対話状態のアノテーションをJMultiWOZ に対して追加することで，対話状態追跡と応答生成を遂行できる対話モデルの構築を目指す．さらに，本データセットを用いて実装された対話モデルの評価実験を実施し，英語圏の標準的なデータセットである MultiWOZ2.2 と同難易度のベンチマークを，JMultiWOZ が提供できることを示す1）．
B10-6,敵対的発言を取り入れた議論による言語モデルの学習強化と推論力の向上,MengsayLoem|金子正弘|岡崎直観,,B10:対話(2),大規模言語モデル（Large Language Model; LLM）は他モデルや人間との議論を通じて問題に対する理解を深めることができる。議論はモデルの学習段階においても論理的・批判的思考力や説明力の向上に寄与すると考えられるが、従来研究では議論を推論時にのみ活用していた。本研究では、学習段階において学習モデルの出力が不正解の場合には正解に、正解の場合には不正解に誘導する敵対的議論を行う「反論モデル」によるフレームワークを提案する。提案手法では議論を用いた追加学習を行い、学習モデルのパラメータを更新する。議論を行わない手法、推論段階に議論を適用する手法、推論過程を言語化する Chain-of-Thought (CoT)と比較して、提案手法は算術、常識推論、質問応答タスクにおいて高い性能を示した。
C10-1,Multilingual CommonsenseQA,坂井優介|上垣外英剛|渡辺太郎,,C10:言語資源・アノテーション(3),言語モデルの自然言語理解能力を測る評価用データセットは多くの言語で不足している．また言語モデルのマルチリンガル性能に焦点を当てたとき，多言語間で対応の取れたデータセットは希少なため，その評価は限定的である．しかしデータセットを人手で構築するには限りがある．この問題を解決するため，本研究ではデータセットの作成過程を多段階に分割し，従来人手で作問していた工程を生成型マルチリンガル言語モデルに置換することで，効率的にマルチリンガルデータセットを作成する方法を提案する．本研究では CommonsenseQA に焦点を当て，提案手法を用いて 8 言語に拡張する．作成したデータセットは作成に使用した言語モデル自身にとっても十分難易度の高いデータセットとなった．
C10-2,ニューラル機械翻訳のための日中対訳コーパスの拡充,張津一|李皓威|高忠輝|毛剣楠|田野|松本忠博|肖桐,,C10:言語資源・アノテーション(3),映画やテレビの字幕は自然言語処理のタスクにおいて重要な役割を果たしてきたが，日本語と中国語の対訳コーパスは依然として不足している．このギャップを埋めるため，著者たちは以前様々な映画やテレビシリーズのウェブサイトから字幕テキストをクロールして，日中対訳コーパスWCC-JC 1.0 とその後継の WCC-JC 2.0 を開発した．最新版の WCC-JC 3.0 は 330 万以上の対訳文対を含み，WCC-JC 2.0 から 55%以上増加した．WCC-JC3.0 の有効性を評価するため，BLEU スコアを測定し，それに基づいてモデルの翻訳を人手で評価した．WCC-JC 3.0 は研究目的のみで利用可能である．
C10-3,『現代日本語書き言葉均衡コーパス』に対する分類語彙表番号悉皆付与,浅田宗磨|古宮嘉那子|浅原正幸,,C10:言語資源・アノテーション(3),本研究では、コーパスを語義情報で検索できるようにすることを目標とし、『現代日本語書き言葉均衡コーパス』(BCCWJ)に対して『分類語彙表』の語義情報を悉皆付与した。BCCWJ-WLSP を訓練データとした all-words WSD モデルを構築し、BCCWJ 1億語規模の分類語彙表番号付きデータを構築した。訓練に用いなかった 10 レジスタについて、500 語に対して人手による性能評価を行い、データの有用性を検証した。さらに、構築した語義付き語彙表について解説する。
C10-4,Word2Vecと対訳単語対を利用した対義語の自動抽出,栁原弘哉|村上仁一,,C10:言語資源・アノテーション(3),対義語抽出は自然言語処理分野において非常に重要なタスクである．しかし，対義語抽出に関する研究[1][2]は少なく，WordNet 等の人手で作成された辞書を正解ラベルとして利用する手法が主流である．本研究では，コーパスにおける“文脈情報”と “単語の対訳関係”を利用することで，正解ラベルを使用せず全自動（人手作成の辞書に依存しない方法）で対義語抽出を試みた．コーパスの文脈情報には，日本語 Wikipedia の記事で学習したWord2Vec[3][4]モデルを使用した．また，単語の対訳関係には，JParaCrawl に対して IBM モデルに基づく FastAlign[5]で単語対応付けを行った．テスト実験により，59%の正解率が得られた．
C10-5,大規模言語モデルを用いたタグ付けによるデータの品質向上,草野元紀,,C10:言語資源・アノテーション(3),データ分析における結果の質を向上させるためには、入力データの質を担保することが重要である。本研究では、データの品質を向上させる目的で、各データ項目にタグを付けることを考える。タグ付けを行うことにより、複数のデータを横断的に扱うデータ分析が容易になり、情報検索の高速化に貢献する。従来手法では、何らかの外部ソースから関連データを抽出し、入力データと結合することで情報拡張が行われていたが、すべてのデータで望ましい外部データを得られるとは限らない。一方で、昨今の大規模言語モデル(LLM)の進展により、関連データが存在しなくても、LLM が含む知識を基に教師なしでデータの特性を予測することが可能になっている。本論文では、LLM を用いたタグ付けシステムGA-Tag (Generated and Aggregated Tag)を紹介する。プロンプトエンジニアリングにより LLM を活用して一つのデータ項目にタグを付与することは可能であるが、大量のデータ項目にタグを付ける際には、後段のデータ処理を考慮し、管理しやすい形式に整理する必要がある。GA-Tag では、LLM によってタグを生成(generated)するが、工夫をしないとタグの総数が爆発的に増えるためデータ管理を目的としてタグを集約(aggregated)する。実データを用いた検証では、教師なしにタグ付けが行えることと、生成されるタグを用いて比較分析ができるようになること、タグの総数を抑えらていることを紹介する。
C10-6,GPT-4による診療文書からのオントロジー自動構築の初期検討,小林和馬|山本和英|浜本隆二,,C10:言語資源・アノテーション(3),読影レポートからなるテキスト・コーパスを用いたオントロジーの自動構築を試みた。まず、オントロジーは医学的エンティティが属する三段階の意味的階層からなると定義し、これを出現形、標準表記、ラベルとした。続いて、各階層のスキーマをデータ駆動的に発見する過程を、ラベル発見タスクと標準表記発見タスクに分解し、GPT-4 による Proposal-Synthesis 型の段階的推論を行った。これにより構築したオントロジー・スキーマに基づき、それぞれの医学的エンティティに対する識別、標準化、ラベリングの過程からなるマッピングを行い、オントロジーを自動構築し、その妥当性を検証した。
D10-1,通訳品質評価に関するデータ収集と分析,安田圭志|菅谷史昭|池田美紀子|米澤早紀恵|隅田英一郎,,D10:テーマセッション１：人間と計算機のことばの評価(2),本論文では、通訳者による翻訳の訳質を評価することを目的とし、実際の通訳者および、通訳学習者による通訳結果のデータ収集した後、実施した主観評価を説明する。次に、主観評価のコストを低減することを視野にいれ、機械翻訳の研究分野で利用される翻訳自動評価法による自動評価値と、主観評価値との関係性についての分析を行なう。
D10-2,嗜好データセットの学習に基づく応答文のアライメント ‐日本語大規模言語モデルへの適用と安全性の評価‐,三橋亮太|田中稔之|山田健太郎,,D10:テーマセッション１：人間と計算機のことばの評価(2),"移動型のモビリティへの導入を目指した,対話型日本語大規模言語モデルを構築し,応答文の安全性を評価した.対話システムの社会実装を進める上で,有害な入力文に応じた,有害な応答文の生成の抑制が課題として挙げられる.本稿では,一般ユーザーの大規模言語モデルのユースケースの一例として自由対話を選択し,構築したモデルから有害な応答文の生成事例を確認した.上記応答を抑制するため,応答文のアライメントと呼ばれる手法を適用した.アライメントの有無の比較から,応答文のアライメントは,大規模言語モデルにおける応答文の安全性を全ての評価基準で増加させることを確認した."
D10-3,Beyond ROUGE: Applying an ELO algorithm to rank model performances in summarization,◊RomainHarang,,D10:テーマセッション１：人間と計算機のことばの評価(2),"We apply an ELO-based algorithm to evaluate the per-formances of Language models in text generation by gen-erating one-on-one encounters in which a judge functiondetermines the outcome. We decided to apply this to thetext summarization task on the CNN-Dailymail Dataset us-ing state-of-the-art models and GPT3 and GPT4 in 0-shotas the judge function and the diﬀerence in ROUGE scoresand compare with ROUGE.We found that this approach is weakly correlated toROUGE; a correlation can only be found after assuminga signiﬁcant random noise and giving a radically diﬀerentranking of the models on the task. In particular, GPT4is preferred as a summarizer. We also found that our re-sults contradict the assumption that the ground truth isbest for the CNN-Dailymail Dataset, comforting previousﬁndings. This research opens avenues for a more compre-hensive understanding of language model performance intext summarization tasks."
D10-4,英日翻訳方略体系に基づく「直訳」「意訳」の訳出分析,山本真佑花|藤田篤|影浦峡,,D10:テーマセッション１：人間と計算機のことばの評価(2),本研究では、しばしば用いられる「直訳」「意訳」という言葉が具体的にはどのような翻訳現象を表しているのかを、山本ら[1]の英日翻訳方略体系に基づいて分析した。この結果から以下の 2 点がわかった。まず、文書ごとの書き換え数の合計を、直訳、意訳間で比較したところ、両者に固有の特徴は見つからなかった。また、事例に対応する方略の頻度分布からは、直訳では、S13（Focus change）の操作が多く使用されていた一方で、意訳では、G12（Omission）、S5（Abstraction change）の操作が多く使用されていた。
D10-5,Adversarial Evaluation of Dialogue System Metrics,◊JustinVasselli|TaroWatanabe,,D10:テーマセッション１：人間と計算機のことばの評価(2),"Eﬀective dialogue system evaluation requires metricsthat align with human judgment and are resilient againstadversarial attacks. We present a benchmark to evaluatethe robustness of evaluation metrics against adversarial at-tacks, including generic responses, ungrammatical replies,and context repetition. We ﬁnd the metric with the high-est correlation with human annotation, GPT-4, is eﬀec-tive against generic responses and context repetition, whilemetrics with lower human correlation like UniEval outper-for m GPT when countering ungrammatical responses. Theproposed benchmark serves as a valuable tool for assessingthe robustness of dialogue evaluation metrics."
D10-6,Polos: 画像キャプション生成における教師あり自動評価尺度,和田唯我|兼田寛大|齋藤大地|杉浦孔明,,D10:テーマセッション１：人間と計算機のことばの評価(2),"画像キャプション生成タスクでは，生成文の品質が適切に評価されることが重要である．しかし，近年のデータ駆動型自動評価尺度は，多様な画像および言語に対する汎化性能が低いという問題が指摘されている．この問題は，これらの尺度が画像キャプション生成とは無関係なタスクで学習された埋め込み表現を用いており，また古典的手法によって類似度を計算しているだけに過ぎないためであると考えられる．そこで，本研究では，画像キャプション生成タスクにおける教師あり自動評価尺度 Polos を提案する．Polos は画像と言語を入力とし，大規模対照学習によって学習された埋め込みを用いた並列クロスモーダル特徴抽出機構により評価値を計算する．また，本研究では人間のフィードバックに基づき自動評価尺度を学習するフレームワーク M2LHFを提案する．さらに，Polos を学習するため，550 人の被験者から 13 万サンプルの人間による評価を収集した最大規模のデータセット Polaris を構築した．実験の結果，Polos は Composite, Flickr8K-Expert,Flickr8K-CF, PASCAL-50S, FOIL, Polaris において，既存手法を上回る結果を得た．"
E10-1,大規模言語モデルの文処理は人間らしいのか？,栗林樹生|大関洋平|TimothyBaldwin,,E10:テーマセッション６：深層学習時代の言語学と自然言語処理(3),言語モデルの計算する次単語確率は，人間の読み活動（読み時間など）をうまく説明する．この知見のもと，本研究では，教師あり指示学習（インストラクション・チューニング）済みの大規模言語モデルが，通常の大規模言語モデルと比べて，人間の読み活動と乖離した単語確率を計算する傾向を示す．すなわち，人間に好まれる応答をするよう言語モデルを追調整することは，心理言語学的な意味でモデルを人間に近づけることを含意していない．さらに，読み時間の予測に有効な指示（プロンプト）を調査する．特定の言語学的仮説を言語化した指示が有効であったものの，依然として純粋な次単語確率の方が人間の読み振る舞いを予測できた．
E10-2,Tree Planted Transformer: 統語的大規模言語モデルの構築に向けて,吉田遼|染谷大河|大関洋平,,E10:テーマセッション６：深層学習時代の言語学と自然言語処理(3),本研究では、小〜中規模ツリーバンクにより統語知識を導入したのち、その統語知識を足場かけとしてテキストコーパスで効率良く大規模化するという統語的大規模言語モデルのフレームワークを提案する。その先駆けとして、Transformer 言語モデルのアテンション重みがツリーバンク上の統語構造に基づく分布に近づくように学習を行う手法(Tree PlantingTraining)を実装し、通常のテキストコーパスでの追加・継続学習が可能なアーキテクチャである TreePlanted Transformer (TPT)を構築する。評価の結果、TPT はトークン列の確率のみをモデル化しているにも関わらず統語的言語モデル相当の統語知識を獲得していることが確かめられ、統語的大規模言語モデルの基盤となりうることが示唆された。
E10-3,自然言語、述語項構造、グラフ（項同士を線や矢印で結んだ表現形式）の表現能力や表現効率性,高橋速巳,,E10:テーマセッション６：深層学習時代の言語学と自然言語処理(3),1905 年頃、夏目漱石は以下のようなことを述べている.「文学上の作品から得た感情を、どうして有形的な文字もしくは記号で説明するか」「分解をやるのみである」「感情の分解と云う事が非常に困難である」「単に一字を見ても其一字から受ける感情を段々考へて見ると非常な遠い所へ縁を引いて聯想に聯想を重ねて居る.ちょうど薄い紙を何枚も重ねて厚紙が成り立て居る様な場合が多い.其紙を一枚一枚元の様にはがして人に見せる事が困難である如く、一字から出て来る感じを分解して説明するのも大変困難な場合がある.」[1]120 年経った今も、作品から得た感情の説明が困難であるというこの事情は変わっていないように思える.本稿ではこのことの周辺でいくつか仮説や仮構を設ける.「感情の説明」を自然言語・述語項構造・グラフは円滑に行うことができないのではないかという仮説を述べ、この困難や不透明性を和らげるための３つの概念装置を提案する.「構造の効果」（概念装置 1）という考え方の下で、単なる因果ではない「重ねあわせ」が生じていると想定し、複数の「越境形式」（概念装置 3）を「モンタージュ」（概念装置 2）させて、小説や映画といった対象を近似的に再構成する.この 3 つの概念装置によって得られる表現形式は Neural Network(以下、NN)と対立するものではなく NN の input や output としての使用を想定している.
E10-4,小規模言語モデルによる統語パラメータの獲得,山田裕真|染谷大河|大関洋平,,E10:テーマセッション６：深層学習時代の言語学と自然言語処理(3),本研究では、言語モデルが統語パラメータを獲得できるか検証することを目的とする。統語パラメータとは、CoLA/BLiMP 等のベンチマークで評価される様な統語現象毎の統語能力では無く、統語現象間の相関・クラスター効果に関する統語能力であり、理論言語学において生得的に賦与されると仮定されている。具体的には、人間の言語獲得を量・質共に近似した小規模言語モデルである BabyBERTa が、冠詞の有無と 2 種類の移動の可否の間の相関・クラスター効果を説明する NP/DP パラメータを獲得できるか検証する。結果として、BabyBERTa が NP/DPパラメータを部分的に獲得できることが示され、統語パラメータが生得的に賦与される必要は無く、経験的に獲得される可能性が示唆された。
E10-5,言語モデルの文法知識評価における間接肯定証拠の分析,大羽未悠|大関洋平|深津聡世|芳賀あかり|大内啓樹|渡辺太郎|菅原朔,,E10:テーマセッション６：深層学習時代の言語学と自然言語処理(3),なぜ大規模言語モデルは人間の数千倍以上の量の訓練データを必要とするのだろうか？本研究では，人間が未知の言語現象を含む文の容認性を関連する観測事例（間接肯定証拠）から類推可能であることに着目する．言語モデルも人間と同様に間接肯定証拠を利用できるかを分析することで，間接肯定証拠の利用可否が人間と言語モデルのデータ効率の差の要因となる帰納バイアスの候補になりうるかを調査する．実験の結果，少なくとも本研究の範囲では，言語モデルは学習時に間接肯定証拠を利用していないことが明らかとなり，このことがデータ効率の差を引き起こしている可能性が示唆された．
P10-1,ChatGPTと表整理技術を利用した株価に関わる新聞記事の分析,村田真樹,,P10:ポスター,本研究では，株価予測のために毎日新聞の記事を表整理技術と ChatGPT を用いて分析している．分析から，日経平均株価に影響を与える 22 の主要因が特定された．また，ChatGPT が新聞データを抽出し，表形式で表示できることがわかった．さらに，ChatGPT に表整理技術を統合することで，高効率で大規模な表生成手法を構築した．この手法は緩い基準を用いて 0.88 を達成している．日経平均株価に関連する記事で頻出する項目を体系的に表にし，その項目に対して株価指数がどのように上昇・下降するかを表に示した．機械学習の素性となるカテゴリを ChatGPT を利用して取り出すことで，知見獲得を目的とする特殊な状況での株価の上昇下落の予測性能が向上することを確認した．ChatGPT によるカテゴリにより，株価の上昇下落の理由がわかりやすくなった．ChatGPT によるカテゴリを利用して，同種のカテゴリを持つが挙動が異なるデータの分析も行った．
P10-2,LDA を使った専門用語の教師なしクラスタリング,黒田航|相良かおる|東条佳奈|麻子軒|西嶋佑太郎|山崎誠,,P10:ポスター,医療，(政治)経済，法律，出版の 4 分野の用語の，Latent Dirichet Allocation (LDA)を使った教師なしクラスタリングの実用性を検討した．単語を documentとし，文字の(不)連続𝑛-gram (𝑛< 4)を term としてLDA を実行した．結果から判った事は 2 つある．小さな topic 数で用語を分野別に分ける課題が実現できる．大きな topic 数では語構成パターンの分類が可能になる．
P10-3,言語モデルからの知識削除：頻出実体の知識は副作用が破滅的,高橋良允|鴨田豪|BenjaminHeinzerling|坂口慶祐|乾健太郎,,P10:ポスター,言語モデル（LM）は学習を通じて内部に知識を獲得できるが，学習データに含まれる個人情報や機密情報によりプライバシーに関する課題が生じる．そのため，LM の知識削除に関する研究が活発に行われているが，LM に学習させる知識の構造を考慮した分析は十分に行われていない．本研究では，知識構造に着目して LM に対する知識削除の影響を分析し，頻出実体に関する知識の削除は大きな副作用を伴い破滅的であることを明らかにした．また，制御された知識構造で学習したモデルを使用して知識削除を分析した初めての研究であり，人工的な知識グラフを用いた知識削除に関する分析の新たな方向性を示した．
P10-4,知識グラフ構築に向けた物語文の構造分析,佐藤浩輔|頼展韜,,P10:ポスター,ゲームやアニメ、映画、漫画などといった近年大規模化し領域横断的に展開するコンテンツ産業において、物語およびその設定に関わる知識をどのように整備・運用するかが課題になっている。物語においては世界内の状態が動的に変化するため、通常の知識グラフでは十分に扱いきれないという問題がある。そこで本研究では、知識グラフの構築の下準備として、物語文（グリム童話）を対象に物語を構成する述語の観点から予備的な分析を行い、課題を抽出した。自然言語処理タスクとしての物語文からの知識グラフ構築について議論する。
P10-5,探査子法を用いた音楽から学習可能な言語モデルの構文的性質の解析,加藤万理子|高橋信行,,P10:ポスター,"自然言語が持つ構造と似た構造を持つ非言語データとして音楽やプログラムコードのデータを事前学習に用いる研究から,非言語データから自然言語習得に寄与する構造的知識が得られていることが先行研究によりわかっている.一方で,音楽データについては構造解釈が複雑なことから具体的にどのような構造が獲得されているか明らかになっていない.本研究では音楽データに着目し,音楽データが自然言語習得に寄与することを確認したのち,探査子を用いて言語モデルが音楽データから学習している構文レベルの言語学的性質を明らかにする."
P10-6,事前学習済みの分散表現は表層的な知識を獲得しているか,平岡達也|岡崎直観,,P10:ポスター,本研究では，事前学習済みのサブワード・単語の分散表現が表層的な知識（文字数や部分文字列）を獲得しているかを 3 つの観点から検証する．英語を主に学習した 9 つの分散表現について実験を行い，これらが文字数や部分文字列に関する情報はある程度捉えているが，どの文字が何番目に出現するかといった順序の情報は獲得できていないことを示す．
P10-7,大規模言語モデルを用いたマイソクPDFからの情報抽出,本郷槙一|叶内晨|齊藤佑太郎|岩成達哉,,P10:ポスター,本研究では，不動産業界で物件情報の流通に使用される PDF データからの効率的な情報抽出を目指す．実験では，PDF を入力として，あらかじめ指定したカテゴリに対してどの程度情報抽出できるか検証した．実験の結果，OCR による出力後に大規模言語モデルを用いて必要な情報を抽出する 2 ステップの手法の精度が最も高く，Accuracy 0.92 を達成した．また，データ入力業務において本研究の出力結果を活用することで，65%の業務時間削減が可能なことを確認した．
P10-8,Empirical Study on Text Classification of Small Science Domain Datasets,◊ShanshanLiu|MasashiIshii|YujiMatsumoto,,P10:ポスター,"As for the classiﬁcation of scientiﬁc texts, there are noclear states on how much data is needed for model train-ing and what performance mainstream text classiﬁers canachieve. This paper uses the number of training papers asa variable to train the models for sentence classiﬁcationtasks on the thermoelectric material synthesis proceduredataset and the polymer biodegradability dataset, and ana-lyzes the results of two classiﬁers based on LLaMA-2-7band SciBERT-base. We aim to provide model baselinesand corresponding data requirements for reference."
P10-9,LLMは日本語追加学習により言語間知識転移を起こすのか？,佐藤美唯|髙野志歩|梶浦照乃|倉光君郎,,P10:ポスター,"大規模言語モデル(Large Language Model, LLM)における言語間知識転移は，英語を中心に公開されている情報を日本語でも活用できるようになることから関心が高まっている．現在，英語圏で開発された高性能な LLM に，日本語を追加学習させて，日本語でも英語と同様の能力を目指す動きがある．本研究では，LLM は日本語追加学習により言語間知識転移を起こすのかをコード生成タスクに焦点を当てて分析する．我々は，日本語からコードを生成する能力を評価するために，ベンチマークデータセットである HumanEval を日本語へ拡張した JHumanEval を開発した．そして，日本語追加学習が LLM のコード生成能力にどのような影響を与えるかを検証した．"
P10-10,訓練可能なk近傍Retrieverで関係抽出事例を導入したニューラルプロンプティング,牧野晃平|三輪誠|佐々木裕,,P10:ポスター,近傍法による関係抽出では，関係の事例を推論に利用すると，少ない訓練データでも高い性能で抽出が可能になるという報告がある．LLM による抽出では，Retriever によって得た事例を使う方法があるものの，事例の選択が微分できないため，Retrieverを end-to-end に訓練できない．そこで本研究では，微分可能な k 近傍事例のソフトな選択を利用して，事例をソフトプロンプトとして導入するニューラルプロンプティングを行うことで，関係抽出でend-to-end に Retriever を訓練できるようにする．標準的なベンチマーク用データセットの TACRED に対する抽出性能は，訓練事例数を 10%と 5%とした場合に，F 値でそれぞれ 71.0%と 70.9%となり，訓練事例を削減した条件では最先端の性能が得られた．
P10-11,他文書の予測を知識グラフに蓄積・利用する文書単位関係抽出,松原拓磨|辻村有輝|三輪誠|佐々木裕,,P10:ポスター,従来の文書単位深層関係抽出では，文書を個別に処理しており，他の文書で予測した関係を利用できていない．そこで，本研究では，再学習せずに予測時に他の文書で予測した関係を知識グラフに関連付けることで，低コストに処理単位を超えて情報を共有する文書単位の関係抽出を提案する．実験では生物医学分野の文書単位関係抽出データセットであるBioRED データセットにおいて，他の文書で予測した関係による関係予測への影響を確認した．
P10-12,生成AIによる化学文書への自動アノテーションとその評価,朱晨成|谷口友紀|大熊智子|嶋田和孝,,P10:ポスター,材料・化学分野のテキストに対して，固有表現抽出を試みる場合，学習に使えるデータが十分でないことやアノテーションに高度な専門知識が必要であるという問題点がある．近年，隆盛を極めている生成 AI（GPT）を用いて固有表現抽出を試みることも可能だが，一般に，教師あり学習によりモデルをタスクに特化する方が良い精度が得られることが多い．そこで，本研究では GPT を用い，いくつかのプロンプトによる自動アノテーションを導入する．自動アノテーションによって得られた訓練データを基にラベル予測モデルを学習し，人間によるアノテーションデータとの精度差についても検証する．
P10-13,機密情報検知における生成AIを用いたデータ拡張,岸波洋介|藤井諒|加藤善大,,P10:ポスター,企業において，電子メールやチャットの誤送信等，様々な場面に機密情報漏えいのリスクが存在する．これに対して，入力文中の機密情報を事前に検知することが有用であると考えられるが，モデルの学習には大規模なデータセットが必要となる．そこで本研究では，生成 AI を用いた機密情報検知のデータ拡張手法を提案する．実験では提案手法で作成したデータを用いて企業名，および法人名を検知するモデルの学習を行い，有効性を調査した．実験の結果，生成 AI を用いてエンティティを拡張する手法によりベースラインに比べ F1 で 2.5%の大幅な精度向上を確認した．
P10-14,CVAEによる複数データセットからの固有表現抽出,大井拓|三輪誠|佐々木裕,,P10:ポスター,固有表現抽出などで主流となっている教師あり深層学習で高い性能を達成するには大量のラベル付きデータが必要になる．ラベル付きデータを増やすために既存のラベル付きデータセットを複数組み合わせて使用する方法が考えられるが，データセットごとにラベル付けの違いがあり性能が上がるとは限らないという問題がある．そこで本研究ではデータセットごとのラベル付けの違いを CVAE (ConditionalVariational Autoencoder)を用いた損失関数を加えることで弱い制約として固有表現抽出モデルに与える手法を提案する．実験では生物医学文書に対する固有表現抽出において提案手法の有効性を示した．
P10-15,ニュース記事テキストにおける組織名の抽出,田村光太郎,,P10:ポスター,ニュース記事は日々多量に配信され，その情報の瞬時の整理・構造化が求められる．我々は，ビジネスや業界固有のトピックを含むニュース記事データを利用し，テキストに現れる組織名とそれに関わる情報を固有表現として抽出するモデルを構築した．モデルは，エンティティ単位での知識も埋め込まれた LUKE を採用し，単語境界をよりとらえられるようにトークナイザーや知識を更新した．公開データセットを用い，提案モデルによる精度検証を行い，一定程度の精度改善が見られることを確認し，また，実データに適用することで，実データでの情報抽出の精度改善に必要な課題を考察した．
P10-16,一部のエンティティに紐づくテキスト情報を知識グラフ埋め込みに活用するための手法,風間健太郎|中村光祐|乙村浩太郎|小路悠介,,P10:ポスター,知識グラフ埋め込みは知識グラフの構成要素をベクトルとして埋め込む手法で，近年，構成要素に紐づくテキストを利用して性能を向上させる手法が提案されている．一方，実用上対象となる知識グラフにおいては，有効なテキスト情報を持つ要素と持たない要素が混在する場合がありえる．本研究では，一部のエンティティのみ有効なテキスト情報が紐づく知識グラフにおいてもテキスト情報を活用可能な手法を提案する．実際の社内技術文書から構築した知識グラフを対象にリンク予測タスクによって精度を評価したところ，ベースとなる TransE を上回る精度を達成し，提案手法が一部のエンティティにのみ有効なテキスト情報が紐づく知識グラフに対して効果があることを確認した．
P10-17,文献グラフにおける多項関係の埋め込み,井田龍希|三輪誠|佐々木裕,,P10:ポスター,知識グラフ埋め込み（Knowledge Graph Embeddings;KGE）では，二つの節点間の関係，すなわち，二項関係を表現する埋め込みを学習している．二項関係は，複数のエンティティと関連するエンティティの検索など，より複雑な関係を推定する上では不十分であり，複数の節点間の関係である多項関係を考慮する必要がある．本研究では，多項関係を考慮する KGE の獲得を目指し，多項関係をモデル化するKGE モデルを提案する．実験では，文献グラフ内の多項関係の予測性能を評価する．
P10-18,衣服を対象とした商品レビューからの長所・短所の抽出,井上京|山田剛一|増田英孝,,P10:ポスター,近年，アパレル通販市場が拡大しており，商品レビューはユーザが商品を購入するかどうか決める際の大きな手掛かりとなっている．しかし，商品レビュー数が多い場合，それらをすべて読むことは難しい．そこで，本研究では商品の長所・短所を提示することを目的とし，商品レビューから商品の長所・短所を抽出する手法を提案する．商品レビューから属性と評価値を抽出し，それらに対する感情の 3 つをトリプレットとして予測する．また，商品レビューに属性が明記されていない場合には，その属性の推定も行う．評価実験において，トリプレット抽出の F1 スコアが「T シャツ・カットソー」カテゴリで0.54，「セーター」カテゴリで 0.53 であった．
P10-19,複数の形式・表現の質問を利用した多角的な関係抽出,山田晃士|三輪誠|佐々木裕,,P10:ポスター,質問応答を用いた関係抽出手法は，各関係タイプごとにその有無を確認する質問を利用し，それぞれの関係タイプに特化した処理を可能にしている．さらに，これらの手法では，質問を変えると結果が変わる柔軟性をもつが，既存手法はそれを十分に利用できていない．本研究では，質問の柔軟性を利用し，関係そのものを複数の方法で捉える，多角的な捉え方が可能な関係抽出の実現を目指し，複数の形式・表現の質問を利用する関係抽出手法を提案する．DrugProt データセットを用いた評価によって，複数の質問形式の利用が有効であること，質問の表現による関係抽出性能への影響を確認した．
P10-20,テキストアナリティクスツールの説明文に含まれる設定キーの認識,仲田将斗|亀甲博貴|森信介,,P10:ポスター,テキストアナリティクスツールは，テキスト集合の性質を統計的に明らかにすることを目的として，人文学において広く用いられている．こうした分野において，テキストアナリティクス実験の再現性を保証するために，論文の説明文から分析手法やそのパラメータを正しく特定することが大事となる．我々はこれをいくつかのサブタスクへ分解し，そのうちの一つである設定キー認識タスクに焦点を当てた．ここでは設定キーごとの二値分類として定式化し，事前学習済みの言語モデルに基づくencoder-decoder モデルを提案する．
P10-21,ChatGPTを用いた複数文章からの表生成,野田直哉|村田真樹,,P10:ポスター,"本研究は,村田ら[1]の単語ベクトルとクラスタリングを用いた表生成と, ChatGPT を利用した表生成の精度を比較した.実験では,人手で作成した正解として定義した表との比較評価において,村田らの先行研究と ChatGPT を利用した手法の F 値が 0.61 と0.64 であり,同程度の性能であった.また,正解のラベル(列の項目名)を用いて表を作成し場合の精度はF 値で 0.78 となった."
P10-22,敵対的生成ネットワークを用いた記号的知識蒸留,日浦隆博|河野誠也|AngelFernandoGarciaContreras|吉野幸一郎,,P10:ポスター,大規模言語モデル（LLM）は多くの自然言語処理タスクで顕著な能力を持つものの、知識推論のようなタスクでは依然として性能に課題があり、LLM が持つカバレージを維持しつつ知識推論の性能を上げる方法が模索されている。その中でも記号的知識蒸留は、大規模言語モデルの出力を知識グラフとして転移しつつ知識推論モデルの学習に用いるもので、非常に膨大な知識グラフの獲得が期待できる。しかし、LLM の出力にはしばしば意味的・文法的に誤ったデータが多数含まれ、それらを除去するフィルタが必要となることが知られている。本研究では、敵対的な学習方法を導入し、知識の生成（選択）と蒸留を同時に学習することで、追加のアノテーションを必要とせずにこうしたフィルタを実現する手法を提案する。
P10-23,知識グラフに基づくルールベースよるFact Verificationとその拡張手法の考察,籾井裕貴|滝口哲也|有木康雄,,P10:ポスター,Fact Verirication とは，claim に誤った情報が含まれていないかを判定するタスクであり，判定に必要な情報を検索するステップと，検索された情報に基づき claim の真偽を判定するステップで構成される．本論文では，最終判定の説明性を高めるため，知識グラフを活用し，最終判定をルールベースで行う方法を提案する．FACTKG データセットによる実験では，ルールベースの手法でモデルベースの手法と同等の結果が得られた．さらに，ルールベースの判定で課題となる，複数の知識トリプルを比較して判定を行う方法について議論する．
P10-24,表層が同じ文字列の同一性を表現した深層固有表現抽出,吉村貴紀|牧野晃平|三輪誠|佐々木裕,,P10:ポスター,本稿では，BERT の内部で文書中の表層が同じ文字列について，その同一性を表現する機構を取り入れた，One Sense Per Discourse 仮説を考慮した深層固有表現抽出モデルを提案する．日本語医療文書データセット Real-MedNLP において提案手法における固有表現抽出の性能は向上しなかったが，解析によりモデルが予測する固有表現のタイプの一貫性が向上していることや，表層が同じ固有表現のスパンを正しく認識できた場合にそのタイプの正解率が向上することを確認した．
P10-25,妊娠・出産・育児に関する情報サイトにおける自治体による子育て支援効果の調査,新井田瑠璃|佐藤栄作|木村泰知|内田ゆず,,P10:ポスター,"本研究では,妊娠・出産・育児に関する情報サイトのデータを分析し,地方自治体の子育て支援の効果を調査することを目的としている.本研究は,東京都のデータを用いたアノテーションと,東京都以外の 46 道府県のデータに対する BERT による自動推定を通じて,機械学習を用いた子育て支援効果の推定の可能性を示した."
P10-26,Sentence-BERTと語義定義文を利用した語義間の類義判定手法,石井佑樹|佐々木稔,,P10:ポスター,自然言語処理技術を開発する上でシソーラスから得られる意味知識は有用である．しかし，既存研究では主に単語間の関係を検出することに注目し，語義を対象とした類義関係の検出は行われていない．本研究では日本語辞書に記述された語義定義文とSentence-BERT を用いた類義判定手法を提案する．岩波国語辞典の見出し語，語義定義文及び分類語彙表の分類番号を用いて作成した評価データセットを対象として，学習データを用いて fine-tuning した類義判定モデルによる類義判定実験を行った．実験の結果，提案手法における Sentence-BERT や変更した語義定義文を用いることによって，ベースライン手法よりも効果的に類義判定ができることを示した．
P10-27,言語構造に制約されない大規模言語モデルの知識編集,石垣龍馬|河窪大介|酒造正樹|前田英作,,P10:ポスター,大規模言語モデル（LLM）は広範な知識と高度な推論能力とを兼ね備えているが，内部処理過程がブラックボックス化されているため，LLM 自身が持つ特定の知識を編集することが難しいという問題がある．これを解決するため，編集対象である知識がエンコードされているニューロンを特定し，このニューロンに関わる重みを調整することによって実現するという，局所変更ベースの知識編集手法が提案されている．しかしながら，この手法も，処理対象となる言語の持つ言語構造に強く依存するという問題がある．そこで本研究では，言語構造に制約されずに知識編集に有効なニューロン（知識ニューロン）を特定する手法を提案する．英語と日本語という言語構造の異なる言語の文に対して提案手法を適用し，知識編集が可能であることを検証し，提案手法の有効性を確認した．
A11-1,Dynamic Inference Thought in Large Language Models,鈴木拓真|川本樹|三山航|目黒拓己|鈴木中穂美|高木友博,,A11:LLM手法提案,本論文では、LLM が必要に応じて事前知識を参照しながら動的に推論を進める新しいフレームワークを提案する。私たちのアプローチでは、LLM による推論とその推論を改善するプロセス、そして現在の思考が十分かを LLM により判断して最終的な回答を推論する。高度な推論を複数の単純な推論に分割すること、多段推論を動的に行うことにより、推論精度の向上を達成する。ANLI データセットを用いて、このフレームワークの有効性を検証しており、先行研究と比較して、最大で 32%の精度向上を達成した。また、定性的評価も行い、本アプローチが従来手法よりも論理的に推論を行えていることを確認した。
A11-2,大規模言語モデル事前学習の安定化,高瀬翔|清野舜|小林颯介|鈴木潤,,A11:LLM手法提案,大規模言語モデルの事前学習では損失スパイクがしばしば起きることが知られている．損失スパイクはモデルの性能を低下させ，学習が失敗してしまうこともある．この損失スパイクの原因を探るため，本研究では中間層の勾配に着目する．理論的な分析を通じて，大規模言語モデルの事前学習では LN 層が勾配爆発を引き起こすこと，および，その解決法を示す．実験を通じて LN 層の勾配爆発を抑制することで損失スパイクも抑制されることを示す．
A11-3,大規模言語モデルに対するサンプリングを活用したメンバーシップ推論攻撃,綿祐貴|金子正弘|YoumiMa|岡崎直観,,A11:LLM手法提案,本研究は，与えられたテキストがモデルの学習データに含まれていたかを判定するメンバーシップ推論攻撃に取り組む．従来手法は，モデルが計算する尤度を必要としており，適用できるモデルが限られる．そこで，本研究では出力テキストだけから検出するサンプリングベース・メンバーシップ推論攻撃を提案する．提案手法は検出対象のテキストを参照テキスト，サンプルされたモデルの複数出力を候補テキストとし，それらの一致度合を計算し，テキストがモデルの学習データに含まれていたか判定する．提案手法は尤度を利用しないにも関わらず，実験では既存手法と肩を並べる性能を発揮し，特に長いテキストを対象とした検出で高い性能を示した．
A11-4,大規模言語モデルにおける評価バイアスの尤度に基づく緩和,大井聖也|金子正弘|小池隆斗|MengsayLoem|岡崎直観,,A11:LLM手法提案,大規模言語モデル(Large Language Model; LLM)は言語生成タスクの評価器として用いられている。ところが、ある文章の意味を変えずに語順や構造を変更した文章を作ると、LLM が計算する尤度が大きく変化することがある。そのため、LLM 評価器には、尤度が低い文章を不当に低く、尤度が高い文章を不当に高く評価する尤度バイアスが存在すると考えられる。本研究では、尤度バイアスが LLM 評価器の性能を低下させることを明らかにし、Few-shotによるバイアス緩和手法を提案する。実験では、複数の LLM が data-to-text タスクと文法誤り訂正タスクで尤度バイアスを持つ可能性を示し、その緩和に成功した。
A11-5,事前学習済みLlama2モデルを活用した言語間転移日英モデルの作成,佐藤諒|麻場直喜|野崎雄太|中島大|近藤宏|川村晋太郎,,A11:LLM手法提案,近年英語を中心に事前学習済み大規模言語モデルが多く公開されてきた。本研究ではそれらのモデルの中でも、ここ最近で高スコアを出した Meta 社のLlama2 13B Chat モデルを再利用し、できるだけ性能の高い日本語モデルを作成することを試みる。特に言語間転移、カリキュラムラーニングの知見を投入し、なるべく事前学習の量を減らした継続学習を行い、日本語を優先した日英モデルの作成の検証結果を報告する。
A11-6,言語モデルの思考連鎖的推論における探索戦略の動的変化,青木洋一|工藤慧音|曾根周作|栗林樹生|谷口雅弥|坂口慶祐|乾健太郎,,A11:LLM手法提案,大規模言語モデルは探索が必要な複雑な推論問題においても一定の性能を示している．例えば推論過程を出力させる思考連鎖指示を用いることで，与えられた前提やゴールに対し，方向感のある推論が可能である．本研究では，大規模言語モデルの一連の推論において，探索に用いる手がかりが動的に変化していることを明らかにする．具体的には，思考連鎖的な推論の初期段階で，モデルは文の位置や質問文との類似度などの表層的な手がかりを用いた探索を行い，推論が進むにつれて最短経路を暗に計算する効率的な探索を行うことが分かった.
B11-1,雑談応答生成モデルによる矛盾応答の大規模収集,佐藤志貴|赤間怜奈|鈴木潤|乾健太郎,,B11:対話(3),雑談応答生成モデルが生成した矛盾応答データの不足は，矛盾応答の抑制に向けた取り組みの障害となっている．本研究では，多様なモデルの矛盾応答からなる大規模データセットを構築する．様々な観点からデータセットを分析し，モデルによる矛盾応答の特徴を明らかにするとともに，構築したデータセットを学習データとして用いることでデータ駆動型の矛盾抑制の有効性が向上することを確認する．
B11-2,ChatGPTを用いた日本語対話応答の多面的自動評価,寺内祐希|加藤恒夫|田村晃裕|池田和史,,B11:対話(3),人間と雑談を行う非タスク指向型対話システムの性能を簡便に測ることのできる自動評価指標が望まれている．対話の応答は多様であり，評価は様々な観点から多面的に行われることが望ましい．そこで本研究では，現在最も性能が優れた大規模言語モデル(LLM)と呼ばれる ChatGPT を用いた，日本語対話応答の多面的な評価を行う．対話の品質を左右すると考える 6 つの評価項目における日本語対話応答の主観評価データを収集し，ChatGPT による自動評価との比較を行う．その結果，ChatGPT と人間の主観評価の相関は，人間同士の相関に近いことを確認した．また，評価対象の文を英語に翻訳することにより，主観評価との相関が強まることを確認した．
B11-3,雑談中の発話と文脈から話者情報を抽出する LLM の能力に関する検証,連慎治|竹下昌志|伊藤敏彦,,B11:対話(3),近年，LLM を用いた雑談システムがユーザやシステム自身の個性を応答生成に活用することで対話の質を向上させる研究が盛んである．しかし，発話者の個性を応答生成に用いるためには対話から発話者の情報を抽出する必要があるが，その抽出手法は十分に研究されていない．また，対話から話者の情報を抽出するためには文脈の考慮も必要だと考えられるが，話者情報抽出における文脈の影響はまだ十分に検証されていない．そこで，本研究では現在最先端とされている LLM がどの程度，雑談発話から文脈を考慮して発話者の情報を抽出できるかを検証する．実験の結果から，最先端の LLM が話者の情報を抽出する際に文脈を十分に考慮できていないことが示された．
B11-4,過去対話セッションからの想起と深化を行う対話モデル,渡邉寛大|河野誠也|湯口彰重|吉野幸一郎,,B11:対話(3),対話システムが人間社会で活用されるためには，高い信頼と長期的な関係を構築するための記憶と学習の能力が必要である．具体的には，過去の対話を記憶し，記憶をもとに様々な経験から知識を更新し，将来の対話で応用する能力が必要である．特に2 回目以降の対話では，過去の対話履歴を想起するだけでなく，対話履歴から想起して利用する外部知識が持つ情報量が重要であることがわかっている[1]．そこで，システムが対話履歴に基づいて想起を行う際，外部知識が持つ情報量を考慮した話題および知識選択のモデルを構築し，大規模言語モデル（GPT-4）のプロンプトとして活用する対話システムを開発した．対話実験から，情報量を考慮した話題選択が，有益な知識の抽出に有効であることを明らかにした．また，情報量を考慮した知識選択が情報提供の側面だけでなく，対話の継続性やエンゲージメント向上といった側面でも有効であることを確認した．
B11-5,非タスク指向型対話における話題の深さ推定モデルの構築,三野星弥|伴碧|吉川雄一郎|石黒浩,,B11:対話(3),非タスク指向型対話システムが，話題の深さを考慮しながらユーザに応じて適切な話題を提示することは，より人間らしく自然な対話を実現するために重要であると考えられる．話題の深さを考慮しながら対話できるシステムの実現のための第一歩として，本研究では，様々な話題について，その深さを推定できるモデルを構築することを目指す．我々は，独自に作成した話題の深さデータセット1）を用いて，GPT-3.5 をファインチューニングし，話題の深さ推定モデルを構築した．そして，評価実験を通して，本モデルが，ベースラインと比較して，高い精度で話題の深さを推定できることを確認した．
B11-6,chat-AMAN: 管制官との双方向コミュニケーションで実現する協働型の航空管制支援システムの構築,宮岡佑弥|井上正樹|虎谷大地|石井南,,B11:対話(3),本研 究で は，新し い管 制支 援シ ステ ム“chat-AMAN”を提案する．chat-AMAN は自然言語処理技術（抜き出し型質疑応答タスク，文書類似タスク）を活用し，管制官との双方向コミュニケーションを可能にする．chat-AMAN は，航空機に対する指示内容案を管制官へ提示し，管制官からの自然言語形式のチャットに基づいて修正を行う．このやり取りを通じて，航空機への指示内容を両者で決定する．chat-AMAN には，管制官のチャットを反映する機能だけでなく，常に航空機の安全性を損なわないような機構もを取り入れている．数値実験では，空港へ到着する航空機に対し，chat-AMAN によって高度指示を決定する過程を示す．
C11-1,生成モデルは医療テキストの固有表現抽出に使えるか？,西山智弘|柴田大作|宇野裕|辻川剛範|北出祐|久保雅洋|矢田竣太郎|若宮翔子|荒牧英治,,C11:情報抽出・データ構築,医療テキストからの情報抽出など，大規模言語モデル（Large Language Model; LLM）の医療分野への利活用に期待が高まっているが，日本語での実施は少ない．本研究では，医療テキストからの固有表現抽出(Named Entity Recognition; NER)について，生成モデルと既存の分類モデルを比較した．その結果，生成モデルにおいて固有表現の種類によっては，データが少数であっても多くのデータでﬁne-tuningした分類モデルに匹敵するような性能で NER が実現可能であることが明らかとなり，精度の高い生成モデルがアノテーション支援に役立つことが示唆された．
C11-2,IDレベル関係抽出における不要な文の自動選択,辻村有輝|三輪誠|佐々木裕,,C11:情報抽出・データ構築,言及を超えた文書に現れるエンティティ間の関係を，エンティティに対応するデータベース上の ID間の関係として抽出する ID レベル関係抽出が取り組まれ始めている．ID により文書を超えた利用性の高い関係情報を抽出できる一方で，入力の広域化による不要な入力情報の増大が問題となる．本研究では，関係抽出対象のエンティティ ID ペアに対する入力文書中の各文の重要性を判断し，不要な文をマスクする ID レベル関係抽出モデルを提案する．さらに固有表現抽出とエンティティリンキングを組み合わせることでテキストのみから ID レベルの関係を抽出するパイプラインシステムを実現し，その性能を明らかにする．
C11-3,事前学習言語モデルとグラフニューラルネットワークの組合せによる専門知識の抽出,浅野聖也|磯沼大|浅谷公威|野村美鈴|森純一郎|坂田一郎,,C11:情報抽出・データ構築,"本研究では,事前学習言語モデルとグラフニューラルネットワークを組み合わせることで,化学物質に関する知識抽出を試みる.具体的には,マスクド言語モデルの一つである BERT にグラフニューラルネットワークを組み込むことで,化学物質の分子構造をグラフ情報として活用することを可能にし,汎化性能が向上することを示す.実験では Scopus の科学論文抄録コーパスを利用し,特に学習コーパスに出現する頻度が少ない化学物質について,従来のモデルに比べて顕著な性能向上を確認した."
C11-4,データ拡張による固有表現抽出の不確実性推定,橋本航|上垣外英剛|渡辺太郎,,C11:情報抽出・データ構築,本研究では，固有表現抽出タスクにおけるデータ拡張が不確実性推定に与える影響について調査する．医療や金融のような高い安全性が求められる領域では，予測結果が正しいだけではなく，その信頼度が高い必要がある．しかし，事前学習済みモデルを含む深層学習モデルはしばしば実際の正解率と乖離した確信度を出力するため，それらの領域への適用が妨げられている．また，その問題に対応する既存手法は推論コストが高い．我々は，ジャンル横断および言語横断の設定にて，固有表現抽出におけるデータ拡張が不確実性の推定性能に与える影響を調査した．その結果，データ拡張は多くの場合不確実性の推定性能を向上させ，データ拡張によって生成した文の Perplexity が低い場合はデータ拡張サイズを増やすことで，さらに不確実性の推定性能が改善することが判明した．
C11-5,変数定義抽出におけるテンプレート文を活用したデータ拡張法,永山航太郎|加藤祥太|加納学,,C11:情報抽出・データ構築,科学技術論文における変数定義の抽出は，論文の理解や活用に欠かせない．しかし，分野によって変数定義の長さや構成する単語は異なるため，既存の変数定義抽出手法の性能は分野間で差がある．各分野の学習データを用意することは性能向上に効果的だが，高品質な学習データの作成コストは高い．この課題を解決するため，本研究では，変数を定義するテンプレート文と学習データ中の変数-変数定義ペアから新たな定義文を生成する手法を提案する．化学プロセス関連論文からの変数定義抽出において，提案手法で生成した定義文で学習した定義抽出モデルは，山本ら[1]のモデルを上回る正解率89.6%を達成した．
C11-6,知識志向 Mixture of LoRA Experts の構築,伊藤俊太朗|河原大輔,,C11:情報抽出・データ構築,大規模言語モデル（LLM）の進化は驚異的であるが、知識の管理には依然として課題が存在する。全パラメタの再学習には膨大なリソースが必要なため、LoRA という手法が採用されることが多い。さらに、複数モデルの出力を組み合わせること（Mixture of Exper ts; MoE）による性能向上が注目されている。本研究では、LoRA と MoE を組み合わせて、モデルのパラメタ増加を最小限に抑えつつ性能を向上させる方法を提案する。提案手法は、知識を専門家（expert）に依存させることで、知識をより効果的かつ局所的に管理する。CommonsenseQA データセットを利用した評価によって提案手法の有効性を確認した。
D11-1,テキスト編集事例の編集操作への自動分解,山口大地|宮田玲|藤田篤|梶原智之|佐藤理史,,D11:テーマセッション１：人間と計算機のことばの評価(3),テキスト編集システムの能力を評価するためには、システムが適用した編集操作を基本的な単位で同定することが重要である。このような編集操作の同定に向け、本稿ではテキスト編集事例の分解タスクを、所与の原文と編集文の間をつなぐ、非冗長かつ文法性を保つ、意味的に関連した最小のまとまりであるプリミティブな編集操作の系列を生成するタスクと定義する。これを自動化するためにアライメントツールと事前学習済み大規模言語モデルを用いた手法を提案し、テキスト平易化と機械翻訳後編集のデータセットを用いた実験の結果について報告する。
D11-2,LCTG Bench: 日本語LLMの制御性ベンチマークの構築,栗原健太郎|三田雅人|張培楠|佐々木翔大|石上亮介|岡崎直観,,D11:テーマセッション１：人間と計算機のことばの評価(3),"日本を含む世界中で大規模言語モデル（LLM）の開発や事業における活用が加速していく中で、LLMの性能評価が重要課題になりつつある。LLM の事業における活用では、記事の入稿規程や SEO 対策などを考慮することから、生成結果の内容の品質のみならず、文字数制約や単語の制約などの制御性もLLM の性能の評価対象となり得る。しかし、日本語 LLM の制御性に着目した評価の枠組みは存在しない。本研究では、LLM の事業応用において留意すべき観点の一つである制御性に焦点を当て、評価ベンチマーク LCTG Bench を構築する。GPT-4 [1]やGemini [2]などの多言語 LLM を含む 11 種類の日本語 LLM を対象とする LCTG Bench を用いたベンチマーク実験を通して,日本語 LLM の制御性に関する現状と課題を示す。"
D11-3,LLMが機械翻訳を捉えた桎梏から脱したのか―翻訳創造性について―,HuachengSong|HaoyingYang|HongzhiXu,,D11:テーマセッション１：人間と計算機のことばの評価(3),翻訳の文化的・技術的転回に伴って、翻訳創造性の重要さが高まる一方、それが自動翻訳モデルに一つの難題だと認識され、訳文における創造性の評価研究がますます必要となる。本研究では、訳者、Google および GPT4 による日本文学の中国語訳を対象に、各翻訳方式の創造性をめぐって細粒度的かつ量的評価を行った。その結果、LLM の翻訳創造性上の性能がニューラル機械翻訳より優れたが、この桎梏から完全に逃したというわけでもなく、翻訳者に比べれば成長の余地が多大にある。
D11-4,Evaluation of ChatGPT Models on Sentence Simplification,XuanxinWu|YukiArase,,D11:テーマセッション１：人間と計算機のことばの評価(3),"Sentence simpliﬁcation, which rewrites a sentence tobe easier to read and understand, is promising technique tohelp people with various reading diﬃculties. Recent inves-tigations have shown that instruction-tuned large languagemodels, namely ChatGPT-3.5, perform strongly on sen-tence simpliﬁcation via prompting. However, it has yet tobe clear how well the most advanced ChatGPT-4 addressesthe problem. Also, it is unclear how eﬀective ﬁne-tuningof ChatGPT-3.5 is on sentence simpliﬁcation. This studyevaluates the capabilities of these two models, by com-paring their performance with the current state-of-the-artsupervised model of Control-T5. The results show thatprompting ChatGPT-4 generally outperforms ﬁne-tunedChatGPT-3.5 and Control-T5, while lexical paraphrasingremains as a challenge."
D11-5,国際会議における質疑応答練習を目的とした ChatGPT による質問生成とその評価,相場真由子|齋藤大輔|峯松信明,,D11:テーマセッション１：人間と計算機のことばの評価(3),本研究では、国際会議における質疑応答の練習を支援する目的で、大規模言語モデルである ChatGPTに当該論文に関する質問を生成させ、論文を執筆した学生、及び、英語プレゼンを指導する語学教師に評価させた。いくつかの方法でテキストベースで専門的な質問を生成させ、評価尺度としては妥当性や有用性を考え複数の尺度を用意した。その結果、論文のキーワードや引用文献を特定˙せ˙ず、「論文 PDFを入力して質問を生成させる」˙簡˙易˙的˙な方法による質問が最も高い妥当性・有用性を示した。国際会議に向けた質疑応答の練習は、語学教師側に専門知識がない場合でも、本手法を用いることで、より現実的な練習が可能となると考えられる。
D11-6,事前学習済みモデルを用いた日本語直喩表現の解釈,鈴木颯仁|山田寛章|徳永健伸,,D11:テーマセッション１：人間と計算機のことばの評価(3),直喩表現（例：ひまわりのような笑顔）に対して，人のような自然な解釈（例：明るい笑顔）の候補を生成するモデルを作成することは，自然言語処理の分野において注目を集めている課題のひとつである．本研究では，事前学習済みマスク言語モデル BERT[1]を用いて直喩表現に対する解釈を生成する．また，形容詞の補完に適したマスク言語モデル(Masked Language Model，MLM)の拡張手法と形容詞-名詞の修飾関係に着目した学習フレームワークを提案する．提案手法の適用によって，直喩解釈のスコアを表す Recall@5 は 0.296 を示し，他比較対象を上回った．
E11-1,教育現場における質問の性質分析と大規模言語モデルを活用した質問回答システムの検討,原田憲旺|EdisonMarrese-Taylor|岩澤有祐|松尾豊,,E11:教育応用,大規模言語モデルの発展により，作業の効率化・自動化や創造性の拡張が期待される．教育分野においても応用例の一つとして学習者の質問に答え学びを促進させる QA システムの開発が期待されるが，現実の利用シーンに即したベンチマークが整備されていないため，QA システムが対処すべき質問の性質が不明なため，開発で注力すべき機能の考慮が行えない．本論文では，教育現場での QA システム開発の一助となることを目指し，実際に行われた講義中において生徒から提出された質問を分析した結果を公開する．また大規模言語モデルを活用して得られた回答文を分析することで今後の課題を明らかにする．
E11-2,複数言語コードを含む発話転写と話者分離：Whisper＋Pyannote.audioによる自動音声認識の高度化,徐勤|砂岡和子,,E11:教育応用,生成系 AI を取り込んだ自動音声認識技術（Automatic Speech Recognition：ASR）は飛 躍的 進歩をとげつつあるが，頻繁に Code-switching（CS）が起きる自然発話の ASR はまだ課題が残る．本文は，CS 発話の典型である外国語授業の3 つのケースを素材とし，Whisper の最新版モデル large-v3 でテキスト転写を行い，更に Pyannote.audio を用いて多人数 CS 発話の話者分離（Speaker Diarization：SD）を行った．large-v3 適用のさいのパラメータ設定，および合成音による SD の結果，従来の手法に比べ，日本語と中国語 CS 発話の ASR 精度が大きく改善した．
E11-3,Prompting Brilliance Unlocking ChatGPT's Potential to Revolutionize EFL Dialogue Practices,◊JulioChristianYoung|宍戸真,,E11:教育応用,"This research addresses a critical  gap in the literatureby  investigating  the  impact  of  prompt  engineering  on generating  high-quality  learning  materials  for  EFL students using  the  relatively new ChatGPT, an area that has  not  been  extensively  explored  in  previous  research. The study  analyzes various prompt techniques  and their impact  on  the  quality  and  characteristics  of  generated dialogues. The  findings  reveal  that  explicitly  providing specifications through the prompt yields better results in terms  of  meeting  desired  low-level  criteria (e.g. word counts  or  lines  per  dialogue). However, for  a  more abstract  criterion (proficiency  level  of  generated materials) only a limited percentage of dialogue produced satisfied the target. Despite receiving explicit instructions to generate dialogue suitable for CEFR B2 students, most of the resulting materials meet criteria below the B2 level. The  unintentional  bias  towards  easier  to  understand response  in  the  training  process  may  contribute  to  this limitation."
E11-4,自然言語処理の教育応用において学習者集団に非依存な難度の尺度は本当に必要か？,江原遥,,E11:教育応用,"教育応用では，個々の学習者に合わせた個別最適な支援（自動作問など）が求められる．一方，作問された設問の「難度」は，設問を解く学習者に関わらず定まる，学習者集団に非依存な尺度であることが求められ，一般ユーザには解釈が難しい，アノテータ間の難度の基準の構築に労力が割かれてきた．しかし，自然言語処理の教育応用では，(学習者,設問文)のペアから個々の学習者が設問に正答するかを予測する予測器さえ構築できれば応用上有用な場面が多く存在すると思われる．本稿では，こうした予測器が入手できる場面で，学習者集団中の予測正答者数の平均を一般ユーザにも解釈しやすい難度の代わりに使える尺度として使う手法を提案する．"
E11-5,英語学習者の発話にみられる非流暢性に関する考察：自己訂正と反復・フィラーの関係性,近大志|瀬戸口彩花|田中悠介|神澤克徳,,E11:教育応用,第二言語学習者におけるスピーキング能力を測る指標の 1 つである流暢性を論じる際，それを阻害する非流暢性現象が注目されてきた．個別の非流暢性現象を習熟度と関連づける先行研究が多い中で，複数の現象間の関係性を大規模なデータから論じた研究は少ない．本研究では，英語学習者コーパスのKIT Speaking Test Cor pus を利用し，4 タイプの自己訂正（追加・削除・置換・倒置）に関して，反復・フィラーという他の非流暢性現象がどの程度共起しやすいかを調査した．その結果，追加・置換については習熟度ごとに共起傾向の違いが認められた．
E11-6,論理構造グラフを用いた自動採点モデル,加藤嘉浩,,E11:教育応用,本研究では，エッセイの論理構造のグラフ表現を考慮した自動採点モデルを提案する．エッセイの論理構造は採点結果に影響する要因の一つと考えられ，これまでに論理構造の要素（主張や前提となる節や句，単語の連なり．以降，論理要素）の統計量や要素間の関係を考慮したモデルが提案されている．しかし，従来手法の論理要素とその関係を提案モデルに入力してもあまり精度が向上しなかった．本研究では，論理要素を含む文全体を論理要素として用い，文間の関係を推定し線形計画法で論理構造グラフを抽出する．そして，グラフ構造を考慮可能な Graph Attention Network により特徴量を抽出し自動採点モデルに結合する．ASAP データセットでの実験から提案モデルはベースラインおよび従来手法よりも高精度な結果となった．また，論理構造推定手法を検証するため，ランダム構造やグラフのエッジ削除前の構造を入力した場合とも比較することで提案手法の有効性を示した．
P11-1,ChatGPTを用いた小説関連研究：教育的小説の生成、マダミスの生成、推理小説での犯人推定,村田真樹,,P11:ポスター,ChatGPT などの言語生成 AI の発展が目覚ましい。本研究では、ChatGPT を用いた小説関連研究を行った。具体的には、教育的小説の半自動生成、マーダーミステリー（マダミス）の半自動生成、推理小説での犯人推定を行った。これらについて紹介する。教育的小説は被験者実験を行い、ある程度の有効性を確かめた。ChatGPT は論理に弱いという問題がある。論理に弱い内容だが、マダミスを 2 編作成できた。推理小説のあらすじを ChatGPT で生成し、そのあらすじを ChatGPT に与えて犯人を答えさせた。
P11-2,処理途中での非文生成の回避を考慮した係り受け解析・語順整序・読点挿入の同時実行,荒木駿介|大野誠寛|松原茂樹,,P11:ポスター,日本語において，語順や読点の使用法は比較的自由に書き手に任されるが，実際には選好が存在しているため，意味は伝わるものの読みにくい文が作成されることがある．本稿では，推敲支援のための要素技術として，Shift-Reduce アルゴリズムを拡張した，日本語文に対する係り受け解析・語順整序・読点挿入の同時実行手法を提案する．提案手法の特徴は，従来手法において処理途中の語順が非文になるという問題を回避するため，同じ文節に係ると決定された 2 文節間でのみ語順入替を行う点にある．
P11-3,大規模言語モデルを用いた規則適合判定と理由の生成,田所佑一|小林一郎|平博順,,P11:ポスター,自律型ロボットと人間が共生したり，自動運転車が公道を走る世の中ではロボットや計算機の行動が，規則に沿ったものであるか説明できる規則適合判定技術は責任問題に関わるため重要である．本研究では，普通自動車免許の学科試験を題材とし，判定理由も出力可能な規則適合判定技術の開発を試みた．実験の結果，GPT-4 を用いた手法で，先行研究と比較して高い精度を達成した．また，GPT-3.5 やGPT-4 と比較して軽量なモデルで規則適合判定と理由の生成が可能であることを確認した．
P11-4,漸進的係り受け解析と残存文長推定に基づく講演文への逐次的な改行挿入,高橋晨成|大野誠寛|松原茂樹,,P11:ポスター,講演を対象とした字幕生成システムにおいて，講演文特有の長い文が複数行にまたがって表示される際に，適切な位置に改行を挿入し，読みやすい字幕を生成する必要がある．これまでにも，改行挿入手法がいくつか提案されているが，特に逐次的な改行挿入手法には精度向上の余地が残されている．そこで本稿では，読みやすい字幕を生成するための要素技術として，漸進的係り受け解析と残存文長推定に基づく逐次的な改行挿入手法を提案する．本手法の特徴は，各文節が入力されるごとに改行を挿入するか否かを BERT により判定する際に，同時に残存文長の推定を行いつつ，漸進的係り受け解析から得られる構文情報を用いる点にある．
P11-5,手順のテキスト化による将棋解説文生成,山内悠輔|河原大輔,,P11:ポスター,近年コンピュータ将棋の進歩は凄まじく、2017 年にコンピュータ将棋が現役名人を破ってからその差は広がるばかりである。しかし、コンピュータ将棋は推定機構の都合上、ある局面における最善手や評価値を出力することしかできず予測した手の意味や局面の状況の良し悪しの根拠は利用者が独自で判断するほかない。本研究ではある局面を、それまでの手順をテキストに変換して言語モデルに入力することで、解説文を自動生成するモデルを構築する。このモデルは局面の状況を言語的特徴量に変換しており、様々な拡張可能性が存在する。
P11-6,二つの時系列データを対象とした特定着目点の動向についての記述文生成,中野由加子|小林一郎,,P11:ポスター,近年，様々な分野において数値データの収集が容易になり，表や時系列チャートなど多様な表現形式での数値データについて自然言語で記述するData-to-Text の研究が注目されている．Data-to-Textの研究のうちデータの分析的な意味について説明する研究においては，一つの時系列データの動向について説明する研究は行われている．その一方で時系列データ全体の動向を捉えることが可能でかつ時系列データ同士を時系列で比べて関係性を捉える研究は，著者らが知る限りほぼ提案されていない．本研究は，二つの時系列データにおいて特定着目点における動向を説明する自然言語文生成手法を提案する．
P11-7,kNN言語モデルは低頻度語の予測に役立つか？,西田悠人|森下睦|出口祥之|上垣外英剛|渡辺太郎,,P11:ポスター,検索拡張言語モデルの 1 つである kNN 言語モデルは，推論時に任意のテキストデータから構築された大規模なデータストアに直接アクセスして近傍事例を活用することで，文脈を適切に把握し，言語らしさを高精度に予測可能であることが報告されている．データストアの明示的な記憶を利用することによって低頻度語の予測性能が改善することが，kNN言語モデルの性能向上の要因の 1 つであるという仮説が提唱されてきたが，この仮説の定量的な検証は行われてこなかった．本研究では，低頻度語に対する kNN 言語モデルの振る舞いを定量的に分析し，これまでの仮説に反して，kNN 言語モデルは低頻度語の予測性能の改善に寄与しないことを示した．
P11-8,RAGにおける小説データベースのChunk SizeとOverlap SizeとEmbeddingモデルの効果,阿部晃弥|新納浩幸,,P11:ポスター,大規模言語モデルにおいて，追加学習せずに外部知識を扱う手法として，RAG(Retrieval-AugmentedGeneration)が用いられる．これは，文書をベクトル化して保存しておき，正確な回答に必要な文書をprompt に組み込んで生成する手法である．本論文では，日本語の小説をデータベースとした RAG において，ベクトル・インデックスの作成の際，ChunkSize，Overlap Size 及び Embedding モデルを変更した場合の Retrieval の結果，回答への影響を検証した．実験の結果，Chunk Size には規則性が見られないが，Overlap Size は大きいほど概ね良い結果が確認できた．また，Chunk Size や Overlap Size の値とは無関係に，Embedding モデル間の性能差が確認された．
P11-9,BERTScoreとキーワード採用率を用いた語義タグ付き用例文生成手法,長友日雅|佐々木稔,,P11:ポスター,近年の語義曖昧性解消タスクには、語義タグ付きコーパスを用いて機械学習を行ったモデルが問題解決に用いられている。しかし、語義タグ付きコーパスは基本的に人手でしか作成することができないため、データ数が限られている。そこで本研究では、語義タグ付きコーパスからキーワードを抽出し、それをもとにテキスト生成を行うことで、語義タグ付きコーパスのデータ数を機械的に増やす手法を提案し、生成したテキストの有用性を分析する。キーワードからテキスト生成を行うモデルには keytotextがあるが、文章が流暢でない、文中にキーワードが含まれないなどの問題を抱えており、自然なテキストを生成することがほとんどない。そのため、本研究では、モデルの学習に使用するデータセットや損失関数を変更することで、モデルの性能がどのように変化するのかを定量的・定性的に評価する。検証の結果、学習に利用するデータセットを洗練し、検証時の損失関数に BertScore やキーワードの採用率といった、正解テキストを直接参照しない評価指標を用いて学習を行うことにより、既存モデルよりも高いスコアを持つモデルが得られることが分かった。
P11-10,文を入力とした俳句の自動生成,大山野乃子|杉本徹,,P11:ポスター,本研究は，GPT-2 モデルを 2 回ファインチューニングすることによって，入力文の内容に合うような俳句を生成する手法を提案する．自分の身近な体験を述べた文から俳句を生成し，それを鑑賞してもらうことでユーザの日々の発見を増やし，より生活を楽しませることを目的としている．俳句と鑑賞文およびそれらから抽出した単語を用いてファインチューニングを行い，モデルを構築した．生成された俳句について，人手の評価を行った結果，俳句中の単語と鑑賞文を用いてファインチューニングすることが入力文の内容と合う俳句を生成するために有効であることが分かった．
P11-11,テキスト生成モデルを利用したデータセット蒸留,前川在|小杉哲|船越孝太郎|奥村学,,P11:ポスター,データセット蒸留は，訓練データセット中の知識を蒸留することで，ニューラルモデルを効率的に学習可能な少量の合成データを獲得する．本研究では，学習効果の高い訓練データを生成するようテキスト生成モデルを学習することで，合成データをテキストとして獲得する手法を提案する．実験では，提案法を複数のテキスト分類タスクのデータセットに適用し，元のデータセットから選択された代表サンプル集合よりも高い性能でモデルを学習可能であることを示した．また，提案法によりテキストとして獲得した合成データは，蒸留時と異なる事前学習済みモデルの学習に対する汎化性能だけでなく，大規模言語モデルの in-context learning に対しても効果的であることを示した．
P11-12,Shift-Reduce法に基づく未入力トークン予測と漸進的係り受け解析の同時実行,橋本優希|大野誠寛|松原茂樹,,P11:ポスター,同時通訳や字幕生成などの音声言語システムに対して，音声入力の途中で随時，構文情報を提供することを目的に，文節が入力されるごとに係り受け構造を同定し出力するという漸進的係り受け解析手法が提案されている．本稿では，さらに豊かな情報を後段のシステムに提供するため，未入力トークン予測と漸進的係り受け解析を同時実行する手法を提案する．講演文を用いた実験の結果，本手法の有効性を確認した．
P11-13,Large Language Models as Generalizable Text-to-Table Systems,◊StevenCoyne|YuyangDong,,P11:ポスター,"Wu et al.[1] formalized the task of text-to-table gen-eration, in which unstructured texts are summarized in ta-ble form. However, their experiments focus on ﬁne-tuned,dataset-speciﬁc models that show limited performance out-side of the data they were trained on. As the task assumesno user query, systems ideally generate valid tables acrossvarious input texts without favoring the layout or tablecount of a particular dataset. To address this, we applyprompted large language models (LLMs) to this task, as-sessing their suitability as generalizable text-to-table sys-tems. To more accurately rate outputs, particularly in azero-shot setting, we revise the evaluation script from [1]to align tables by column similarity before scoring."
P11-14,日本語GPTの蒸留における損失関数の比較,西村稜真|狩野芳伸,,P11:ポスター,本研究では日本語を対象に，蒸留を用いて GPT-2の小型化のための事前学習を行った.蒸留に際しては，通常の事前学習におけるマスク言語モデルの損失と蒸留の損失の混合率や，蒸留の損失において計算対象とする層など，異なる損失関数を用意して比較した.パープレキシティによる主観評価では，small サイズのベースラインに対しその 68%のサイズの生徒モデルでよりよい値を達成し，文生成結果の主観評価では上回らなかったものの，大きなモデルの性能に匹敵するより小さいモデルへの蒸留の可能性を示した.
P11-15,大規模言語モデルへの定量的推論機能の組み込み,伊東恵美|小林一郎,,P11:ポスター,本研究は，大規模言語モデルに実世界に対応した定量的推論（特にファジィ推論）機能を組み込むことを目的とし，二つの物体が衝突した後の予測状態を自然言語で推論可能であることを示す．衝突後の状態として推論される帰結を自然言語で表現すると同時に，定量的な状態変化をファジィ推論によるメンバーシップ関数の推定により導き出すことによって，大規模言語モデルを用いた曖昧な表現を含む推論を実現する．
P11-16,入出力文の関係を考慮した複数文要約でのデータ拡張,三沢翔太郎|三浦康秀,,P11:ポスター,自然言語処理でのデータ拡張（Data Augmentation）は，単語の削除，挿入，置換や，学習済みモデルで文全体を言い換える手法などが一般的に用いられている．しかし複数文から成り立つ長い文章を要約する設定に対して，文章全体のトピック構成を変化させる方法は存在しない．本研究では，入出力文の関係性を担保したまま，文章全体のトピック構成を変えたデータを作成する方法を提案する．入力文章が複数文である文書要約を対象とした実験で本手法の有効性を確認した．
P11-17,LLMを利用した文書分類のためのData Augmentation,小野寺優|新納浩幸,,P11:ポスター,大規模言語モデル(Large Language Model:LLM)は様々な自然言語処理タスクに利用され，多くの成果を挙げている．本研究では，文書分類に対するData Augmentation に LLM を利用することを試みる．LLM を Data Augmentation に利用する場合，少数のラベル付きデータからどのようなプロンプトで文書を生成すればよいかが重要となる．ここでは，少数の訓練データからキーワードと要約文を生成し，その 2 要素で構成されたプロンプトを試みる．実験では，livedoor ニュースコーパスの文書分類タスクを行い，本プロンプトの有効性を調査した．その結果，本プロンプトの有効性を示すことはできなかった．これを踏まえて，LLM を用いて文書分類に対するデータを生成する上での課題を考察する．
P11-18,訴求軸を考慮したキーワードからの広告文生成,村田栄樹|大友寛之|村上聡一朗|本多右京|舟久保弘明,,P11:ポスター,"広告文が適切な訴求を含むことは,その効果を高める.しかし,キーワードから広告文を生成する既存研究では明示的に訴求を考慮していない.本論文では,キーワードを入力として広告文を生成するタスクを対象に,訴求軸を考慮した広告文生成手法を提案する.キーワードに加え訴求軸を指定することで,その訴求を含む広告文を生成する.自動評価および人手評価により,入力された訴求軸に対応した適切な広告文を生成できることを確かめた."
P11-19,文書情報構造認識のためのAI chatbotプロンプト評価,中渡瀬秀一,,P11:ポスター,生成 AI の一種である AI チャットボットは，対話的に利用者の指示に応えることができる．この機能によって与えられた文書に対する処理(加工・認識など)を行うことも可能である．本稿では，生成 AI で文書の情報構造を認識するタスク（文献抽出）を処理するために用いるプロンプトの実験的評価を行う．実験では異なるレイアウトやフォーマットの論文に対して，先行研究の知見を参考にして設計した複数のプロンプトを適用してそれらの評価と知見の検証を行った．
P11-20,検出器の判断に基づく大規模言語モデルの生成テキストの特徴分析,三浦東子|谷口雅弥|坂口慶祐|乾健太郎,,P11:ポスター,本研究では，大規模言語モデル(LLM)が生成するテキスト(LLM-text)の特徴をヒトが書いたテキスト(human-text)との比較から明らかにする．エッセイを対象に 2 つの実験を行った. 1 つ目は human-text とLLM-text から LLM-text を分類する実験，2 つ目は，LLM-text に改変を加えることで LLM-text の検出を妨害する実験である．1 つ目の実験から LLM-textに固有の特徴があることを示した．さらに2つ目の実験から，その特徴が「単語の連なりの滑らかさ」であることを示した．そして，この他の特徴をLLM-text が備え得ることや， LLM-text の特徴の軽減と human-text の特徴の付加について今後の課題として議論する.
P11-21,おもしろい川柳の生成,太田聖三郎|河原大輔|野村理朗,,P11:ポスター,本研究では，深層学習による川柳生成モデルの構築を通じて，自然言語処理技術の創造性の向上に焦点を当てる．川柳生成において，音数やお題に沿った内容，おもしろさの学習を組み合わせ，end-to-endでの生成を可能にする．人手評価や自動評価により，提案手法はベースラインに比べて音数制御の精度，川柳のとしての適否，おもしろさの面で優れていることを示した．今後は，人間の川柳との相違点を埋めつつ，モデルの更なる洗練を目指す．
P11-22,創造的な文生成タスクに対するLLMプロンプトの自動生成,鈴木就斗|狩野芳伸,,P11:ポスター,大規模言語モデル（LLM）の性能を引き出すには，与えるプロンプトの良し悪しが重要である．プロンプト自動生成の研究もあるが，多くは自動評価しやすい唯一解のあるタスクが対象である．我々は，唯一解の無い創造的な文生成タスクに対してプロンプトの自動生成を試みた．そのための自動評価指標には埋め込み表現を用いて，期待される正解への近さと，創造性すなわち入力からの距離とを総合した指標により両者が反映されるようにした．インターネット記事作成における読者ニーズおよび記事見出しの生成を題材に，プロンプトを生成しないFew-shot Prompting と比較し，主観評価により提案手法がより有用な結果を生成できることを示した．
P11-23,Retrieval-augmented generation に基づくカスタマーサポートにおける返信メール自動生成の検討,小島淳嗣,,P11:ポスター,企業のカスタマーサポートにおけるカスタマーへの返信メール作成業務を支援するため、返信メールを自動で生成するシステムを検討する。システムは retriever model とプロダクトについて学習させた large language model (LLM)によって構成され、retrieval augmented generation (RAG)に基づいて返信メールを生成する。メールの生成において、retrievermodel は問い合わせメールの回答に該当する情報を含む topN のチャンクをサポートサイトのページと返信メールテンプレートから抽出する。次に LLMは retriever model によって選択されたチャンクとカスタマーのメール文を入力として返信メールを生成する。LLM は事前に汎用ドメインで事前学習を行った後、サポートサイトのテキストを用いて継続事前学習を行う。さらに、カスタマーの問い合わせメールと実際の返信メールをそれぞれ prompt とcompletion とみなして supervised ﬁne-tuning を行った。実験では、継続事前学習や RAG の有効性、及びエラー分析の結果について報告する。
P11-24,大規模言語モデルを用いた関連研究セクション生成,桒原龍生|杉山弘晃|堂坂浩二|田中陸斗|平博順,,P11:ポスター,科学論文が増加している中，論文執筆支援に注目が集まっている．論文執筆支援における部分タスクとして，関連研究セクションの文章生成がある．関連研究セクションの文章生成に関する研究は，言語モデルの入力トークン数の制限から，そのほとんどが単一の引用文生成に焦点を当てていた．本研究では，入力トークン数の上限が上がった最新の大規模言語モデルを用いて，関連研究セクション全体の文章生成を試みた．また，人手による文章品質の評価と相関が高いと言われている G-EVAL と呼ばれる評価手法により，文章生成結果についての品質評価および分析を行った．
P11-25,コード生成のための大規模言語モデルを用いた検索手法,中原康宏|宮下大輔|出口淳,,P11:ポスター,"Large Language Model によるプログラムコード生成は有用であるが，LLM が持つ情報の更新には膨大なコストが必要である．この課題に対応するために，関連する情報を検索し LLM への入力に追加する手法が提唱されており，コード生成の分野ではBM25 などのベクトル検索を用いた手法が成果を挙げている．しかし，GitHub のような Web サイトをデータベースとする場合，全データを手元に置く必要のあるベクトル検索はデータ収集に膨大なコストを必要とし，常に情報を最新に保つことは困難である．よって，本論文では GitHub API がサポートしている既存の Web 検索と LLM を用いた検索手法を提案する．これにより，提案する手法は低コストで常に最新の情報にアクセスすることができる．本手法は Web 検索と LLM を組み合わせる際に生じるいくつかの典型的な課題にも対応している．提案手法を評価した結果,有用なリポジトリを見つけ出すことができたことを確認した．"
P11-26,RLHFを用いた「面白い」短歌の自動生成の試み,羽根田賢和|浦川通|田口雄哉|田森秀明|坂口慶祐,,P11:ポスター,自然言語処理技術の発展は小説などの文学作品の自動生成を現実的なものとしている．一方で短歌におけるモーラ数のような制約を満たしつつ，高い芸術性を有する文学作品を生成することは，既存の言語モデルでは容易ではない．本研究ではこの課題に対する解決策として RLHF による学習を用いた短歌の自動生成モデルを提案する．人間の短歌に対する評価を反映した報酬モデルの学習とこれを用いた生成モデルの強化学習により，短歌らしい系列長を有し，かつ人間に「面白い」と判断されやすいような短歌の自動生成が可能となった．
P11-27,Event-Centered Prompting for Text Style Transfer,◊徐勝|鈴木良弥|福本文代,,P11:ポスター,"Text style transfer (TST), recently, attracted signiﬁcantresearch interest. Although previous attempts have shownoutstanding performance for sentiment or formality trans-fer, they still encounter limitations to some extent consid-ering the arbitrariness of context and the lack of anno-tated corpora. In this work, we explore an Event-CenteredPrompt (ECP) strategy leading to causal large languagemodel (LLM) transferring the text style. Based on thestrategy, we explore the inference of LLM by two steps ofthe prompt: the model retrieves the event of the source textalong the prompt, then further generates the target follow-ing another prompt. Our ECP strategy can be applicableto design prompt formats for diverse style transfer tasks.The experimental results on the Yelp and Amazon datasetswhich leverage the LLaMA as the backbone show the ef-fectiveness of our method. The source code is availableonline1）."
