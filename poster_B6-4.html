

<!DOCTYPE html>
<html lang="en">
<head>
    


    <!-- Required meta tags -->
    <meta charset="utf-8"/>
    <meta
            name="viewport"
            content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />

    <!-- External Javascript libs_ext  -->
    <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script
            src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
            integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
            crossorigin="anonymous"
    ></script>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js"
            integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
            integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js"
            integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww="
            crossorigin="anonymous"></script>


    <!-- Library libs_ext -->
    <script src="static/js/libs_ext/typeahead.bundle.js"></script>


    <!--    Internal Libs -->
    <script src="static/js/data/api.js"></script>

    

    <!-- External CSS -->
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
          integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY="
          crossorigin="anonymous">

    <!-- External Fonts (no google for china) -->
    <link
            href="static/css/Lato.css"
            rel="stylesheet"
    />
    <link href="static/css/Exo.css" rel="stylesheet"/>
    <link
            href="static/css/Cuprum.css"
            rel="stylesheet"
    />
    <link rel="stylesheet" href="static/css/main.css"/>
<!--    <link rel="stylesheet" href="static/css/fa_regular.css"/>-->
    <link rel="stylesheet" href="static/css/fa_solid.css"/>
    <link rel="stylesheet" href="static/css/lazy_load.css"/>
    <link rel="stylesheet" href="static/css/typeahead.css"/>

    <title>NLP2024人工画像を用いたText-to-Imageモデルの事前学習</title>
    
<meta name="citation_title" content="人工画像を用いたText-to-Imageモデルの事前学習"/>

<meta name="citation_author" content="○中尾純平 (東大), 磯沼大 (東大/エディンバラ大), 片岡裕雄 (産総研), 森純一郎 (東大/理研), 坂田一郎 (東大)"/>

<meta name="citation_publication_date" content=""/>
<meta name="citation_conference_title"
      content=""/>
<meta name="citation_inbook_title" content=""/>
<meta name="citation_abstract" content="近年，大規模 Text-to-Image (T2I)モデルの事前学習に用いるデータセットに対して倫理面の問題が指摘されている．そこで本研究では人工画像を用いた T2I モデルの事前学習を検討する．人工画像にはキャプションが付与されていないことが事前学習に用いる際の難所となるが，本研究では CLIP を活用して人工画像に疑似的なキャプションを付与することでこの点にアプローチした．評価実験では，人工画像と実画像でそれぞれ事前学習したモデルを，複数の実画像データセットでファインチューニングした後の生成画像の精度で比較することで，人工画像を用いた事前学習が実画像を用いた事前学習に迫る有効性を示すことと共に，人工画像の色による多様性と輪郭という性質が重要であることを確認した．"/>

<meta name="citation_keywords" content=""/>

<meta name="citation_pdf_url" content=""/>


</head>

<body>
<!-- NAV -->



<nav
        class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto"
        id="main-nav"
>
    <div class="container">
        
        
        <a class="navbar-brand" href="papers.html">NLP2024</a>
        
        <button
                class="navbar-toggler"
                type="button"
                data-toggle="collapse"
                data-target="#navbarNav"
                aria-controls="navbarNav"
                aria-expanded="false"
                aria-label="Toggle navigation"
        >
            <span class="navbar-toggler-icon"></span>
        </button>
        <div
                class="collapse navbar-collapse text-right flex-grow-1"
                id="navbarNav"
        >
            <ul class="navbar-nav ml-auto">
                
                <li class="nav-item ">
                    <a class="nav-link" href="papers.html">Papers</a>
                </li>
                
            </ul>
        </div>
    </div>
</nav>



<!-- User Overrides -->
 

<div class="container">
    <!-- Tabs -->
    <div class="tabs">
         
    </div>
    <!-- Content -->
    <div class="content">
        

<!-- Title -->
<div class="pp-card m-3" style="">
    <div class="card-header">
        <h2 class="card-title main-title text-center" style="">
            人工画像を用いたText-to-Imageモデルの事前学習
        </h2>
        <h3 class="card-subtitle mb-2 text-muted text-center">
            
            <a href="papers.html?filter=authors&search=○中尾純平 (東大), 磯沼大 (東大/エディンバラ大), 片岡裕雄 (産総研), 森純一郎 (東大/理研), 坂田一郎 (東大)"
               class="text-muted"
            >○中尾純平 (東大), 磯沼大 (東大/エディンバラ大), 片岡裕雄 (産総研), 森純一郎 (東大/理研), 坂田一郎 (東大)</a
            >
            
        </h3>
        <p class="card-text text-center">
            <span class="">Keywords:</span>
            
            <a
                    href="papers.html?filter=keywords&search="
                    class="text-secondary text-decoration-none"
            ></a
            >
            
        </p>
        <div class="text-center p-3">
            
            <a class="card-link" target="_blank" href="https://anlp.jp/proceedings/annual_meeting/2024/pdf_dir/B6-4.pdf">
                Paper (PDF)
            </a>
            
        </div>
    </div>
</div>
<div id="details" class="pp-card m-3">
    <div class="card-body">
        <div class="card-text">
            <div id="abstractExample">
                <span class="font-weight-bold">Abstract:</span>
                近年，大規模 Text-to-Image (T2I)モデルの事前学習に用いるデータセットに対して倫理面の問題が指摘されている．そこで本研究では人工画像を用いた T2I モデルの事前学習を検討する．人工画像にはキャプションが付与されていないことが事前学習に用いる際の難所となるが，本研究では CLIP を活用して人工画像に疑似的なキャプションを付与することでこの点にアプローチした．評価実験では，人工画像と実画像でそれぞれ事前学習したモデルを，複数の実画像データセットでファインチューニングした後の生成画像の精度で比較することで，人工画像を用いた事前学習が実画像を用いた事前学習に迫る有効性を示すことと共に，人工画像の色による多様性と輪郭という性質が重要であることを確認した．
            </div>
        </div>
        <p></p>
    </div>
</div>



<script src="https://cdn.jsdelivr.net/npm/pdfjs-dist@2.3.200/build/pdf.min.js"></script>
<script src="static/js/modules/pdfRender.js"></script>
<script>
  $(document).ready(() => {
    // render first page of PDF to div
    // PDF name can be bound to variable -- e.g. paper.content.poster_link
    const pdfFile =
      " ";
    initPDFViewer(pdfFile, "#pdf_view");
  });
</script>



    </div>
</div>



<!-- Google Analytics -->
<script
        async
        src="https://www.googletagmanager.com/gtag/js?id="
></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag("js", new Date());
  gtag("config", "");
</script>



<!-- Code for hash tags -->
<script type="text/javascript">
  $(document).ready(function () {
    if (window.location.hash !== "") {
      $(`a[href="${window.location.hash}"]`).tab("show");
    }

    $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
      const hash = $(e.target).attr("href");
      if (hash.substr(0, 1) === "#") {
        const position = $(window).scrollTop();
        window.location.replace(`#${hash.substr(1)}`);
        $(window).scrollTop(position);
      }
    });
  });
</script>
<!--    <script src="static/js/modules/lazyLoad.js"></script>-->

</body>
</html>